{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "batch_size = 1024\n",
    "#dataset = \"MNIST\"\n",
    "dataset = \"CIFAR10\"\n",
    "#dataset = \"CIFAR100\"\n",
    "#dataset = \"IMAGENET\"\n",
    "#dataset = \"FMNIST\"\n",
    "\n",
    "if(dataset == \"MNIST\"):\n",
    "    # 1) MNIST Dataset & Dataloaders\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    classes = ('zero', 'one', 'two', 'three', 'four', 'five', 'sis', 'seven', 'eight', 'nine')\n",
    "\n",
    "    input_size = (1, 32, 32)\n",
    "\n",
    "if(dataset == \"FMNIST\"):\n",
    "    # 1) MNIST Dataset & Dataloaders\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset  = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    classes = ('zero', 'one', 'two', 'three', 'four', 'five', 'sis', 'seven', 'eight', 'nine')\n",
    "\n",
    "    input_size = (1, 32, 32)\n",
    "    \n",
    "if(dataset == \"CIFAR10\"):\n",
    "    # 2) CIFAR-10 dataset\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(90, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        #transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))  # mean, std\n",
    "    ])\n",
    "\n",
    "    # Transformations for testing: just convert and normalize\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    input_size = (3, 32, 32)\n",
    "\n",
    "if(dataset == \"CIFAR100\"):\n",
    "    # 2) CIFAR-10 dataset\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(90, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        #transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))  # mean, std\n",
    "    ])\n",
    "\n",
    "    # Transformations for testing: just convert and normalize\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
    "    test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = [x for x in range(100)]\n",
    "\n",
    "    input_size = (3, 32, 32)\n",
    "    \n",
    "if(dataset == \"IMAGENET\"):\n",
    "    # 2) CIFAR-10 dataset\n",
    "    train_transform = transforms.Compose([\n",
    "        #transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(90, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        #transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))  # mean, std\n",
    "    ])\n",
    "\n",
    "    # Transformations for testing: just convert and normalize\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageNet(root='./data', train=True, download=True, transform=train_transform)\n",
    "    test_dataset = datasets.ImageNet(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = [x for x in range(100)]\n",
    "\n",
    "    input_size = (3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img_tensor):\n",
    "    \"\"\"\n",
    "    img_tensor: a batch of images in shape (B, C, H, W) or a single image in (C, H, W).\n",
    "    \"\"\"\n",
    "    # If it's a batch of images (4D), make a grid first\n",
    "    if len(img_tensor.shape) == 4:\n",
    "        img_tensor = torchvision.utils.make_grid(img_tensor)\n",
    "    # Unnormalize\n",
    "    #img_tensor = unnormalize(img_tensor)\n",
    "    # Convert to numpy\n",
    "    npimg = img_tensor.numpy()\n",
    "    # Transpose from (C, H, W) to (H, W, C)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(images[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_to_bit(x : torch.Tensor) -> torch.Tensor:\n",
    "    return torch.exp(x)\n",
    "\n",
    "def bit_to_param(x : torch.Tensor) -> torch.Tensor:\n",
    "    return torch.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_float_truncate(x: torch.Tensor, e_bits_int: int, m_bits_int: int, scale_int: int) -> torch.Tensor:\n",
    "\n",
    "    sign = x.sign()\n",
    "    abs_x = x.abs().clamp(min=1e-45) / 2**scale_int\n",
    "\n",
    "    #recover the floatint point representation\n",
    "    #exponent \\in {-2**7,..,2**7-1}\n",
    "    #mantissa \\in {1.0,...,2.0}\n",
    "\n",
    "    exponent = torch.floor(torch.log2(abs_x)).clamp(min=1e-45)\n",
    "    mantissa = abs_x / (2**exponent)\n",
    "    \n",
    "    #print(\"exp: \", exponent)\n",
    "    #print(\"mantissa: \", mantissa)\n",
    "\n",
    "    # truncate exponent\n",
    "    # lets parameterize the exponent as a constant value + a variable value\n",
    "    # the constant part is 2**7-1 in standar floating point, but we will learn it\n",
    "    # the variable part \\in {0,..,2**8-1}\n",
    "    # lets say exponent = v_exponent - 2**(bits-1)-1 + c_exponent\n",
    "    # so v_exponent = exponent + 2**(bits-1)-1 - c_exponent\n",
    "    c_exponent = 0 #scale_int\n",
    "    z_exponent = (2**(e_bits_int-1)-1)\n",
    "    if e_bits_int == 0:\n",
    "        z_exponent = 0\n",
    "    v_exponent = exponent + z_exponent - c_exponent\n",
    "    \n",
    "    #print(\"v exponent: \", v_exponent)\n",
    "    \n",
    "    # the valriable part is clamped to the alloted bits\n",
    "    q_min = torch.tensor(float(0)).to(x.device)\n",
    "    q_max = 2**e_bits_int-1\n",
    "    q_v_exponent = torch.clamp(v_exponent, q_min, q_max)\n",
    "    q_exponent = q_v_exponent - z_exponent + c_exponent\n",
    "\n",
    "    #print(\"q v exponent: \", q_v_exponent)\n",
    "    #print(\"q exponent: \", q_exponent)\n",
    "\n",
    "    # truncate mantissa\n",
    "    # this just removes the less significant bits\n",
    "    m_scale = 2.0 ** m_bits_int\n",
    "    q_mantissa = torch.floor(mantissa * m_scale) / m_scale\n",
    "\n",
    "    #print(\"q mantissa \", q_mantissa)\n",
    "\n",
    "    # from quantized floatint point to float\n",
    "    fq_x = sign * (2**q_exponent) * q_mantissa * 2**scale_int\n",
    "    return fq_x\n",
    "\n",
    "class FakeFloatFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd for 'fake-float' exponent+mantissa truncation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, e_bits_param, m_bits_param, scale_param):\n",
    "        \n",
    "        # save for backward\n",
    "        ctx.save_for_backward(x, e_bits_param, m_bits_param, scale_param)\n",
    "        \n",
    "        # Round e_bits, m_bits to nearest integer for the forward pass\n",
    "        e_bits_int = int(torch.round(param_to_bit(e_bits_param)).item())\n",
    "        m_bits_int = int(torch.round(param_to_bit(m_bits_param)).item())\n",
    "        s_int = int(torch.round(scale_param).item())\n",
    "\n",
    "        out = fake_float_truncate(x, e_bits_int, m_bits_int, s_int)\n",
    "        \n",
    "        #print(\"input\")\n",
    "        #print(x)\n",
    "        #print(\"output\")\n",
    "        #print(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, e_bits_param, m_bits_param, scale_param = ctx.saved_tensors\n",
    "        \n",
    "        e_bits = param_to_bit(e_bits_param)\n",
    "        m_bits = param_to_bit(m_bits_param)\n",
    "        scale = scale_param\n",
    "                \n",
    "        e_bits_int = int(torch.round(e_bits).item())\n",
    "        m_bits_int = int(torch.round(m_bits).item())\n",
    "        scale_int = int(torch.round(scale).item())\n",
    "\n",
    "        #print(\"shape x: \", x.shape)\n",
    "        #print(\"shape grad_output: \", grad_output.shape)\n",
    "\n",
    "        # 1) Gradient wrt x: straight-through\n",
    "        grad_x = grad_output\n",
    "        \n",
    "        # 1) Gradient wrt x: approximate with central difference\n",
    "        \"\"\"\n",
    "        grad_x = None\n",
    "        if True:\n",
    "            delta = 0.01            \n",
    "\n",
    "            f_plus2  = fake_float_truncate(x + 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_plus   = fake_float_truncate(x + 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus  = fake_float_truncate(x - 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus2 = fake_float_truncate(x - 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "        \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "            grad_x = grad_output * der\n",
    "        \"\"\"\n",
    "                \n",
    "        # 2) Gradient wrt e_bits: approximate with central difference\n",
    "        grad_e_bits = None\n",
    "        if e_bits_param.requires_grad:\n",
    "            \n",
    "            if(e_bits_int < 2):\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int + 1, m_bits_int, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int    , m_bits_int, scale_int)\n",
    "                der = (f_plus - f_minus)\n",
    "            else:\n",
    "                f_plus2  = fake_float_truncate(x, e_bits_int + 2, m_bits_int, scale_int)\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int + 1, m_bits_int, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int - 1, m_bits_int, scale_int)\n",
    "                f_minus2 = fake_float_truncate(x, e_bits_int - 2, m_bits_int, scale_int)\n",
    "            \n",
    "                der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_e_bits = grad_output * der * e_bits\n",
    "        \n",
    "        # 3) Gradient wrt m_bits: approximate with central difference\n",
    "        grad_m_bits = None\n",
    "        if m_bits_param.requires_grad:\n",
    "            \n",
    "            if(m_bits_int < 2):\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int, m_bits_int + 1, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int, m_bits_int    , scale_int)\n",
    "                der = (f_plus - f_minus)\n",
    "            else:\n",
    "                f_plus2  = fake_float_truncate(x, e_bits_int, m_bits_int + 2, scale_int)\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int, m_bits_int + 1, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int, m_bits_int - 1, scale_int)\n",
    "                f_minus2 = fake_float_truncate(x, e_bits_int, m_bits_int - 2, scale_int)\n",
    "            \n",
    "                der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_m_bits = grad_output * der * m_bits\n",
    "       \n",
    "        # 4) Gradient wrt m_bits: approximate with central difference\n",
    "        grad_scale_bits = None\n",
    "        if scale_param.requires_grad:\n",
    "            \n",
    "            f_plus2  = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int + 2)\n",
    "            f_plus   = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int + 1)\n",
    "            f_minus  = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int - 1)\n",
    "            f_minus2 = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int - 2)\n",
    "            \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0 \n",
    "            grad_scale_bits = grad_output * der\n",
    "             \n",
    "        return grad_x, grad_e_bits, grad_m_bits, grad_scale_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_bits  0  m_bits  15  scale  1\n",
      "in:  tensor([45.0375])  out:  tensor([2.8148])\n",
      "e_bits  6  m_bits  14  scale  0\n",
      "in:  tensor([6.0524])  out:  tensor([6.0522])\n",
      "e_bits  6  m_bits  14  scale  0\n",
      "in:  tensor([-4.3906])  out:  tensor([-4.3906])\n",
      "e_bits  7  m_bits  26  scale  0\n",
      "in:  tensor([-35.0224])  out:  tensor([-35.0224])\n",
      "e_bits  0  m_bits  24  scale  -1\n",
      "in:  tensor([20.8946])  out:  tensor([0.6530])\n",
      "e_bits  7  m_bits  17  scale  0\n",
      "in:  tensor([38.9923])  out:  tensor([38.9922])\n",
      "e_bits  4  m_bits  30  scale  1\n",
      "in:  tensor([30.2829])  out:  tensor([30.2829])\n",
      "e_bits  1  m_bits  18  scale  0\n",
      "in:  tensor([-39.1020])  out:  tensor([-2.4439])\n",
      "e_bits  8  m_bits  5  scale  2\n",
      "in:  tensor([18.2539])  out:  tensor([18.])\n",
      "e_bits  4  m_bits  10  scale  1\n",
      "in:  tensor([-28.8484])  out:  tensor([-28.8438])\n",
      "e_bits  7  m_bits  15  scale  -2\n",
      "in:  tensor([-41.9346])  out:  tensor([-41.9346])\n",
      "e_bits  2  m_bits  26  scale  -2\n",
      "in:  tensor([35.0531])  out:  tensor([1.0954])\n",
      "e_bits  3  m_bits  11  scale  0\n",
      "in:  tensor([-10.2775])  out:  tensor([-10.2773])\n",
      "e_bits  3  m_bits  26  scale  -1\n",
      "in:  tensor([-29.8515])  out:  tensor([-14.9257])\n",
      "e_bits  8  m_bits  14  scale  1\n",
      "in:  tensor([-2.5053])  out:  tensor([-2.5052])\n",
      "e_bits  4  m_bits  28  scale  0\n",
      "in:  tensor([-23.1600])  out:  tensor([-23.1600])\n",
      "e_bits  3  m_bits  14  scale  2\n",
      "in:  tensor([5.4883])  out:  tensor([5.4880])\n",
      "e_bits  6  m_bits  13  scale  2\n",
      "in:  tensor([41.3728])  out:  tensor([41.3711])\n",
      "e_bits  4  m_bits  14  scale  2\n",
      "in:  tensor([-17.5311])  out:  tensor([-17.5303])\n",
      "e_bits  1  m_bits  24  scale  -1\n",
      "in:  tensor([-0.3248])  out:  tensor([-0.3248])\n",
      "e_bits  8  m_bits  9  scale  0\n",
      "in:  tensor([-3.1502])  out:  tensor([-3.1484])\n",
      "e_bits  4  m_bits  27  scale  2\n",
      "in:  tensor([-33.3149])  out:  tensor([-33.3149])\n",
      "e_bits  3  m_bits  14  scale  -2\n",
      "in:  tensor([9.0790])  out:  tensor([4.5393])\n",
      "e_bits  1  m_bits  4  scale  2\n",
      "in:  tensor([18.2244])  out:  tensor([9.])\n",
      "e_bits  9  m_bits  14  scale  -1\n",
      "in:  tensor([-46.0338])  out:  tensor([-46.0332])\n",
      "e_bits  7  m_bits  8  scale  0\n",
      "in:  tensor([23.0923])  out:  tensor([23.0625])\n",
      "e_bits  0  m_bits  24  scale  -1\n",
      "in:  tensor([-3.9930])  out:  tensor([-0.9983])\n",
      "e_bits  3  m_bits  8  scale  1\n",
      "in:  tensor([-49.4203])  out:  tensor([-49.3750])\n",
      "e_bits  6  m_bits  7  scale  0\n",
      "in:  tensor([46.5679])  out:  tensor([46.5000])\n",
      "e_bits  2  m_bits  20  scale  0\n",
      "in:  tensor([-45.8053])  out:  tensor([-5.7257])\n",
      "e_bits  4  m_bits  7  scale  -1\n",
      "in:  tensor([-34.8893])  out:  tensor([-34.7500])\n",
      "e_bits  0  m_bits  27  scale  1\n",
      "in:  tensor([-49.1354])  out:  tensor([-3.0710])\n",
      "e_bits  0  m_bits  14  scale  -2\n",
      "in:  tensor([-31.2653])  out:  tensor([-0.4885])\n",
      "e_bits  7  m_bits  19  scale  0\n",
      "in:  tensor([-14.6109])  out:  tensor([-14.6109])\n",
      "e_bits  8  m_bits  15  scale  2\n",
      "in:  tensor([46.2537])  out:  tensor([46.2529])\n",
      "e_bits  7  m_bits  29  scale  1\n",
      "in:  tensor([-7.6921])  out:  tensor([-7.6921])\n",
      "e_bits  1  m_bits  27  scale  0\n",
      "in:  tensor([-1.8778])  out:  tensor([-1.8778])\n",
      "e_bits  3  m_bits  19  scale  0\n",
      "in:  tensor([-45.5428])  out:  tensor([-22.7714])\n",
      "e_bits  9  m_bits  4  scale  1\n",
      "in:  tensor([-22.4303])  out:  tensor([-22.])\n",
      "e_bits  3  m_bits  16  scale  0\n",
      "in:  tensor([-24.5814])  out:  tensor([-24.5813])\n",
      "e_bits  10  m_bits  22  scale  1\n",
      "in:  tensor([36.9339])  out:  tensor([36.9339])\n",
      "e_bits  10  m_bits  10  scale  0\n",
      "in:  tensor([-40.8261])  out:  tensor([-40.8125])\n",
      "e_bits  3  m_bits  10  scale  1\n",
      "in:  tensor([28.5984])  out:  tensor([28.5938])\n",
      "e_bits  7  m_bits  4  scale  1\n",
      "in:  tensor([10.6625])  out:  tensor([10.5000])\n",
      "e_bits  8  m_bits  29  scale  -1\n",
      "in:  tensor([-35.1890])  out:  tensor([-35.1890])\n",
      "e_bits  9  m_bits  14  scale  -2\n",
      "in:  tensor([0.4155])  out:  tensor([0.4155])\n",
      "e_bits  1  m_bits  13  scale  -2\n",
      "in:  tensor([4.3481])  out:  tensor([0.5435])\n",
      "e_bits  0  m_bits  23  scale  -2\n",
      "in:  tensor([-30.4052])  out:  tensor([-0.4751])\n",
      "e_bits  1  m_bits  11  scale  0\n",
      "in:  tensor([-15.7082])  out:  tensor([-3.9268])\n",
      "e_bits  0  m_bits  19  scale  1\n",
      "in:  tensor([35.7526])  out:  tensor([2.2345])\n",
      "e_bits  2  m_bits  12  scale  0\n",
      "in:  tensor([1.0117])  out:  tensor([1.0115])\n",
      "e_bits  5  m_bits  14  scale  -2\n",
      "in:  tensor([-35.3635])  out:  tensor([-35.3633])\n",
      "e_bits  7  m_bits  27  scale  2\n",
      "in:  tensor([-38.6694])  out:  tensor([-38.6694])\n",
      "e_bits  9  m_bits  14  scale  -2\n",
      "in:  tensor([-37.0122])  out:  tensor([-37.0117])\n",
      "e_bits  1  m_bits  27  scale  0\n",
      "in:  tensor([-0.7182])  out:  tensor([-0.7182])\n",
      "e_bits  8  m_bits  5  scale  -2\n",
      "in:  tensor([-43.5583])  out:  tensor([-43.])\n",
      "e_bits  5  m_bits  25  scale  0\n",
      "in:  tensor([-23.0895])  out:  tensor([-23.0895])\n",
      "e_bits  0  m_bits  4  scale  -1\n",
      "in:  tensor([22.3775])  out:  tensor([0.6875])\n",
      "e_bits  8  m_bits  6  scale  1\n",
      "in:  tensor([-42.6934])  out:  tensor([-42.5000])\n",
      "e_bits  7  m_bits  17  scale  -1\n",
      "in:  tensor([-5.8233])  out:  tensor([-5.8233])\n",
      "e_bits  5  m_bits  15  scale  -2\n",
      "in:  tensor([-46.6758])  out:  tensor([-46.6758])\n",
      "e_bits  1  m_bits  17  scale  -1\n",
      "in:  tensor([-36.9648])  out:  tensor([-1.1551])\n",
      "e_bits  3  m_bits  19  scale  -2\n",
      "in:  tensor([0.2995])  out:  tensor([0.2995])\n",
      "e_bits  9  m_bits  7  scale  -2\n",
      "in:  tensor([-31.1223])  out:  tensor([-31.])\n",
      "e_bits  5  m_bits  7  scale  2\n",
      "in:  tensor([48.9618])  out:  tensor([48.7500])\n",
      "e_bits  4  m_bits  4  scale  2\n",
      "in:  tensor([-0.1473])  out:  tensor([-0.])\n",
      "e_bits  8  m_bits  6  scale  1\n",
      "in:  tensor([38.2821])  out:  tensor([38.])\n",
      "e_bits  1  m_bits  24  scale  -2\n",
      "in:  tensor([18.8443])  out:  tensor([0.5889])\n",
      "e_bits  5  m_bits  17  scale  -2\n",
      "in:  tensor([-3.0717])  out:  tensor([-3.0717])\n",
      "e_bits  7  m_bits  27  scale  1\n",
      "in:  tensor([26.7016])  out:  tensor([26.7016])\n",
      "e_bits  6  m_bits  11  scale  0\n",
      "in:  tensor([5.8557])  out:  tensor([5.8555])\n",
      "e_bits  5  m_bits  11  scale  -2\n",
      "in:  tensor([-48.0392])  out:  tensor([-48.0312])\n",
      "e_bits  0  m_bits  5  scale  1\n",
      "in:  tensor([9.2755])  out:  tensor([2.3125])\n",
      "e_bits  5  m_bits  20  scale  -1\n",
      "in:  tensor([-41.4692])  out:  tensor([-41.4692])\n",
      "e_bits  9  m_bits  15  scale  1\n",
      "in:  tensor([-49.8436])  out:  tensor([-49.8428])\n",
      "e_bits  8  m_bits  5  scale  1\n",
      "in:  tensor([35.6912])  out:  tensor([35.])\n",
      "e_bits  3  m_bits  10  scale  -2\n",
      "in:  tensor([37.7523])  out:  tensor([4.7188])\n",
      "e_bits  8  m_bits  28  scale  0\n",
      "in:  tensor([-29.8767])  out:  tensor([-29.8767])\n",
      "e_bits  1  m_bits  5  scale  0\n",
      "in:  tensor([23.5146])  out:  tensor([2.9375])\n",
      "e_bits  0  m_bits  28  scale  2\n",
      "in:  tensor([1.0182])  out:  tensor([1.0182])\n",
      "e_bits  4  m_bits  5  scale  0\n",
      "in:  tensor([8.1821])  out:  tensor([8.])\n",
      "e_bits  5  m_bits  22  scale  -2\n",
      "in:  tensor([46.7407])  out:  tensor([46.7407])\n",
      "e_bits  9  m_bits  13  scale  -1\n",
      "in:  tensor([2.7119])  out:  tensor([2.7117])\n",
      "e_bits  7  m_bits  2  scale  0\n",
      "in:  tensor([3.5127])  out:  tensor([3.5000])\n",
      "e_bits  6  m_bits  30  scale  0\n",
      "in:  tensor([-0.8288])  out:  tensor([-0.8288])\n",
      "e_bits  9  m_bits  29  scale  -2\n",
      "in:  tensor([11.8684])  out:  tensor([11.8684])\n",
      "e_bits  1  m_bits  30  scale  1\n",
      "in:  tensor([46.1073])  out:  tensor([5.7634])\n",
      "e_bits  6  m_bits  26  scale  0\n",
      "in:  tensor([17.0518])  out:  tensor([17.0518])\n",
      "e_bits  7  m_bits  11  scale  -1\n",
      "in:  tensor([-43.1550])  out:  tensor([-43.1406])\n",
      "e_bits  6  m_bits  22  scale  1\n",
      "in:  tensor([9.4747])  out:  tensor([9.4747])\n",
      "e_bits  4  m_bits  11  scale  2\n",
      "in:  tensor([-1.6854])  out:  tensor([-1.6836])\n",
      "e_bits  4  m_bits  24  scale  -1\n",
      "in:  tensor([49.3438])  out:  tensor([49.3438])\n",
      "e_bits  6  m_bits  4  scale  -2\n",
      "in:  tensor([-47.3463])  out:  tensor([-46.])\n",
      "e_bits  4  m_bits  8  scale  2\n",
      "in:  tensor([-29.4081])  out:  tensor([-29.3750])\n",
      "e_bits  2  m_bits  17  scale  1\n",
      "in:  tensor([20.3933])  out:  tensor([10.1966])\n",
      "e_bits  7  m_bits  16  scale  -2\n",
      "in:  tensor([-25.3940])  out:  tensor([-25.3938])\n",
      "e_bits  3  m_bits  26  scale  -2\n",
      "in:  tensor([23.3282])  out:  tensor([5.8320])\n",
      "e_bits  5  m_bits  19  scale  0\n",
      "in:  tensor([22.0795])  out:  tensor([22.0794])\n",
      "e_bits  3  m_bits  23  scale  -2\n",
      "in:  tensor([5.2651])  out:  tensor([5.2651])\n",
      "e_bits  1  m_bits  27  scale  -1\n",
      "in:  tensor([-21.2306])  out:  tensor([-1.3269])\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    in_test = (torch.rand(1) - 0.5)*100.0\n",
    "    e_bits = int(torch.round(torch.rand(1)*10).item())\n",
    "    m_bits = int(torch.round(torch.rand(1)*30).item())\n",
    "    scale = int(torch.round((torch.rand(1) - 0.5)*5.0).item())\n",
    "    out_test = fake_float_truncate(in_test, e_bits, m_bits, scale)\n",
    "    print(\"e_bits \", e_bits, \" m_bits \", m_bits, \" scale \", scale)\n",
    "    print(\"in: \", in_test, \" out: \", out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_fixed_truncate2(x: torch.Tensor, bits_int: int, scale_int: int, zero_point_int: int) -> torch.Tensor:\n",
    "    \n",
    "    qmin = 0\n",
    "    qmax = 2**bits_int - 1\n",
    "    \n",
    "    #from float to fixed point, and quantize accordingly\n",
    "    q_x = torch.clamp(torch.round(x * 2**(scale_int + bits_int//2) + 2**(bits_int-1) + zero_point_int), qmin, qmax)\n",
    "\n",
    "    # from quantized fixed point to float\n",
    "    fq_x = (q_x - 2**(bits_int-1) - zero_point_int) / 2**(scale_int + bits_int//2)\n",
    "        \n",
    "    return fq_x\n",
    "\n",
    "def fake_fixed_truncate(x: torch.Tensor, bits_int: int, scale_int: int, zero_point_int: int) -> torch.Tensor:\n",
    "    \n",
    "    qmin = 0\n",
    "    qmax = 2**bits_int - 1\n",
    "    \n",
    "    mantissa = x * 2**(scale_int + bits_int//2) + zero_point_int + 2**(bits_int-1)\n",
    "    \n",
    "    #from float to fixed point, and quantize accordingly\n",
    "    q_x = torch.clamp(torch.round(mantissa), qmin, qmax)\n",
    "\n",
    "    # from quantized fixed point to float\n",
    "    fq_x = (q_x - 2**(bits_int-1) - zero_point_int) / 2**(scale_int + bits_int//2)\n",
    "        \n",
    "    return fq_x\n",
    "\n",
    "class FakeFixedFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd for 'fake-float' exponent+mantissa truncation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, bits_param, scale_param, zero_point_param):\n",
    "        \n",
    "        # save for backward\n",
    "        ctx.save_for_backward(x, bits_param, scale_param, zero_point_param)\n",
    "        \n",
    "        # Round e_bits, m_bits to nearest integer for the forward pass\n",
    "        bits_int = int(torch.round(param_to_bit(bits_param)).item())\n",
    "        scale_int = int(torch.round(scale_param).item())\n",
    "        zero_point_int = int(torch.round(zero_point_param).item())\n",
    "\n",
    "        out = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int)\n",
    "        \n",
    "        #print(\"input\")\n",
    "        #print(x)\n",
    "        #print(\"output\")\n",
    "        #print(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, bits_param, scale_param, zero_point_param = ctx.saved_tensors\n",
    "        \n",
    "        bits = param_to_bit(bits_param)\n",
    "        scale = scale_param\n",
    "        zero_point = zero_point_param\n",
    "                \n",
    "        bits_int = int(torch.round(bits).item())\n",
    "        scale_int = int(torch.round(scale).item())\n",
    "        zero_point_int = int(torch.round(zero_point).item())\n",
    "\n",
    "        #print(\"shape x: \", x.shape)\n",
    "        #print(\"shape grad_output: \", grad_output.shape)\n",
    "\n",
    "        # 1) Gradient wrt x: straight-through\n",
    "        grad_x = grad_output\n",
    "        \n",
    "        # 1) Gradient wrt x: approximate with central difference\n",
    "        \"\"\"\n",
    "        grad_x = None\n",
    "        if True:\n",
    "            delta = 0.01            \n",
    "\n",
    "            f_plus2  = fake_float_truncate(x + 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_plus   = fake_float_truncate(x + 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus  = fake_float_truncate(x - 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus2 = fake_float_truncate(x - 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "        \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "            grad_x = grad_output * der\n",
    "        \"\"\"\n",
    "                \n",
    "        # 2) Gradient wrt bits: approximate with central difference\n",
    "        grad_bits = None\n",
    "        if bits_param.requires_grad:\n",
    "            if(bits_int < 2):\n",
    "                f_plus   = fake_fixed_truncate(x, bits_int + 1, scale_int, zero_point_int)\n",
    "                f_minus  = fake_fixed_truncate(x, bits_int    , scale_int, zero_point_int)\n",
    "                der = (f_plus - f_minus)\n",
    "            else:\n",
    "                f_plus2  = fake_fixed_truncate(x, bits_int + 2, scale_int, zero_point_int)\n",
    "                f_plus   = fake_fixed_truncate(x, bits_int + 1, scale_int, zero_point_int)\n",
    "                f_minus  = fake_fixed_truncate(x, bits_int - 1, scale_int, zero_point_int)\n",
    "                f_minus2 = fake_fixed_truncate(x, bits_int - 2, scale_int, zero_point_int)\n",
    "            \n",
    "                der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_bits = grad_output * der * bits\n",
    "        \n",
    "        # 3) Gradient wrt scale: approximate with central difference\n",
    "        grad_scale_bits = None\n",
    "        if scale_param.requires_grad:\n",
    "            \n",
    "            f_plus2  = fake_fixed_truncate(x, bits_int, scale_int + 2, zero_point_int)\n",
    "            f_plus   = fake_fixed_truncate(x, bits_int, scale_int + 1, zero_point_int)\n",
    "            f_minus  = fake_fixed_truncate(x, bits_int, scale_int - 1, zero_point_int)\n",
    "            f_minus2 = fake_fixed_truncate(x, bits_int, scale_int - 2, zero_point_int)\n",
    "        \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_scale_bits = grad_output * der\n",
    "       \n",
    "        # 4) Gradient wrt m_bits: approximate with central difference\n",
    "        grad_zero_point_bits = None\n",
    "        if zero_point_param.requires_grad:\n",
    "            \n",
    "            f_plus2  = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int + 2)\n",
    "            f_plus   = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int + 1)\n",
    "            f_minus  = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int - 1)\n",
    "            f_minus2 = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int - 2)\n",
    "            \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0 \n",
    "            grad_zero_point_bits = grad_output * der\n",
    "             \n",
    "        return grad_x, grad_bits, grad_scale_bits, grad_zero_point_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bits  15  scale  2  zero_point  0\n",
      "in:  tensor([-29.9284])  out  tensor([-29.9277])\n",
      "bits  14  scale  2  zero_point  0\n",
      "in:  tensor([-31.5267])  out  tensor([-16.])\n",
      "bits  6  scale  -1  zero_point  0\n",
      "in:  tensor([41.5015])  out  tensor([7.7500])\n",
      "bits  3  scale  1  zero_point  0\n",
      "in:  tensor([-47.0128])  out  tensor([-1.])\n",
      "bits  14  scale  2  zero_point  0\n",
      "in:  tensor([9.4887])  out  tensor([9.4883])\n",
      "bits  24  scale  0  zero_point  0\n",
      "in:  tensor([26.7965])  out  tensor([26.7966])\n",
      "bits  7  scale  1  zero_point  0\n",
      "in:  tensor([7.8182])  out  tensor([3.9375])\n",
      "bits  5  scale  2  zero_point  0\n",
      "in:  tensor([-41.6897])  out  tensor([-1.])\n",
      "bits  3  scale  1  zero_point  0\n",
      "in:  tensor([-34.3668])  out  tensor([-1.])\n",
      "bits  1  scale  0  zero_point  0\n",
      "in:  tensor([-15.8550])  out  tensor([-1.])\n",
      "bits  14  scale  -2  zero_point  0\n",
      "in:  tensor([-21.0217])  out  tensor([-21.0312])\n",
      "bits  21  scale  -2  zero_point  0\n",
      "in:  tensor([-40.6223])  out  tensor([-40.6211])\n",
      "bits  29  scale  -1  zero_point  0\n",
      "in:  tensor([38.0890])  out  tensor([38.0898])\n",
      "bits  30  scale  0  zero_point  0\n",
      "in:  tensor([27.3816])  out  tensor([27.3809])\n",
      "bits  20  scale  2  zero_point  0\n",
      "in:  tensor([20.4316])  out  tensor([20.4316])\n",
      "bits  25  scale  0  zero_point  0\n",
      "in:  tensor([-2.5146])  out  tensor([-2.5146])\n",
      "bits  32  scale  2  zero_point  0\n",
      "in:  tensor([44.5961])  out  tensor([44.5957])\n",
      "bits  20  scale  0  zero_point  0\n",
      "in:  tensor([-22.2721])  out  tensor([-22.2725])\n",
      "bits  27  scale  -1  zero_point  0\n",
      "in:  tensor([-9.4386])  out  tensor([-9.4385])\n",
      "bits  26  scale  1  zero_point  0\n",
      "in:  tensor([7.6714])  out  tensor([7.6714])\n",
      "bits  8  scale  0  zero_point  0\n",
      "in:  tensor([21.4444])  out  tensor([7.9375])\n",
      "bits  7  scale  1  zero_point  0\n",
      "in:  tensor([-37.1492])  out  tensor([-4.])\n",
      "bits  22  scale  -2  zero_point  0\n",
      "in:  tensor([-39.7986])  out  tensor([-39.7988])\n",
      "bits  17  scale  0  zero_point  0\n",
      "in:  tensor([8.5889])  out  tensor([8.5898])\n",
      "bits  2  scale  2  zero_point  0\n",
      "in:  tensor([20.5266])  out  tensor([0.1250])\n",
      "bits  7  scale  -1  zero_point  0\n",
      "in:  tensor([5.9453])  out  tensor([6.])\n",
      "bits  12  scale  -2  zero_point  0\n",
      "in:  tensor([37.9107])  out  tensor([37.9375])\n",
      "bits  16  scale  -2  zero_point  0\n",
      "in:  tensor([20.0197])  out  tensor([20.0156])\n",
      "bits  21  scale  -2  zero_point  0\n",
      "in:  tensor([37.2384])  out  tensor([37.2383])\n",
      "bits  23  scale  2  zero_point  0\n",
      "in:  tensor([41.0401])  out  tensor([41.0400])\n",
      "bits  9  scale  0  zero_point  0\n",
      "in:  tensor([-12.5397])  out  tensor([-12.5625])\n",
      "bits  24  scale  2  zero_point  0\n",
      "in:  tensor([-20.6693])  out  tensor([-20.6693])\n",
      "bits  13  scale  -1  zero_point  0\n",
      "in:  tensor([-13.3797])  out  tensor([-13.3750])\n",
      "bits  13  scale  1  zero_point  0\n",
      "in:  tensor([-35.5894])  out  tensor([-32.])\n",
      "bits  13  scale  -1  zero_point  0\n",
      "in:  tensor([-38.3229])  out  tensor([-38.3125])\n",
      "bits  28  scale  -1  zero_point  0\n",
      "in:  tensor([-5.7167])  out  tensor([-5.7168])\n",
      "bits  31  scale  -2  zero_point  0\n",
      "in:  tensor([17.1468])  out  tensor([17.1406])\n",
      "bits  7  scale  -1  zero_point  0\n",
      "in:  tensor([33.3796])  out  tensor([15.7500])\n",
      "bits  7  scale  -1  zero_point  0\n",
      "in:  tensor([-30.9807])  out  tensor([-16.])\n",
      "bits  20  scale  2  zero_point  0\n",
      "in:  tensor([-14.5793])  out  tensor([-14.5793])\n",
      "bits  9  scale  -1  zero_point  0\n",
      "in:  tensor([-49.1589])  out  tensor([-32.])\n",
      "bits  3  scale  -2  zero_point  0\n",
      "in:  tensor([25.4185])  out  tensor([6.])\n",
      "bits  15  scale  0  zero_point  0\n",
      "in:  tensor([-35.5642])  out  tensor([-35.5625])\n",
      "bits  3  scale  -1  zero_point  0\n",
      "in:  tensor([11.6339])  out  tensor([3.])\n",
      "bits  1  scale  -2  zero_point  0\n",
      "in:  tensor([32.2147])  out  tensor([0.])\n",
      "bits  6  scale  2  zero_point  0\n",
      "in:  tensor([-6.0455])  out  tensor([-1.])\n",
      "bits  27  scale  -2  zero_point  0\n",
      "in:  tensor([-34.6475])  out  tensor([-34.6484])\n",
      "bits  20  scale  -2  zero_point  0\n",
      "in:  tensor([-15.3122])  out  tensor([-15.3125])\n",
      "bits  21  scale  -2  zero_point  0\n",
      "in:  tensor([-36.5962])  out  tensor([-36.5977])\n",
      "bits  12  scale  -1  zero_point  0\n",
      "in:  tensor([49.5699])  out  tensor([49.5625])\n",
      "bits  31  scale  0  zero_point  0\n",
      "in:  tensor([-26.5971])  out  tensor([-26.5977])\n",
      "bits  18  scale  -1  zero_point  0\n",
      "in:  tensor([10.8755])  out  tensor([10.8750])\n",
      "bits  11  scale  1  zero_point  0\n",
      "in:  tensor([4.0657])  out  tensor([4.0625])\n",
      "bits  23  scale  1  zero_point  0\n",
      "in:  tensor([46.3211])  out  tensor([46.3210])\n",
      "bits  24  scale  -1  zero_point  0\n",
      "in:  tensor([26.2664])  out  tensor([26.2666])\n",
      "bits  18  scale  1  zero_point  0\n",
      "in:  tensor([-21.6412])  out  tensor([-21.6416])\n",
      "bits  22  scale  -2  zero_point  0\n",
      "in:  tensor([-26.9352])  out  tensor([-26.9355])\n",
      "bits  17  scale  0  zero_point  0\n",
      "in:  tensor([38.8327])  out  tensor([38.8320])\n",
      "bits  18  scale  -2  zero_point  0\n",
      "in:  tensor([-39.5688])  out  tensor([-39.5703])\n",
      "bits  22  scale  -2  zero_point  0\n",
      "in:  tensor([24.7764])  out  tensor([24.7773])\n",
      "bits  15  scale  -2  zero_point  0\n",
      "in:  tensor([-46.6678])  out  tensor([-46.6562])\n",
      "bits  3  scale  1  zero_point  0\n",
      "in:  tensor([-39.8887])  out  tensor([-1.])\n",
      "bits  12  scale  0  zero_point  0\n",
      "in:  tensor([47.4798])  out  tensor([31.9844])\n",
      "bits  18  scale  -2  zero_point  0\n",
      "in:  tensor([-44.3885])  out  tensor([-44.3906])\n",
      "bits  22  scale  -1  zero_point  0\n",
      "in:  tensor([-46.7784])  out  tensor([-46.7783])\n",
      "bits  3  scale  1  zero_point  0\n",
      "in:  tensor([6.6785])  out  tensor([0.7500])\n",
      "bits  23  scale  2  zero_point  0\n",
      "in:  tensor([-27.5169])  out  tensor([-27.5168])\n",
      "bits  17  scale  -1  zero_point  0\n",
      "in:  tensor([4.3959])  out  tensor([4.3984])\n",
      "bits  17  scale  1  zero_point  0\n",
      "in:  tensor([28.6092])  out  tensor([28.6094])\n",
      "bits  22  scale  -2  zero_point  0\n",
      "in:  tensor([3.4572])  out  tensor([3.4570])\n",
      "bits  18  scale  1  zero_point  0\n",
      "in:  tensor([5.9321])  out  tensor([5.9316])\n",
      "bits  16  scale  0  zero_point  0\n",
      "in:  tensor([-8.2650])  out  tensor([-8.2656])\n",
      "bits  18  scale  1  zero_point  0\n",
      "in:  tensor([-36.0163])  out  tensor([-36.0166])\n",
      "bits  12  scale  1  zero_point  0\n",
      "in:  tensor([24.8438])  out  tensor([15.9922])\n",
      "bits  20  scale  2  zero_point  0\n",
      "in:  tensor([48.5379])  out  tensor([48.5378])\n",
      "bits  14  scale  2  zero_point  0\n",
      "in:  tensor([-0.6941])  out  tensor([-0.6934])\n",
      "bits  4  scale  -2  zero_point  0\n",
      "in:  tensor([42.5066])  out  tensor([7.])\n",
      "bits  1  scale  2  zero_point  0\n",
      "in:  tensor([-4.6936])  out  tensor([-0.2500])\n",
      "bits  14  scale  -1  zero_point  0\n",
      "in:  tensor([-9.7332])  out  tensor([-9.7344])\n",
      "bits  5  scale  1  zero_point  0\n",
      "in:  tensor([44.9814])  out  tensor([1.8750])\n",
      "bits  3  scale  1  zero_point  0\n",
      "in:  tensor([13.8967])  out  tensor([0.7500])\n",
      "bits  24  scale  1  zero_point  0\n",
      "in:  tensor([-16.0733])  out  tensor([-16.0732])\n",
      "bits  9  scale  0  zero_point  0\n",
      "in:  tensor([-38.8928])  out  tensor([-16.])\n",
      "bits  14  scale  -2  zero_point  0\n",
      "in:  tensor([13.2944])  out  tensor([13.2812])\n",
      "bits  7  scale  -2  zero_point  0\n",
      "in:  tensor([-38.6295])  out  tensor([-32.])\n",
      "bits  20  scale  -2  zero_point  0\n",
      "in:  tensor([-32.7226])  out  tensor([-32.7227])\n",
      "bits  3  scale  1  zero_point  0\n",
      "in:  tensor([18.2890])  out  tensor([0.7500])\n",
      "bits  27  scale  -2  zero_point  0\n",
      "in:  tensor([22.3297])  out  tensor([22.3281])\n",
      "bits  10  scale  -1  zero_point  0\n",
      "in:  tensor([-22.4287])  out  tensor([-22.4375])\n",
      "bits  27  scale  2  zero_point  0\n",
      "in:  tensor([38.6856])  out  tensor([38.6855])\n",
      "bits  1  scale  1  zero_point  0\n",
      "in:  tensor([-44.2569])  out  tensor([-0.5000])\n",
      "bits  20  scale  0  zero_point  0\n",
      "in:  tensor([25.6238])  out  tensor([25.6240])\n",
      "bits  5  scale  2  zero_point  0\n",
      "in:  tensor([48.4008])  out  tensor([0.9375])\n",
      "bits  26  scale  -1  zero_point  0\n",
      "in:  tensor([36.7339])  out  tensor([36.7344])\n",
      "bits  27  scale  1  zero_point  0\n",
      "in:  tensor([-44.4555])  out  tensor([-44.4556])\n",
      "bits  30  scale  1  zero_point  0\n",
      "in:  tensor([46.7690])  out  tensor([46.7686])\n",
      "bits  20  scale  -2  zero_point  0\n",
      "in:  tensor([9.9812])  out  tensor([9.9805])\n",
      "bits  19  scale  -1  zero_point  0\n",
      "in:  tensor([37.6428])  out  tensor([37.6445])\n",
      "bits  16  scale  1  zero_point  0\n",
      "in:  tensor([-35.1475])  out  tensor([-35.1484])\n",
      "bits  5  scale  -2  zero_point  0\n",
      "in:  tensor([5.3595])  out  tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    bits = int(torch.round(torch.rand(1)*32).item())\n",
    "    scale = int(torch.round((torch.rand(1) - 0.5)*5.0).item())\n",
    "    zero_point = int(torch.round((torch.rand(1) - 0.5)*0.0).item())\n",
    "    in_test = (torch.rand(1)-0.5)*100.0\n",
    "    out_test = fake_fixed_truncate(in_test, bits, scale, zero_point)\n",
    "    print(\"bits \", bits, \" scale \", scale, \" zero_point \", zero_point)\n",
    "    print(\"in: \", in_test, \" out \", out_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### differentiable Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundSTE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass: use the usual rounding\n",
    "        return torch.round(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass: pass the gradient unchanged (STE)\n",
    "        return grad_output\n",
    "    \n",
    "class RoundFDE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass: use the usual rounding\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.round(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass: pass the gradient unchanged (STE)\n",
    "        (input, ) = ctx.saved_tensors\n",
    "        delta = 1.0\n",
    "        f_plus2  = torch.round(input + 2*delta)\n",
    "        f_plus   = torch.round(input + 1*delta)\n",
    "        f_minus  = torch.round(input - 1*delta)\n",
    "        f_minus2 = torch.round(input - 2*delta)\n",
    "        # der = (f_plus - f_minus)/2.0\n",
    "        der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "        \n",
    "        return der * grad_output\n",
    "\n",
    "class RoundSIG(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd function that does a hard round in forward,\n",
    "    but uses a sigmoid-based approximation for the backward pass.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, alpha=10.0):\n",
    "        \"\"\"\n",
    "        Forward pass: returns torch.round(input).\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.alpha = alpha\n",
    "        return torch.round(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Backward pass: approximate the gradient of round(x)\n",
    "        with the derivative of a sigmoid centered at the fractional midpoint (0.5).\n",
    "        \"\"\"\n",
    "        (input,) = ctx.saved_tensors\n",
    "        alpha = ctx.alpha\n",
    "\n",
    "        # Fractional part\n",
    "        frac = input - torch.floor(input)\n",
    "\n",
    "        # Sigmoid of (fractional_part - 0.5), scaled by alpha\n",
    "        s = torch.sigmoid(alpha * (frac - 0.5))\n",
    "\n",
    "        # Derivative of sigmoid = alpha * s * (1 - s)\n",
    "        grad_input = alpha * s * (1 - s) * grad_output\n",
    "        return grad_input, None  # alpha is not a tensor that requires grad\n",
    "    \n",
    "def diff_round(x):\n",
    "    return RoundSTE.apply(x)\n",
    "    #return RoundFDE.apply(x)\n",
    "    #return RoundSIG.apply(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloorSTE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass uses standard floor\n",
    "        return torch.floor(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Straight-through pass: just return the gradient as-is\n",
    "        return grad_output\n",
    "\n",
    "class FloorFDE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass: use the usual rounding\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.floor(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass: pass the gradient unchanged (STE)\n",
    "        (input, ) = ctx.saved_tensors\n",
    "        delta = 1.0\n",
    "        f_plus2  = torch.floor(input + 2*delta)\n",
    "        f_plus   = torch.floor(input + 1*delta)\n",
    "        f_minus  = torch.floor(input - 1*delta)\n",
    "        f_minus2 = torch.floor(input - 2*delta)\n",
    "        # der = (f_plus - f_minus)/2.0\n",
    "        der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "        \n",
    "        return der * grad_output\n",
    "\n",
    "def diff_floor(input):\n",
    "    return FloorSTE.apply(input)\n",
    "    #return FloorFDE.apply(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxObserver(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We store running min/max\n",
    "        self.register_buffer(\"min_val\", torch.tensor(float(\"inf\")))\n",
    "        self.register_buffer(\"max_val\", torch.tensor(float(\"-inf\")))\n",
    "        # You could also store averaging stats, etc.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Update running min/max\n",
    "        self.min_val = torch.min(self.min_val, x.detach().min())\n",
    "        self.max_val = torch.max(self.max_val, x.detach().max())\n",
    "        return x  # Just pass through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed point quanizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPointFakeQuantize(nn.Module):\n",
    "    def __init__(self, observer, bits=32, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.observer = observer\n",
    "        self.bits = nn.Parameter(torch.tensor(float(bits)), requires_grad=requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        b_int = torch.clamp(diff_round(self.bits), 1, 32)\n",
    "        \n",
    "        # 1) Get min/max from observer\n",
    "        min_val = self.observer.min_val\n",
    "        max_val = self.observer.max_val\n",
    "\n",
    "        # If they're not valid, skip\n",
    "        #if min_val >= max_val:\n",
    "        #    return x\n",
    "\n",
    "        # 2) Compute scale and zero_point\n",
    "        # For an unsigned 4-bit range, we can hold values 0..15\n",
    "        # qmin, qmax = 0, (1 << b_int) - 1  # e.g. 0..15\n",
    "        qmin, qmax = torch.tensor(float(0)), 2**b_int - 1  # e.g. 0..15\n",
    "        \n",
    "        qmin = qmin.to(x.device)\n",
    "        #qmax = qmax.to(x.device)\n",
    "        max_val = max_val.to(x.device)\n",
    "        min_val = min_val.to(x.device)\n",
    "\n",
    "        # Typical formula for scale/zero-point:\n",
    "        scale = (max_val - min_val) / float(qmax - qmin)\n",
    "        zero_point = qmin - diff_round(min_val / scale)\n",
    "\n",
    "        # 3) Quantize (in floating point)\n",
    "        # clamp to range of [qmin, qmax]\n",
    "        q_x = torch.clamp(diff_round(x / scale + zero_point), qmin, qmax)\n",
    "\n",
    "        # 4) Dequantize back to float\n",
    "        fq_x = (q_x - zero_point) * scale\n",
    "        return fq_x\n",
    "\n",
    "    def getBits(self):\n",
    "        return [self.bits]\n",
    "\n",
    "    def printParams(self):\n",
    "        print(\"bits: \", self.bits.detach().item())\n",
    "        \n",
    "class FixedPointFakeQuantize2(nn.Module):\n",
    "    def __init__(self, bits=32, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.bits = nn.Parameter(torch.tensor(float(bits)), requires_grad=requires_grad)\n",
    "        self.scale = nn.Parameter(torch.tensor(float(bits//2)), requires_grad=requires_grad)\n",
    "        self.zero_point = nn.Parameter(torch.tensor(float(2**(bits//2-1)-1)), requires_grad=requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        bits_int = torch.clamp(diff_round(self.bits), 1, 32)\n",
    "        scale_int = diff_round(self.scale)\n",
    "        zero_point_int = diff_round(self.zero_point)\n",
    "        \n",
    "        qmin = torch.tensor(float(0)).to(x.device)\n",
    "        qmax = 2**bits_int - 1  # e.g. 0..15\n",
    "        \n",
    "        #from float to fixed point, and quantize accordingly\n",
    "        q_x = torch.clamp(diff_round(x * 2**scale_int + zero_point_int), qmin, qmax)\n",
    "\n",
    "        # from quantized fixed point to float\n",
    "        fq_x = (q_x - zero_point_int) / 2**scale_int\n",
    "        \n",
    "        return fq_x\n",
    "\n",
    "    def getBits(self):\n",
    "        return [self.bits]\n",
    "\n",
    "    def printParams(self):\n",
    "        print(\"bits: \", self.bits.detach().item())\n",
    "        print(\"scale: \", self.scale.detach().item())\n",
    "        print(\"zero point: \", self.zero_point.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point quantizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloatingPointFakeQuantize(nn.Module):\n",
    "    def __init__(self, m_bits=23, e_bits=8, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.e_bits = nn.Parameter(torch.tensor(float(e_bits)), requires_grad=requires_grad)\n",
    "        self.m_bits = nn.Parameter(torch.tensor(float(m_bits)), requires_grad=requires_grad)\n",
    "        self.scale = nn.Parameter(torch.tensor(float(0)), requires_grad=requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e_bits_int = torch.clamp(diff_round(self.e_bits), 0, 32)\n",
    "        m_bits_int = torch.clamp(diff_round(self.m_bits), 1, 32)\n",
    "        scale_int = diff_round(self.scale)\n",
    "        \n",
    "        sign = x.sign()\n",
    "        abs_x = x.abs().clamp(min=1e-45)\n",
    "\n",
    "        #recover the floatint point representation\n",
    "        #exponent \\in {-2**7,..,2**7-1}\n",
    "        #mantissa \\in {1.0,...,2.0}\n",
    "\n",
    "        exponent = diff_floor(torch.log2(abs_x)).clamp(min=1e-45)\n",
    "        mantissa = abs_x / (2**exponent)\n",
    "    \n",
    "        # truncate exponent\n",
    "        # lets parameterize the exponent as a constant value + a variable value\n",
    "        # the constant part is 2**7-1 in standar floating point, but we will learn it\n",
    "        # the variable part \\in {0,..,2**8-1}\n",
    "        # lets say exponent = v_exponent - 2**(bits-1)-1 + c_exponent\n",
    "        # so v_exponent = exponent + 2**(bits-1)-1 - c_exponent\n",
    "        c_exponent = scale_int\n",
    "        v_exponent = exponent + (2**(e_bits_int-1)-1) - c_exponent\n",
    "        \n",
    "        # the valriable part is clamped to the alloted bits\n",
    "        q_min = torch.tensor(float(0)).to(x.device)\n",
    "        q_max = 2**e_bits_int-1\n",
    "        q_exponent = torch.clamp(v_exponent, q_min, q_max) - (2**(e_bits_int-1)-1) + c_exponent\n",
    "    \n",
    "        # truncate mantissa\n",
    "        # this just removes the less significant bits\n",
    "        m_scale = 2.0 ** m_bits_int\n",
    "        q_mantissa = diff_floor(mantissa * m_scale) / m_scale\n",
    "    \n",
    "        # from quantized floatint point to float\n",
    "        fq_x = sign * (2**q_exponent) * q_mantissa\n",
    "        return fq_x\n",
    "\n",
    "    def getBits(self):\n",
    "        return [self.e_bits, self.m_bits]\n",
    "\n",
    "    def printParams(self):\n",
    "        print(\"e_bits: \", self.e_bits.detach().item())\n",
    "        print(\"m_bits: \", self.m_bits.detach().item())\n",
    "        print(\"scale: \", self.scale.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float32 example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCIFAR10Model(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size[0], 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * input_size[1]//8 * input_size[2]//8, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantWrapper(nn.Module):\n",
    "    def __init__(self, module, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.observer = MinMaxObserver()\n",
    "        self.fake_quant_input = FixedPointFakeQuantize(self.observer, requires_grad=optimizeQuant)\n",
    "        self.fake_quant_weight = FixedPointFakeQuantize(self.observer, requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_input = FixedPointFakeQuantize2(requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_weight = FixedPointFakeQuantize2(requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_input = FloatingPointFakeQuantize(requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_weight = FloatingPointFakeQuantize(requires_grad=optimizeQuant)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.observer(x)\n",
    "        x = self.fake_quant_input(x)\n",
    "        w = self.fake_quant_weight(self.module.weight)\n",
    "        b = self.module.bias\n",
    "        if isinstance(self.module, nn.Conv2d):\n",
    "            return F.conv2d(x, w, b, stride=self.module.stride, padding=self.module.padding, dilation=self.module.dilation, groups=self.module.groups)\n",
    "        elif isinstance(self.module, nn.Linear):\n",
    "            return F.linear(x, w, b)\n",
    "        else:\n",
    "            return self.module(x)\n",
    "        \n",
    "    def getBits(self):\n",
    "        return self.fake_quant_input.getBits() + self.fake_quant_weight.getBits()\n",
    "        #return self.fake_quant_weight.getBits()\n",
    "    \n",
    "    def printQuantParams(self):\n",
    "        print(\"input quant params: \")\n",
    "        self.fake_quant_input.printParams()\n",
    "        print(\"weight quant params: \")\n",
    "        self.fake_quant_weight.printParams()\n",
    "\n",
    "class QuantWrapperFloatingPoint(nn.Module):\n",
    "    def __init__(self, module, e_bits=5, m_bits=10, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "        self.input_e_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(e_bits))), requires_grad=optimizeQuant)\n",
    "        self.input_m_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(m_bits))), requires_grad=optimizeQuant)\n",
    "        self.input_scale = nn.Parameter(torch.tensor(0.0), requires_grad=optimizeQuant)\n",
    "        self.weight_e_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(e_bits))), requires_grad=optimizeQuant)\n",
    "        self.weight_m_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(m_bits))), requires_grad=optimizeQuant)\n",
    "        self.weight_scale = nn.Parameter(torch.tensor(0.0), requires_grad=optimizeQuant)\n",
    "         \n",
    "    def forward(self, x):\n",
    "        x = FakeFloatFunction.apply(x,   self.input_e_bits_param, self.input_m_bits_param, self.input_scale)\n",
    "        w = FakeFloatFunction.apply(self.module.weight, self.weight_e_bits_param, self.weight_m_bits_param, self.weight_scale)\n",
    "        \n",
    "        b = self.module.bias\n",
    "        if isinstance(self.module, nn.Conv2d):\n",
    "            return F.conv2d(x, w, b, stride=self.module.stride, padding=self.module.padding, dilation=self.module.dilation, groups=self.module.groups)\n",
    "        elif isinstance(self.module, nn.Linear):\n",
    "            return F.linear(x, w, b)\n",
    "        else:\n",
    "            return self.module(x)\n",
    "        \n",
    "    def getBits(self):\n",
    "        return [param_to_bit(self.input_e_bits_param) + param_to_bit(self.input_m_bits_param) + 1, param_to_bit(self.weight_e_bits_param) + param_to_bit(self.weight_m_bits_param) + 1]\n",
    "\n",
    "    def printQuantParams(self):\n",
    "        print(\"input quant params: \")\n",
    "        print(\"e bits: \", param_to_bit(self.input_e_bits_param).detach().item(), \" m bits \", param_to_bit(self.input_m_bits_param).detach().item(), \" scale \", self.input_scale.detach().item())\n",
    "        print(\"weight quant params: \")\n",
    "        print(\"e bits \", param_to_bit(self.weight_e_bits_param).detach().item(), \" m bits \", param_to_bit(self.weight_m_bits_param).detach().item(), \" scale \", self.weight_scale.detach().item())\n",
    "\n",
    "class QuantWrapperFixedPoint(nn.Module):\n",
    "    def __init__(self, module, bits=32, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "        self.input_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(bits))), requires_grad=optimizeQuant)\n",
    "        self.input_scale = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        self.input_zero_point = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        self.weight_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(bits))), requires_grad=optimizeQuant)\n",
    "        self.weight_scale = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        self.weight_zero_point = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = FakeFixedFunction.apply(x, self.input_bits_param, self.input_scale, self.input_zero_point)\n",
    "        w = FakeFixedFunction.apply(self.module.weight, self.weight_bits_param, self.weight_scale, self.weight_zero_point)\n",
    "        \n",
    "        b = self.module.bias\n",
    "        if isinstance(self.module, nn.Conv2d):\n",
    "            return F.conv2d(x, w, b, stride=self.module.stride, padding=self.module.padding, dilation=self.module.dilation, groups=self.module.groups)\n",
    "        elif isinstance(self.module, nn.Linear):\n",
    "            return F.linear(x, w, b)\n",
    "        else:\n",
    "            return self.module(x)\n",
    "        \n",
    "    def getBits(self):\n",
    "        return [param_to_bit(self.input_bits_param), param_to_bit(self.weight_bits_param)]\n",
    "\n",
    "    def printQuantParams(self):\n",
    "        print(\"input quant params: \")\n",
    "        print(\"bits: \", param_to_bit(self.input_bits_param).detach().item(), \" scale \", self.input_scale.detach().item(), \" zero point \", self.input_zero_point.detach().item())\n",
    "        print(\"weight quant params: \")\n",
    "        print(\"bits: \", param_to_bit(self.weight_bits_param).detach().item(), \" scale \", self.weight_scale.detach().item(), \" zero point \", self.weight_zero_point.detach().item())\n",
    "\n",
    "class QuantSimpleCIFAR10Model(nn.Module):\n",
    "    def __init__(self, num_classes=10, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.conv1 = QuantWrapperFloatingPoint(nn.Conv2d(input_size[0], 64, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = QuantWrapperFloatingPoint(nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = QuantWrapperFloatingPoint(nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = QuantWrapperFloatingPoint(nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv5 = QuantWrapperFloatingPoint(nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = QuantWrapperFloatingPoint(nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.fc7 = QuantWrapperFloatingPoint(nn.Linear(256 * input_size[1]//4 * input_size[2]//4, 512), optimizeQuant=optimizeQuant)\n",
    "        self.bn7 = nn.BatchNorm1d(512)\n",
    "        self.fc8 = QuantWrapperFloatingPoint(nn.Linear(512, 512), optimizeQuant=optimizeQuant)\n",
    "        self.bn8 = nn.BatchNorm1d(512)\n",
    "        self.fc9 = QuantWrapperFloatingPoint(nn.Linear(512, num_classes), optimizeQuant=optimizeQuant)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc8(x)\n",
    "        x = self.bn8(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class squared_hinge_loss(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, predictions, targets):\n",
    "        ctx.save_for_backward(predictions, targets)\n",
    "        output = 1. - predictions.mul(targets)\n",
    "        output[output.le(0.)] = 0.\n",
    "        loss = torch.mean(output.mul(output))\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        predictions, targets = ctx.saved_tensors\n",
    "        output = 1. - predictions.mul(targets)\n",
    "        output[output.le(0.)] = 0.\n",
    "        grad_output.resize_as_(predictions).copy_(targets).mul_(-2.).mul_(output)\n",
    "        grad_output.mul_(output.ne(0).float())\n",
    "        grad_output.div_(predictions.numel())\n",
    "        return grad_output, None\n",
    "\n",
    "\n",
    "class SqrHingeLoss(nn.Module):\n",
    "    # Squared Hinge Loss\n",
    "    def __init__(self):\n",
    "        super(SqrHingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return squared_hinge_loss.apply(input, target)\n",
    "    \n",
    "def label_smoothing_loss(pred, target, smoothing=0.1):\n",
    "    confidence = 1.0 - smoothing\n",
    "    log_probs = F.log_softmax(pred, dim=-1)\n",
    "    nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "    nll_loss = nll_loss.squeeze(1)\n",
    "    smooth_loss = -log_probs.mean(dim=-1)\n",
    "    loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitwidth_squared(model):\n",
    "    s = 0.0\n",
    "    c = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            for bit in module.getBits():\n",
    "                s += bit ** 2\n",
    "                c += 1\n",
    "    if c == 0:\n",
    "        return 0\n",
    "    return s/c\n",
    "\n",
    "def bitwidth_sum(model):\n",
    "    s = 0.0\n",
    "    c = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            for bit in module.getBits():\n",
    "                s += bit\n",
    "                c += 1\n",
    "    if c==0:\n",
    "        return 0\n",
    "    return s/c\n",
    "\n",
    "def bitwidth_round_sum(model):\n",
    "    s = 0.0\n",
    "    c = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            for bit in module.getBits():\n",
    "                s += torch.round(bit)\n",
    "                c += 1\n",
    "    if c==0:\n",
    "        return 0\n",
    "    return s/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBitWidths(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            print(\"module: \", name)\n",
    "            module.printQuantParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, bit_width_criterion, scheduler=None, lambda_bw=1e-1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        if isinstance(criterion, SqrHingeLoss):\n",
    "            target = target.unsqueeze(1)\n",
    "            target_onehot = torch.Tensor(target.size(0), len(classes)).to(device, non_blocking=True)\n",
    "            target_onehot.fill_(-1)\n",
    "            target_onehot.scatter_(1, target, 1)\n",
    "            target = target.squeeze()\n",
    "            target = target_onehot\n",
    "                    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_ce = criterion(output, target)\n",
    "        penalty_bw = bit_width_criterion(model) \n",
    "        loss = loss_ce + lambda_bw*penalty_bw\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        #if batch_idx % 200 == 0:\n",
    "        #    print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \"\n",
    "        #          f\"({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Train set: Average loss: {train_loss:.4f}\")\n",
    "\n",
    "def test(model, device, test_loader, criterion, bit_width_criterion, lambda_bw=1e-1):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    penalty_bw = bit_width_criterion(model) \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            if isinstance(criterion, SqrHingeLoss):\n",
    "                target = target.unsqueeze(1)\n",
    "                target_onehot = torch.Tensor(target.size(0), len(classes)).to(device, non_blocking=True)\n",
    "                target_onehot.fill_(-1)\n",
    "                target_onehot.scatter_(1, target, 1)\n",
    "                target = target.squeeze()\n",
    "                target = target_onehot\n",
    "\n",
    "            loss_ce = criterion(output, target)\n",
    "            loss = loss_ce + lambda_bw*penalty_bw\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {accuracy} ({100.0*accuracy:.2f}%) bit penalty {penalty_bw}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using divice  cuda\n",
      "Train set: Average loss: 1.4346\n",
      "Test set: Average loss: 1.5872, Accuracy: 0.8696 (86.96%) bit penalty 10.449259757995605\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  3.150547742843628  m bits  6.306061267852783  scale  -0.014655613340437412\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.292372703552246  scale  -0.036560483276844025\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  3.149285316467285  m bits  6.297874927520752  scale  0.01306905783712864\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.294673442840576  scale  0.14251366257667542\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  3.1532504558563232  m bits  6.298027992248535  scale  -0.08544464409351349\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.295134544372559  scale  0.1067584902048111\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  3.1514484882354736  m bits  6.3003106117248535  scale  0.07445784658193588\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.2988057136535645  scale  0.11362763494253159\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  3.1521663665771484  m bits  6.2996110916137695  scale  0.06133480370044708\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.305523872375488  scale  -0.012239973060786724\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  3.1511130332946777  m bits  6.301235198974609  scale  0.2577613890171051\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.303225517272949  scale  0.0695146918296814\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  3.151801586151123  m bits  6.297910213470459  scale  0.27105948328971863\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.288697719573975  scale  0.35037699341773987\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  3.150691509246826  m bits  6.300368309020996  scale  0.2909945845603943\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.302302837371826  scale  0.10168959945440292\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  3.150526285171509  m bits  6.295619487762451  scale  0.4135013222694397\n",
      "weight quant params: \n",
      "e bits  3.150547742843628  m bits  6.2931647300720215  scale  0.392153799533844\n",
      "Train set: Average loss: 0.9817\n",
      "Test set: Average loss: 1.2429, Accuracy: 0.8669 (86.69%) bit penalty 7.528936862945557\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  2.1651957035064697  m bits  4.673121452331543  scale  -0.4499064087867737\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.43903112411499  scale  -0.10682216286659241\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  2.2399513721466064  m bits  4.324491500854492  scale  0.23331670463085175\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.315381050109863  scale  0.24769185483455658\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  2.178415536880493  m bits  4.328423976898193  scale  -0.01798473857343197\n",
      "weight quant params: \n",
      "e bits  2.165276288986206  m bits  4.334171772003174  scale  0.11863154917955399\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  2.16715407371521  m bits  4.335782527923584  scale  0.013721762225031853\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.339391708374023  scale  0.1519959717988968\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  2.169635057449341  m bits  4.321699142456055  scale  0.3073901832103729\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.334132194519043  scale  -0.025665972381830215\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  2.15995192527771  m bits  4.337001800537109  scale  0.18455623090267181\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.342649459838867  scale  -0.02777077816426754\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  2.160386323928833  m bits  4.332591533660889  scale  0.26472583413124084\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.264480113983154  scale  0.7896966934204102\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  2.170542001724243  m bits  4.332261562347412  scale  0.44580018520355225\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.338881492614746  scale  -0.03525027260184288\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  2.166952133178711  m bits  4.3486127853393555  scale  0.3199201226234436\n",
      "weight quant params: \n",
      "e bits  2.1651957035064697  m bits  4.413720607757568  scale  0.22592167556285858\n",
      "Train set: Average loss: 0.7764\n",
      "Test set: Average loss: 1.1486, Accuracy: 0.8564 (85.64%) bit penalty 5.937015533447266\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.6126832962036133  m bits  3.9602465629577637  scale  -0.8318134546279907\n",
      "weight quant params: \n",
      "e bits  1.5928094387054443  m bits  3.9667775630950928  scale  -0.5312521457672119\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.658453106880188  m bits  3.2208921909332275  scale  0.1568215936422348\n",
      "weight quant params: \n",
      "e bits  1.5924996137619019  m bits  3.244227409362793  scale  0.11302207410335541\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.6057225465774536  m bits  3.2102174758911133  scale  -0.01972198858857155\n",
      "weight quant params: \n",
      "e bits  1.5925666093826294  m bits  3.352842092514038  scale  -0.4113254249095917\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.5706708431243896  m bits  3.211397171020508  scale  -0.3433322608470917\n",
      "weight quant params: \n",
      "e bits  1.5925617218017578  m bits  3.3162338733673096  scale  -0.25091469287872314\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  1.599665641784668  m bits  3.1992733478546143  scale  0.2603014409542084\n",
      "weight quant params: \n",
      "e bits  1.5925617218017578  m bits  3.264130115509033  scale  -0.33801576495170593\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  1.5897248983383179  m bits  3.207766056060791  scale  0.09362246096134186\n",
      "weight quant params: \n",
      "e bits  1.5925617218017578  m bits  3.2942585945129395  scale  -0.42984268069267273\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  1.5783597230911255  m bits  3.224485158920288  scale  0.0358215868473053\n",
      "weight quant params: \n",
      "e bits  1.5925617218017578  m bits  3.3758249282836914  scale  0.7507358193397522\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  1.588671088218689  m bits  3.224301338195801  scale  0.1535908430814743\n",
      "weight quant params: \n",
      "e bits  1.5925617218017578  m bits  3.2331416606903076  scale  -0.20928208529949188\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  1.5959349870681763  m bits  3.2024519443511963  scale  0.30822256207466125\n",
      "weight quant params: \n",
      "e bits  1.5925617218017578  m bits  3.4246809482574463  scale  -0.08424364775419235\n",
      "Train set: Average loss: 0.6867\n",
      "Test set: Average loss: 1.0364, Accuracy: 0.8524 (85.24%) bit penalty 4.948630332946777\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.24580717086792  m bits  3.5252037048339844  scale  -1.2545604705810547\n",
      "weight quant params: \n",
      "e bits  1.2278809547424316  m bits  3.228902816772461  scale  -0.6462153792381287\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.5547242164611816  m bits  2.5400190353393555  scale  0.30717575550079346\n",
      "weight quant params: \n",
      "e bits  1.2281581163406372  m bits  2.5661776065826416  scale  -0.02129749022424221\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.4977246522903442  m bits  2.5725626945495605  scale  0.2584543228149414\n",
      "weight quant params: \n",
      "e bits  1.2292150259017944  m bits  2.6749470233917236  scale  -0.5279109477996826\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.3000965118408203  m bits  2.517566204071045  scale  -0.3000110387802124\n",
      "weight quant params: \n",
      "e bits  1.2281572818756104  m bits  2.7733898162841797  scale  -0.6966387629508972\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  1.3117355108261108  m bits  2.5584256649017334  scale  0.4728812277317047\n",
      "weight quant params: \n",
      "e bits  1.2281572818756104  m bits  2.6848526000976562  scale  -0.6806371212005615\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  1.305080533027649  m bits  2.4911701679229736  scale  0.5876742005348206\n",
      "weight quant params: \n",
      "e bits  1.2281153202056885  m bits  2.625778913497925  scale  -0.6984362006187439\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  1.3159961700439453  m bits  2.4888687133789062  scale  0.41148775815963745\n",
      "weight quant params: \n",
      "e bits  1.2281572818756104  m bits  2.606515884399414  scale  0.7847850918769836\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  1.281658411026001  m bits  2.524430513381958  scale  0.46462491154670715\n",
      "weight quant params: \n",
      "e bits  1.2281572818756104  m bits  2.554570436477661  scale  -0.5641468167304993\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  1.230931043624878  m bits  2.4369711875915527  scale  0.38081714510917664\n",
      "weight quant params: \n",
      "e bits  1.2281572818756104  m bits  2.6070852279663086  scale  -0.0646202489733696\n",
      "Train set: Average loss: 0.6635\n",
      "Test set: Average loss: 1.2074, Accuracy: 0.8204 (82.04%) bit penalty 4.545082092285156\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.3214833736419678  m bits  3.868666172027588  scale  -1.442671298980713\n",
      "weight quant params: \n",
      "e bits  0.980471670627594  m bits  2.881422519683838  scale  -0.8298286199569702\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.5082619190216064  m bits  2.0877602100372314  scale  0.3607725501060486\n",
      "weight quant params: \n",
      "e bits  0.9806352853775024  m bits  2.490802764892578  scale  -0.32340747117996216\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5271629095077515  m bits  2.37896990776062  scale  0.4384520649909973\n",
      "weight quant params: \n",
      "e bits  0.9821394085884094  m bits  2.3899903297424316  scale  -0.6518321633338928\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.1847302913665771  m bits  2.353271961212158  scale  -0.4222355782985687\n",
      "weight quant params: \n",
      "e bits  0.9806333184242249  m bits  2.403355121612549  scale  -1.0017420053482056\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  1.1787344217300415  m bits  2.494100570678711  scale  0.49834251403808594\n",
      "weight quant params: \n",
      "e bits  0.9806333184242249  m bits  2.3586783409118652  scale  -1.0116500854492188\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  1.1825259923934937  m bits  2.4556798934936523  scale  0.4916219711303711\n",
      "weight quant params: \n",
      "e bits  0.980608344078064  m bits  2.165560007095337  scale  -0.9499174952507019\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  1.1844143867492676  m bits  2.245783567428589  scale  0.49797722697257996\n",
      "weight quant params: \n",
      "e bits  0.9806333184242249  m bits  2.5818700790405273  scale  0.5946593284606934\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  1.0795176029205322  m bits  2.1756510734558105  scale  0.48525455594062805\n",
      "weight quant params: \n",
      "e bits  0.9806333184242249  m bits  2.056142568588257  scale  -0.806297242641449\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.9811217784881592  m bits  1.9455771446228027  scale  0.284817099571228\n",
      "weight quant params: \n",
      "e bits  0.9806333184242249  m bits  2.503225326538086  scale  -0.2522355914115906\n",
      "Train set: Average loss: 0.6204\n",
      "Test set: Average loss: 0.9126, Accuracy: 0.8506 (85.06%) bit penalty 4.243931770324707\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.4551295042037964  m bits  3.700207233428955  scale  -1.4785032272338867\n",
      "weight quant params: \n",
      "e bits  0.8040021061897278  m bits  2.6608409881591797  scale  -0.9371991753578186\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.5467498302459717  m bits  1.8895246982574463  scale  0.3832743763923645\n",
      "weight quant params: \n",
      "e bits  0.8056721091270447  m bits  2.4068167209625244  scale  -0.5035372972488403\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.499453067779541  m bits  2.2969393730163574  scale  0.4735475778579712\n",
      "weight quant params: \n",
      "e bits  0.8083885312080383  m bits  1.9349461793899536  scale  -0.5386722683906555\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.1112216711044312  m bits  2.1043317317962646  scale  -0.47851142287254333\n",
      "weight quant params: \n",
      "e bits  0.8040985465049744  m bits  2.1740903854370117  scale  -1.2959173917770386\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  1.0372315645217896  m bits  2.5100409984588623  scale  0.5134377479553223\n",
      "weight quant params: \n",
      "e bits  0.8040985465049744  m bits  2.047926187515259  scale  -1.2728012800216675\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  1.086402416229248  m bits  2.474459171295166  scale  0.501691460609436\n",
      "weight quant params: \n",
      "e bits  0.8040832877159119  m bits  1.863614559173584  scale  -1.1323671340942383\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  1.074610710144043  m bits  2.2358596324920654  scale  0.5010089874267578\n",
      "weight quant params: \n",
      "e bits  0.8040985465049744  m bits  2.5040056705474854  scale  0.4835363030433655\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.9223250150680542  m bits  2.018700361251831  scale  0.5005894303321838\n",
      "weight quant params: \n",
      "e bits  0.8040985465049744  m bits  1.679125428199768  scale  -0.8490797877311707\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.8047946095466614  m bits  1.6092283725738525  scale  0.29731428623199463\n",
      "weight quant params: \n",
      "e bits  0.8040985465049744  m bits  2.499549150466919  scale  -0.3738592267036438\n",
      "Train set: Average loss: 0.5711\n",
      "Test set: Average loss: 0.9780, Accuracy: 0.8568 (85.68%) bit penalty 3.985562562942505\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.51991868019104  m bits  3.7572546005249023  scale  -1.4972435235977173\n",
      "weight quant params: \n",
      "e bits  0.6732747554779053  m bits  2.61484956741333  scale  -1.0341898202896118\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.4986146688461304  m bits  1.7126615047454834  scale  0.39286303520202637\n",
      "weight quant params: \n",
      "e bits  0.6756959557533264  m bits  2.2420132160186768  scale  -0.49677708745002747\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.509342908859253  m bits  2.210508108139038  scale  0.4872914254665375\n",
      "weight quant params: \n",
      "e bits  0.6758402585983276  m bits  1.6692184209823608  scale  -0.5025083422660828\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.063646912574768  m bits  1.8577086925506592  scale  -0.47985541820526123\n",
      "weight quant params: \n",
      "e bits  0.6743648648262024  m bits  1.922206997871399  scale  -1.5051249265670776\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.9144046306610107  m bits  2.494377374649048  scale  0.5159819722175598\n",
      "weight quant params: \n",
      "e bits  0.673957884311676  m bits  1.821966528892517  scale  -1.5129624605178833\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.9535167217254639  m bits  2.3840126991271973  scale  0.5102290511131287\n",
      "weight quant params: \n",
      "e bits  0.6733242869377136  m bits  1.5977871417999268  scale  -1.2678827047348022\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.9498057961463928  m bits  2.0748422145843506  scale  0.5005829930305481\n",
      "weight quant params: \n",
      "e bits  0.6733339428901672  m bits  2.1973166465759277  scale  0.48832982778549194\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.7960224151611328  m bits  1.7797417640686035  scale  0.48904550075531006\n",
      "weight quant params: \n",
      "e bits  0.6733339428901672  m bits  1.445617914199829  scale  -1.161712408065796\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.6733392477035522  m bits  1.5009692907333374  scale  -0.014038588851690292\n",
      "weight quant params: \n",
      "e bits  0.6733339428901672  m bits  2.512006998062134  scale  -0.4977736175060272\n",
      "Train set: Average loss: 0.5388\n",
      "Test set: Average loss: 0.8526, Accuracy: 0.8686 (86.86%) bit penalty 3.8220651149749756\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5129294395446777  m bits  3.5897374153137207  scale  -1.5278279781341553\n",
      "weight quant params: \n",
      "e bits  0.573460578918457  m bits  2.8680942058563232  scale  -1.2469393014907837\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.6195526123046875  m bits  1.6221940517425537  scale  0.49429914355278015\n",
      "weight quant params: \n",
      "e bits  0.581001341342926  m bits  2.091947317123413  scale  -0.4943281412124634\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5425442457199097  m bits  2.430516242980957  scale  0.4866982400417328\n",
      "weight quant params: \n",
      "e bits  0.5775895714759827  m bits  1.519791603088379  scale  -0.5170416235923767\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.0956627130508423  m bits  1.6831146478652954  scale  -0.3242218792438507\n",
      "weight quant params: \n",
      "e bits  0.6157844662666321  m bits  1.751058578491211  scale  -1.4854121208190918\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.8153000473976135  m bits  2.5042619705200195  scale  0.5053601861000061\n",
      "weight quant params: \n",
      "e bits  0.5992445349693298  m bits  1.6456868648529053  scale  -1.4977728128433228\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.8733332753181458  m bits  2.4159185886383057  scale  0.5058039426803589\n",
      "weight quant params: \n",
      "e bits  0.5772625803947449  m bits  1.486666202545166  scale  -1.5570980310440063\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.7976681590080261  m bits  1.801741600036621  scale  0.5063208341598511\n",
      "weight quant params: \n",
      "e bits  0.573497474193573  m bits  1.9572423696517944  scale  0.48557645082473755\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.6816002726554871  m bits  1.6154521703720093  scale  0.49830031394958496\n",
      "weight quant params: \n",
      "e bits  0.5756058692932129  m bits  1.3044859170913696  scale  -1.65714693069458\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.5730510950088501  m bits  1.4902210235595703  scale  -0.2589968740940094\n",
      "weight quant params: \n",
      "e bits  0.573497474193573  m bits  2.260450601577759  scale  -0.5020711421966553\n",
      "Train set: Average loss: 0.5107\n",
      "Test set: Average loss: 1.1955, Accuracy: 0.7992 (79.92%) bit penalty 3.658538341522217\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5291575193405151  m bits  3.5271899700164795  scale  -1.519777774810791\n",
      "weight quant params: \n",
      "e bits  0.4939453601837158  m bits  2.8718366622924805  scale  -1.4053159952163696\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.5335841178894043  m bits  1.5282715559005737  scale  0.4604988694190979\n",
      "weight quant params: \n",
      "e bits  0.5087873339653015  m bits  2.1306114196777344  scale  -0.5049930214881897\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.4963955879211426  m bits  2.4385249614715576  scale  0.48753243684768677\n",
      "weight quant params: \n",
      "e bits  0.49935704469680786  m bits  1.500490665435791  scale  -0.649386465549469\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.1399444341659546  m bits  1.4998036623001099  scale  -0.19645389914512634\n",
      "weight quant params: \n",
      "e bits  0.5543036460876465  m bits  1.5463260412216187  scale  -1.501896619796753\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.7427595257759094  m bits  2.5009829998016357  scale  0.5073828101158142\n",
      "weight quant params: \n",
      "e bits  0.5494073629379272  m bits  1.495384693145752  scale  -1.5117453336715698\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.7528328895568848  m bits  2.3039395809173584  scale  0.5002446174621582\n",
      "weight quant params: \n",
      "e bits  0.5325583219528198  m bits  1.4338279962539673  scale  -1.4815000295639038\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.6818113327026367  m bits  1.5317729711532593  scale  0.5424193739891052\n",
      "weight quant params: \n",
      "e bits  0.4953720271587372  m bits  1.745582103729248  scale  0.4890565276145935\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.5974141359329224  m bits  1.4993784427642822  scale  0.476169615983963\n",
      "weight quant params: \n",
      "e bits  0.5022274255752563  m bits  1.1233428716659546  scale  -1.5606290102005005\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.49559471011161804  m bits  1.4523777961730957  scale  -0.3683706820011139\n",
      "weight quant params: \n",
      "e bits  0.49539753794670105  m bits  2.1231985092163086  scale  -0.5523039698600769\n",
      "Train set: Average loss: 0.5093\n",
      "Test set: Average loss: 0.8955, Accuracy: 0.8563 (85.63%) bit penalty 3.5962533950805664\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5009623765945435  m bits  3.465071439743042  scale  -1.5220060348510742\n",
      "weight quant params: \n",
      "e bits  0.44561469554901123  m bits  2.7146155834198  scale  -1.4515953063964844\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.594576358795166  m bits  1.5103209018707275  scale  0.49131110310554504\n",
      "weight quant params: \n",
      "e bits  0.5178256630897522  m bits  2.325556516647339  scale  -0.4848747253417969\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5105139017105103  m bits  2.540964365005493  scale  0.4832032024860382\n",
      "weight quant params: \n",
      "e bits  0.5107352137565613  m bits  1.5155127048492432  scale  -0.5928669571876526\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.2372633218765259  m bits  1.5019681453704834  scale  -0.08491066098213196\n",
      "weight quant params: \n",
      "e bits  0.5329903960227966  m bits  1.5117571353912354  scale  -1.5012940168380737\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.6609110832214355  m bits  2.431384325027466  scale  0.5123708248138428\n",
      "weight quant params: \n",
      "e bits  0.5122657418251038  m bits  1.5029467344284058  scale  -1.501602292060852\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.658069372177124  m bits  2.1554465293884277  scale  0.5116296410560608\n",
      "weight quant params: \n",
      "e bits  0.5005614161491394  m bits  1.4649497270584106  scale  -1.5098403692245483\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.6133520603179932  m bits  1.5138816833496094  scale  0.5147538185119629\n",
      "weight quant params: \n",
      "e bits  0.4329850971698761  m bits  1.5863779783248901  scale  0.4803774654865265\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.5405333638191223  m bits  1.5436700582504272  scale  0.5016756057739258\n",
      "weight quant params: \n",
      "e bits  0.4598067104816437  m bits  1.013677716255188  scale  -1.5085899829864502\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.4569648206233978  m bits  1.3934913873672485  scale  -0.32358360290527344\n",
      "weight quant params: \n",
      "e bits  0.43335604667663574  m bits  1.921674132347107  scale  -0.5574577450752258\n",
      "Train set: Average loss: 0.5026\n",
      "Test set: Average loss: 1.0131, Accuracy: 0.8193 (81.93%) bit penalty 3.632946491241455\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.522255539894104  m bits  3.9493556022644043  scale  -1.5014625787734985\n",
      "weight quant params: \n",
      "e bits  0.5408520102500916  m bits  3.532890796661377  scale  -1.4954930543899536\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.582252025604248  m bits  1.6658660173416138  scale  0.43284645676612854\n",
      "weight quant params: \n",
      "e bits  0.5022560358047485  m bits  2.484482526779175  scale  -0.48806437849998474\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.4564579725265503  m bits  2.5056018829345703  scale  0.5031953454017639\n",
      "weight quant params: \n",
      "e bits  0.49938589334487915  m bits  1.5145024061203003  scale  -0.5898357629776001\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.3868846893310547  m bits  1.5041587352752686  scale  0.04493187367916107\n",
      "weight quant params: \n",
      "e bits  0.5184958577156067  m bits  1.4930143356323242  scale  -1.5005831718444824\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.5914434790611267  m bits  2.49361515045166  scale  0.50108402967453\n",
      "weight quant params: \n",
      "e bits  0.5138198733329773  m bits  1.512133002281189  scale  -1.4953001737594604\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.5592085719108582  m bits  1.8848401308059692  scale  0.511101245880127\n",
      "weight quant params: \n",
      "e bits  0.5074392557144165  m bits  1.5066978931427002  scale  -1.4962254762649536\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.552995502948761  m bits  1.4994897842407227  scale  0.5037468671798706\n",
      "weight quant params: \n",
      "e bits  0.3824182450771332  m bits  1.5007030963897705  scale  0.4541076123714447\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.4985986053943634  m bits  1.5010795593261719  scale  0.5136662721633911\n",
      "weight quant params: \n",
      "e bits  0.4234798550605774  m bits  0.9247797131538391  scale  -1.4697026014328003\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.41106757521629333  m bits  1.3567054271697998  scale  -0.4197062849998474\n",
      "weight quant params: \n",
      "e bits  0.38260117173194885  m bits  1.7312052249908447  scale  -0.5492997765541077\n",
      "Train set: Average loss: 0.4874\n",
      "Test set: Average loss: 0.8771, Accuracy: 0.864 (86.40%) bit penalty 3.5809695720672607\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5195636749267578  m bits  3.696829319000244  scale  -1.5434221029281616\n",
      "weight quant params: \n",
      "e bits  0.5520762205123901  m bits  3.513678550720215  scale  -1.495514154434204\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.533469319343567  m bits  1.5175026655197144  scale  0.47190597653388977\n",
      "weight quant params: \n",
      "e bits  0.5039376616477966  m bits  2.5037436485290527  scale  -0.4892261326313019\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5526710748672485  m bits  2.5076258182525635  scale  0.5344133377075195\n",
      "weight quant params: \n",
      "e bits  0.5027357935905457  m bits  1.5369020700454712  scale  -0.5753832459449768\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.4561824798583984  m bits  1.50121009349823  scale  0.20945219695568085\n",
      "weight quant params: \n",
      "e bits  0.5160204172134399  m bits  1.4911507368087769  scale  -1.4976859092712402\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.5478935241699219  m bits  2.5035808086395264  scale  0.5059417486190796\n",
      "weight quant params: \n",
      "e bits  0.5001987218856812  m bits  1.510179877281189  scale  -1.434885859489441\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.4903751313686371  m bits  1.7377463579177856  scale  0.5061050653457642\n",
      "weight quant params: \n",
      "e bits  0.5041346549987793  m bits  1.4610533714294434  scale  -1.4906655550003052\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.5045996308326721  m bits  1.5095056295394897  scale  0.508176326751709\n",
      "weight quant params: \n",
      "e bits  0.34077614545822144  m bits  1.5001448392868042  scale  0.3458594083786011\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.4913807213306427  m bits  1.5356134176254272  scale  0.5236266255378723\n",
      "weight quant params: \n",
      "e bits  0.38579338788986206  m bits  0.8507025837898254  scale  -1.500343918800354\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.38015270233154297  m bits  1.3616682291030884  scale  -0.4798028767108917\n",
      "weight quant params: \n",
      "e bits  0.340995192527771  m bits  1.5956509113311768  scale  -0.5723722577095032\n",
      "Train set: Average loss: 0.4872\n",
      "Test set: Average loss: 0.7883, Accuracy: 0.8775 (87.75%) bit penalty 3.53951096534729\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5205520391464233  m bits  3.514619827270508  scale  -1.5769869089126587\n",
      "weight quant params: \n",
      "e bits  0.5519112348556519  m bits  3.440831422805786  scale  -1.4827203750610352\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.6553783416748047  m bits  1.5960973501205444  scale  0.49876850843429565\n",
      "weight quant params: \n",
      "e bits  0.5119102597236633  m bits  2.5065221786499023  scale  -0.4576456844806671\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5060430765151978  m bits  2.5252373218536377  scale  0.49325844645500183\n",
      "weight quant params: \n",
      "e bits  0.5014961957931519  m bits  1.5043314695358276  scale  -0.5332766771316528\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.4975602626800537  m bits  1.5006234645843506  scale  0.2945897877216339\n",
      "weight quant params: \n",
      "e bits  0.5427014827728271  m bits  1.5026764869689941  scale  -1.4940102100372314\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.5062890648841858  m bits  2.4783732891082764  scale  0.510413408279419\n",
      "weight quant params: \n",
      "e bits  0.4959813952445984  m bits  1.5017545223236084  scale  -1.469436526298523\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.5006042718887329  m bits  1.512041687965393  scale  0.7218695282936096\n",
      "weight quant params: \n",
      "e bits  0.5077346563339233  m bits  1.494018793106079  scale  -1.5048562288284302\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.4989960491657257  m bits  1.4943054914474487  scale  0.5905960202217102\n",
      "weight quant params: \n",
      "e bits  0.305878221988678  m bits  1.5039732456207275  scale  0.2556944489479065\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.45786726474761963  m bits  1.5056933164596558  scale  0.5579475164413452\n",
      "weight quant params: \n",
      "e bits  0.36145660281181335  m bits  0.7802074551582336  scale  -1.5042353868484497\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.34872955083847046  m bits  1.2670049667358398  scale  -0.4888571500778198\n",
      "weight quant params: \n",
      "e bits  0.306248277425766  m bits  1.5055407285690308  scale  -0.6326219439506531\n",
      "Train set: Average loss: 0.4834\n",
      "Test set: Average loss: 0.9361, Accuracy: 0.8546 (85.46%) bit penalty 3.5470314025878906\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5426220893859863  m bits  3.535008192062378  scale  -1.57388174533844\n",
      "weight quant params: \n",
      "e bits  0.5190170407295227  m bits  3.269090414047241  scale  -1.470041036605835\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.7589375972747803  m bits  1.814974308013916  scale  0.4920429587364197\n",
      "weight quant params: \n",
      "e bits  0.4696817398071289  m bits  2.4926486015319824  scale  -0.4993188977241516\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5339112281799316  m bits  2.546748399734497  scale  0.5263336896896362\n",
      "weight quant params: \n",
      "e bits  0.5029044151306152  m bits  1.6711257696151733  scale  -0.4993552267551422\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.5047565698623657  m bits  1.504584550857544  scale  0.4213331639766693\n",
      "weight quant params: \n",
      "e bits  0.5597800612449646  m bits  1.4980016946792603  scale  -1.4956828355789185\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.5201767086982727  m bits  2.485494613647461  scale  0.5158026814460754\n",
      "weight quant params: \n",
      "e bits  0.5151214003562927  m bits  1.5223274230957031  scale  -1.482726812362671\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.4989493787288666  m bits  1.5220580101013184  scale  0.7950496673583984\n",
      "weight quant params: \n",
      "e bits  0.503307044506073  m bits  1.4904228448867798  scale  -1.5120600461959839\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.4988938868045807  m bits  1.5124245882034302  scale  0.6742547154426575\n",
      "weight quant params: \n",
      "e bits  0.2762674391269684  m bits  1.5103204250335693  scale  0.18335233628749847\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.4267337918281555  m bits  1.5078613758087158  scale  0.6126127243041992\n",
      "weight quant params: \n",
      "e bits  0.33919811248779297  m bits  0.7083881497383118  scale  -1.496146559715271\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.3218719959259033  m bits  1.1835544109344482  scale  -0.4266578257083893\n",
      "weight quant params: \n",
      "e bits  0.2767725884914398  m bits  1.502629280090332  scale  -0.7998031377792358\n",
      "Train set: Average loss: 0.4812\n",
      "Test set: Average loss: 0.8405, Accuracy: 0.8776 (87.76%) bit penalty 3.578812599182129\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5307774543762207  m bits  3.495635986328125  scale  -1.6325888633728027\n",
      "weight quant params: \n",
      "e bits  0.5260751843452454  m bits  3.4020731449127197  scale  -1.4959173202514648\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.8713281154632568  m bits  1.9605185985565186  scale  0.49481654167175293\n",
      "weight quant params: \n",
      "e bits  0.48666736483573914  m bits  2.45556640625  scale  -0.4728604555130005\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.6361172199249268  m bits  2.5369534492492676  scale  0.5489951372146606\n",
      "weight quant params: \n",
      "e bits  0.5127685070037842  m bits  1.9700255393981934  scale  -0.5180989503860474\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.4765894412994385  m bits  1.551518440246582  scale  0.5183731913566589\n",
      "weight quant params: \n",
      "e bits  0.5441474318504333  m bits  1.5454130172729492  scale  -1.4979848861694336\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.5372196435928345  m bits  2.525747537612915  scale  0.5396825671195984\n",
      "weight quant params: \n",
      "e bits  0.5062160491943359  m bits  1.5279958248138428  scale  -1.4947459697723389\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.4977494776248932  m bits  1.5163251161575317  scale  0.8840011954307556\n",
      "weight quant params: \n",
      "e bits  0.5072497129440308  m bits  1.48263418674469  scale  -1.5055692195892334\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.5002269148826599  m bits  1.5239371061325073  scale  0.7175286412239075\n",
      "weight quant params: \n",
      "e bits  0.2511257529258728  m bits  1.4999892711639404  scale  0.09489092975854874\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.4022371470928192  m bits  1.5061514377593994  scale  0.6578919291496277\n",
      "weight quant params: \n",
      "e bits  0.31923243403434753  m bits  0.6465560793876648  scale  -1.4801867008209229\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.29647189378738403  m bits  1.1160647869110107  scale  -0.4351377785205841\n",
      "weight quant params: \n",
      "e bits  0.25151318311691284  m bits  1.5018079280853271  scale  -0.9540395140647888\n",
      "Train set: Average loss: 0.4714\n",
      "Test set: Average loss: 0.9293, Accuracy: 0.8583 (85.83%) bit penalty 3.5610949993133545\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5233935117721558  m bits  3.640141487121582  scale  -1.6597387790679932\n",
      "weight quant params: \n",
      "e bits  0.5145601034164429  m bits  3.1430015563964844  scale  -1.4903134107589722\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  1.9284342527389526  m bits  2.012377977371216  scale  0.49958741664886475\n",
      "weight quant params: \n",
      "e bits  0.5303045511245728  m bits  2.5311741828918457  scale  -0.4511388838291168\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5149650573730469  m bits  2.518181324005127  scale  0.5001860857009888\n",
      "weight quant params: \n",
      "e bits  0.5042756795883179  m bits  2.2129955291748047  scale  -0.524236798286438\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.3498891592025757  m bits  1.6355174779891968  scale  0.5081589221954346\n",
      "weight quant params: \n",
      "e bits  0.5678072571754456  m bits  1.5096186399459839  scale  -1.4931777715682983\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.50650554895401  m bits  2.3391969203948975  scale  0.5284186601638794\n",
      "weight quant params: \n",
      "e bits  0.5441620349884033  m bits  1.4917519092559814  scale  -1.4874436855316162\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.5034699440002441  m bits  1.5192877054214478  scale  0.9815638065338135\n",
      "weight quant params: \n",
      "e bits  0.49968817830085754  m bits  1.4712778329849243  scale  -1.5036879777908325\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.5001763105392456  m bits  1.4994451999664307  scale  0.7852741479873657\n",
      "weight quant params: \n",
      "e bits  0.22929131984710693  m bits  1.502772569656372  scale  0.000959469994995743\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.376494437456131  m bits  1.5138376951217651  scale  0.6905776262283325\n",
      "weight quant params: \n",
      "e bits  0.2933506369590759  m bits  0.5897834897041321  scale  -1.4955707788467407\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.27411845326423645  m bits  1.0759049654006958  scale  -0.39442333579063416\n",
      "weight quant params: \n",
      "e bits  0.22994498908519745  m bits  1.5026084184646606  scale  -1.1126742362976074\n",
      "Train set: Average loss: 0.4696\n",
      "Test set: Average loss: 0.9270, Accuracy: 0.848 (84.80%) bit penalty 3.567765474319458\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5210517644882202  m bits  3.650804042816162  scale  -1.6847686767578125\n",
      "weight quant params: \n",
      "e bits  0.5406156778335571  m bits  3.1181719303131104  scale  -1.5037775039672852\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  2.020905017852783  m bits  2.1096653938293457  scale  0.5000064969062805\n",
      "weight quant params: \n",
      "e bits  0.49692657589912415  m bits  2.500439405441284  scale  -0.4892652928829193\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5131959915161133  m bits  2.5513315200805664  scale  0.4869622588157654\n",
      "weight quant params: \n",
      "e bits  0.5026922821998596  m bits  2.44897198677063  scale  -0.4981570839881897\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.3826950788497925  m bits  1.7730510234832764  scale  0.5080583095550537\n",
      "weight quant params: \n",
      "e bits  0.5615875720977783  m bits  1.5027565956115723  scale  -1.4947915077209473\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.500773549079895  m bits  2.051753282546997  scale  0.6572950482368469\n",
      "weight quant params: \n",
      "e bits  0.5763915777206421  m bits  1.5460330247879028  scale  -1.4968461990356445\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.500575065612793  m bits  1.49787437915802  scale  1.1079459190368652\n",
      "weight quant params: \n",
      "e bits  0.5015255212783813  m bits  1.437090277671814  scale  -1.498822569847107\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.4998297393321991  m bits  1.5183826684951782  scale  0.8500701785087585\n",
      "weight quant params: \n",
      "e bits  0.21045629680156708  m bits  1.5261311531066895  scale  -0.10827786475419998\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.35941487550735474  m bits  1.5141644477844238  scale  0.7462941408157349\n",
      "weight quant params: \n",
      "e bits  0.271747887134552  m bits  0.5426065921783447  scale  -1.493329644203186\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.25240838527679443  m bits  1.006789207458496  scale  -0.38116025924682617\n",
      "weight quant params: \n",
      "e bits  0.21123982965946198  m bits  1.4997318983078003  scale  -1.226358413696289\n",
      "Train set: Average loss: 0.4673\n",
      "Test set: Average loss: 0.8159, Accuracy: 0.8819 (88.19%) bit penalty 3.5800201892852783\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5081770420074463  m bits  3.5524117946624756  scale  -1.7134933471679688\n",
      "weight quant params: \n",
      "e bits  0.6629171967506409  m bits  3.142014265060425  scale  -1.4915542602539062\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  2.100700855255127  m bits  2.2704763412475586  scale  0.5021024346351624\n",
      "weight quant params: \n",
      "e bits  0.5580142140388489  m bits  2.5118870735168457  scale  -0.4194130301475525\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5080435276031494  m bits  2.506394863128662  scale  0.4938522279262543\n",
      "weight quant params: \n",
      "e bits  0.4851580560207367  m bits  2.583709478378296  scale  -0.4857906401157379\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.3860414028167725  m bits  1.9080326557159424  scale  0.49487191438674927\n",
      "weight quant params: \n",
      "e bits  0.5859646201133728  m bits  1.506515383720398  scale  -1.494606375694275\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.5010862946510315  m bits  1.956959843635559  scale  0.741309642791748\n",
      "weight quant params: \n",
      "e bits  0.5933608412742615  m bits  1.5149420499801636  scale  -1.5014641284942627\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.5011404156684875  m bits  1.507685899734497  scale  1.1502002477645874\n",
      "weight quant params: \n",
      "e bits  0.505193829536438  m bits  1.3672409057617188  scale  -1.5074740648269653\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.4994546175003052  m bits  1.4986778497695923  scale  0.8943194150924683\n",
      "weight quant params: \n",
      "e bits  0.1940523236989975  m bits  1.514451026916504  scale  -0.22079259157180786\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.34179380536079407  m bits  1.5059064626693726  scale  0.8282715678215027\n",
      "weight quant params: \n",
      "e bits  0.25262346863746643  m bits  0.5007765889167786  scale  -1.5038987398147583\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.2354988157749176  m bits  0.9763184785842896  scale  -0.37486732006073\n",
      "weight quant params: \n",
      "e bits  0.1949678212404251  m bits  1.5017703771591187  scale  -1.3386061191558838\n",
      "Train set: Average loss: 0.4569\n",
      "Test set: Average loss: 0.9050, Accuracy: 0.8615 (86.15%) bit penalty 3.5814106464385986\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5122400522232056  m bits  3.5108449459075928  scale  -1.7058714628219604\n",
      "weight quant params: \n",
      "e bits  0.787402868270874  m bits  3.1630797386169434  scale  -1.5029628276824951\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  2.108994960784912  m bits  2.317312240600586  scale  0.4958840012550354\n",
      "weight quant params: \n",
      "e bits  0.5104312896728516  m bits  2.514453649520874  scale  -0.484598308801651\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5238841772079468  m bits  2.4747471809387207  scale  0.49856409430503845\n",
      "weight quant params: \n",
      "e bits  0.47338974475860596  m bits  2.497363328933716  scale  -0.48837020993232727\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.489020824432373  m bits  2.114650249481201  scale  0.5076231360435486\n",
      "weight quant params: \n",
      "e bits  0.5879982709884644  m bits  1.503656268119812  scale  -1.494391918182373\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.50193190574646  m bits  1.8015004396438599  scale  0.816165566444397\n",
      "weight quant params: \n",
      "e bits  0.6031447052955627  m bits  1.5118942260742188  scale  -1.4995290040969849\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.5001460313796997  m bits  1.5071167945861816  scale  1.2163865566253662\n",
      "weight quant params: \n",
      "e bits  0.5049890875816345  m bits  1.3362452983856201  scale  -1.501644492149353\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.5004717707633972  m bits  1.5001996755599976  scale  0.9308179020881653\n",
      "weight quant params: \n",
      "e bits  0.17946812510490417  m bits  1.5057568550109863  scale  -0.31276458501815796\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.322002649307251  m bits  1.4996724128723145  scale  0.8793426156044006\n",
      "weight quant params: \n",
      "e bits  0.24244049191474915  m bits  0.49991074204444885  scale  -1.5054287910461426\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.22305496037006378  m bits  0.9589934349060059  scale  -0.485235333442688\n",
      "weight quant params: \n",
      "e bits  0.180885449051857  m bits  1.4960925579071045  scale  -1.4259257316589355\n",
      "Train set: Average loss: 0.4518\n",
      "Test set: Average loss: 0.8806, Accuracy: 0.8639 (86.39%) bit penalty 3.576350450515747\n",
      "module:  conv1\n",
      "input quant params: \n",
      "e bits:  1.5054656267166138  m bits  3.5248911380767822  scale  -1.709634780883789\n",
      "weight quant params: \n",
      "e bits  0.9317231178283691  m bits  3.120314359664917  scale  -1.5012861490249634\n",
      "module:  conv2\n",
      "input quant params: \n",
      "e bits:  2.1833205223083496  m bits  2.3988945484161377  scale  0.49681800603866577\n",
      "weight quant params: \n",
      "e bits  0.5096917748451233  m bits  2.5301618576049805  scale  -0.49447131156921387\n",
      "module:  conv3\n",
      "input quant params: \n",
      "e bits:  1.5024257898330688  m bits  2.4032158851623535  scale  0.5017368197441101\n",
      "weight quant params: \n",
      "e bits  0.4882630705833435  m bits  2.5171406269073486  scale  -0.47635897994041443\n",
      "module:  conv4\n",
      "input quant params: \n",
      "e bits:  1.352466344833374  m bits  2.131748676300049  scale  0.501880407333374\n",
      "weight quant params: \n",
      "e bits  0.613508939743042  m bits  1.5005863904953003  scale  -1.5011413097381592\n",
      "module:  conv5\n",
      "input quant params: \n",
      "e bits:  0.499996542930603  m bits  1.6941906213760376  scale  0.8660012483596802\n",
      "weight quant params: \n",
      "e bits  0.6241883635520935  m bits  1.5014854669570923  scale  -1.4918091297149658\n",
      "module:  conv6\n",
      "input quant params: \n",
      "e bits:  0.5002238154411316  m bits  1.5466798543930054  scale  1.2504783868789673\n",
      "weight quant params: \n",
      "e bits  0.4949575960636139  m bits  1.2888103723526  scale  -1.4971320629119873\n",
      "module:  fc7\n",
      "input quant params: \n",
      "e bits:  0.49849140644073486  m bits  1.5123573541641235  scale  0.9892650842666626\n",
      "weight quant params: \n",
      "e bits  0.1666245460510254  m bits  1.5077461004257202  scale  -0.4271564781665802\n",
      "module:  fc8\n",
      "input quant params: \n",
      "e bits:  0.3070427477359772  m bits  1.5039262771606445  scale  0.9220168590545654\n",
      "weight quant params: \n",
      "e bits  0.23512841761112213  m bits  0.49940359592437744  scale  -1.4994335174560547\n",
      "module:  fc9\n",
      "input quant params: \n",
      "e bits:  0.2133258432149887  m bits  0.9134398102760315  scale  -0.4854332208633423\n",
      "weight quant params: \n",
      "e bits  0.16807499527931213  m bits  1.4843980073928833  scale  -1.4605462551116943\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit_width_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, bit_width_criterion, scheduler, lambda_bw)\u001b[0m\n\u001b[1;32m     18\u001b[0m penalty_bw \u001b[38;5;241m=\u001b[39m bit_width_criterion(model) \n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_ce \u001b[38;5;241m+\u001b[39m lambda_bw\u001b[38;5;241m*\u001b[39mpenalty_bw\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"using divice \", device)\n",
    "\n",
    "base_model_path = f\"train_weights_and_quant_{dataset}_base_model_fixed.pth\"\n",
    "best_accuracy_model_path = f\"train_weights_and_quant_{dataset}_best_accuracy_model_fixed.pth\"\n",
    "less_bits_model_path = f\"train_weights_and_quant_{dataset}_less_bits_model_fixed.pth\"\n",
    "\n",
    "load_model_path = None\n",
    "if(os.path.isfile(best_accuracy_model_path)):\n",
    "    load_model_path = best_accuracy_model_path\n",
    "elif(os.path.isfile(base_model_path)):\n",
    "    load_model_path = base_model_path   \n",
    "else:\n",
    "    best_accuracy_model_path = base_model_path\n",
    "    less_bits_model_path = base_model_path\n",
    "\n",
    "if(load_model_path):\n",
    "    # Create model\n",
    "    # model = SimpleQuantizedMLP(e_bits=4.0, m_bits=4.0, num_classes=len(classes)).to(device)\n",
    "    model = QuantSimpleCIFAR10Model(num_classes=len(classes), optimizeQuant=True).to(device)\n",
    "    #model = SimpleCIFAR10Model(num_classes=len(classes)).to(device)\n",
    "    model.load_state_dict(torch.load(load_model_path, weights_only=True))\n",
    "else:\n",
    "    model = QuantSimpleCIFAR10Model(num_classes=len(classes), optimizeQuant=False).to(device)\n",
    "\n",
    "#criterion = SqrHingeLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = label_smoothing_loss\n",
    "\n",
    "bit_width_criterion = bitwidth_sum\n",
    "\n",
    "# Create optimizer (SGD or Adam)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)  # Adjusted Cosine Annealing with warm-up strategy\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_penalty_bw = 100000.0\n",
    "# Train for some epochs\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, criterion, bit_width_criterion, epoch)\n",
    "    if scheduler != None:\n",
    "        scheduler.step()\n",
    "    accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "    penalty_bw = bitwidth_sum(model)\n",
    "    if(accuracy > best_accuracy):\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), best_accuracy_model_path)\n",
    "    if(penalty_bw < best_penalty_bw):\n",
    "        best_penalty_bw = penalty_bw\n",
    "        torch.save(model.state_dict(), less_bits_model_path)\n",
    "    printBitWidths(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(base_model_path, weights_only=True))\n",
    "base_accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "base_penalty_bw = bitwidth_round_sum(model).detach().item()\n",
    "model.load_state_dict(torch.load(best_accuracy_model_path, weights_only=True))\n",
    "best_accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "best_accuracy_penalty_bw = bitwidth_round_sum(model).detach().item()\n",
    "model.load_state_dict(torch.load(less_bits_model_path, weights_only=True))\n",
    "lest_bits_accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "less_bits_penalty_bw = bitwidth_round_sum(model).detach().item()\n",
    "print(\"base model accuracy: \", base_accuracy, \" penalty bw \", base_penalty_bw)\n",
    "print(\"best accuracy model accuracy: \", best_accuracy, \" penalty bw \", best_accuracy_penalty_bw)\n",
    "print(\"less bits model accuracy: \", lest_bits_accuracy, \" penalty bw \", less_bits_penalty_bw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
