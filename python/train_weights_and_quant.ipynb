{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "batch_size = 1024\n",
    "#dataset = \"MNIST\"\n",
    "dataset = \"CIFAR10\"\n",
    "#dataset = \"CIFAR100\"\n",
    "#dataset = \"FMNIST\"\n",
    "\n",
    "if(dataset == \"MNIST\"):\n",
    "    # 1) MNIST Dataset & Dataloaders\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    classes = ('zero', 'one', 'two', 'three', 'four', 'five', 'sis', 'seven', 'eight', 'nine')\n",
    "\n",
    "    input_size = (1, 32, 32)\n",
    "\n",
    "if(dataset == \"FMNIST\"):\n",
    "    # 1) MNIST Dataset & Dataloaders\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset  = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    classes = ('zero', 'one', 'two', 'three', 'four', 'five', 'sis', 'seven', 'eight', 'nine')\n",
    "\n",
    "    input_size = (1, 32, 32)\n",
    "    \n",
    "if(dataset == \"CIFAR10\"):\n",
    "    # 2) CIFAR-10 dataset\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(90, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        #transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))  # mean, std\n",
    "    ])\n",
    "\n",
    "    # Transformations for testing: just convert and normalize\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    input_size = (3, 32, 32)\n",
    "\n",
    "if(dataset == \"CIFAR100\"):\n",
    "    # 2) CIFAR-10 dataset\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(90, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        #transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))  # mean, std\n",
    "    ])\n",
    "\n",
    "    # Transformations for testing: just convert and normalize\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transform)\n",
    "    test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = [x for x in range(100)]\n",
    "\n",
    "    input_size = (3, 32, 32)\n",
    "    \n",
    "if(dataset == \"IMAGENET\"):\n",
    "    # 2) CIFAR-10 dataset\n",
    "    train_transform = transforms.Compose([\n",
    "        #transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomVerticalFlip(),\n",
    "        #transforms.RandomRotation(90, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        #transforms.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))  # mean, std\n",
    "    ])\n",
    "\n",
    "    # Transformations for testing: just convert and normalize\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "        #                    (0.2470, 0.2435, 0.2616))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageNet(root='./data', train=True, download=True, transform=train_transform)\n",
    "    test_dataset = datasets.ImageNet(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = [x for x in range(100)]\n",
    "\n",
    "    input_size = (3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img_tensor):\n",
    "    \"\"\"\n",
    "    img_tensor: a batch of images in shape (B, C, H, W) or a single image in (C, H, W).\n",
    "    \"\"\"\n",
    "    # If it's a batch of images (4D), make a grid first\n",
    "    if len(img_tensor.shape) == 4:\n",
    "        img_tensor = torchvision.utils.make_grid(img_tensor)\n",
    "    # Unnormalize\n",
    "    #img_tensor = unnormalize(img_tensor)\n",
    "    # Convert to numpy\n",
    "    npimg = img_tensor.numpy()\n",
    "    # Transpose from (C, H, W) to (H, W, C)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(images[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_to_bit(x : torch.Tensor) -> torch.Tensor:\n",
    "    return torch.exp(x)\n",
    "\n",
    "def bit_to_param(x : torch.Tensor) -> torch.Tensor:\n",
    "    return torch.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_float_truncate(x: torch.Tensor, e_bits_int: int, m_bits_int: int, scale_int: int) -> torch.Tensor:\n",
    "\n",
    "    sign = x.sign()\n",
    "    abs_x = x.abs().clamp(min=1e-45) / 2**scale_int\n",
    "\n",
    "    #recover the floatint point representation\n",
    "    #exponent \\in {-2**7,..,2**7-1}\n",
    "    #mantissa \\in {1.0,...,2.0}\n",
    "\n",
    "    exponent = torch.floor(torch.log2(abs_x)).clamp(min=1e-45)\n",
    "    mantissa = abs_x / (2**exponent)\n",
    "    \n",
    "    #print(\"exp: \", exponent)\n",
    "    #print(\"mantissa: \", mantissa)\n",
    "\n",
    "    # truncate exponent\n",
    "    # lets parameterize the exponent as a constant value + a variable value\n",
    "    # the constant part is 2**7-1 in standar floating point, but we will learn it\n",
    "    # the variable part \\in {0,..,2**8-1}\n",
    "    # lets say exponent = v_exponent - 2**(bits-1)-1 + c_exponent\n",
    "    # so v_exponent = exponent + 2**(bits-1)-1 - c_exponent\n",
    "    c_exponent = 0 #scale_int\n",
    "    z_exponent = (2**(e_bits_int-1)-1)\n",
    "    if e_bits_int == 0:\n",
    "        z_exponent = 0\n",
    "    v_exponent = exponent + z_exponent - c_exponent\n",
    "    \n",
    "    #print(\"v exponent: \", v_exponent)\n",
    "    \n",
    "    # the valriable part is clamped to the alloted bits\n",
    "    q_min = torch.tensor(float(0)).to(x.device)\n",
    "    q_max = 2**e_bits_int-1\n",
    "    q_v_exponent = torch.clamp(v_exponent, q_min, q_max)\n",
    "    q_exponent = q_v_exponent - z_exponent + c_exponent\n",
    "\n",
    "    #print(\"q v exponent: \", q_v_exponent)\n",
    "    #print(\"q exponent: \", q_exponent)\n",
    "\n",
    "    # truncate mantissa\n",
    "    # this just removes the less significant bits\n",
    "    m_scale = 2.0 ** m_bits_int\n",
    "    q_mantissa = torch.floor(mantissa * m_scale) / m_scale\n",
    "\n",
    "    #print(\"q mantissa \", q_mantissa)\n",
    "\n",
    "    # from quantized floatint point to float\n",
    "    fq_x = sign * (2**q_exponent) * q_mantissa * 2**scale_int\n",
    "    return fq_x\n",
    "\n",
    "class FakeFloatFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd for 'fake-float' exponent+mantissa truncation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, e_bits_param, m_bits_param, scale_param):\n",
    "        \n",
    "        # save for backward\n",
    "        ctx.save_for_backward(x, e_bits_param, m_bits_param, scale_param)\n",
    "        \n",
    "        # Round e_bits, m_bits to nearest integer for the forward pass\n",
    "        e_bits_int = int(torch.round(param_to_bit(e_bits_param)).item())\n",
    "        m_bits_int = int(torch.round(param_to_bit(m_bits_param)).item())\n",
    "        s_int = int(torch.round(scale_param).item())\n",
    "\n",
    "        out = fake_float_truncate(x, e_bits_int, m_bits_int, s_int)\n",
    "        \n",
    "        #if(m_bits_int == 0):\n",
    "        #    print(\"input\")\n",
    "        #    print(x)\n",
    "        #    print(\"output\")\n",
    "        #    print(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, e_bits_param, m_bits_param, scale_param = ctx.saved_tensors\n",
    "        \n",
    "        e_bits = param_to_bit(e_bits_param)\n",
    "        m_bits = param_to_bit(m_bits_param)\n",
    "        scale = scale_param\n",
    "                \n",
    "        e_bits_int = int(torch.round(e_bits).item())\n",
    "        m_bits_int = int(torch.round(m_bits).item())\n",
    "        scale_int = int(torch.round(scale).item())\n",
    "\n",
    "        #print(\"shape x: \", x.shape)\n",
    "        #print(\"shape grad_output: \", grad_output.shape)\n",
    "\n",
    "        # 1) Gradient wrt x: straight-through\n",
    "        grad_x = grad_output\n",
    "        \n",
    "        # 1) Gradient wrt x: approximate with central difference\n",
    "        \"\"\"\n",
    "        grad_x = None\n",
    "        if True:\n",
    "            delta = 0.01            \n",
    "\n",
    "            f_plus2  = fake_float_truncate(x + 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_plus   = fake_float_truncate(x + 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus  = fake_float_truncate(x - 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus2 = fake_float_truncate(x - 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "        \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "            grad_x = grad_output * der\n",
    "        \"\"\"\n",
    "                \n",
    "        # 2) Gradient wrt e_bits: approximate with central difference\n",
    "        grad_e_bits = None\n",
    "        if e_bits_param.requires_grad:\n",
    "            \n",
    "            if(e_bits_int < 2):\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int + 1, m_bits_int, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int    , m_bits_int, scale_int)\n",
    "                der = (f_plus - f_minus)\n",
    "            else:\n",
    "                f_plus2  = fake_float_truncate(x, e_bits_int + 2, m_bits_int, scale_int)\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int + 1, m_bits_int, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int - 1, m_bits_int, scale_int)\n",
    "                f_minus2 = fake_float_truncate(x, e_bits_int - 2, m_bits_int, scale_int)\n",
    "            \n",
    "                der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_e_bits = grad_output * der * e_bits\n",
    "        \n",
    "        # 3) Gradient wrt m_bits: approximate with central difference\n",
    "        grad_m_bits = None\n",
    "        if m_bits_param.requires_grad:\n",
    "            \n",
    "            if(m_bits_int < 2):\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int, m_bits_int + 1, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int, m_bits_int    , scale_int)\n",
    "                der = (f_plus - f_minus)\n",
    "            else:\n",
    "                f_plus2  = fake_float_truncate(x, e_bits_int, m_bits_int + 2, scale_int)\n",
    "                f_plus   = fake_float_truncate(x, e_bits_int, m_bits_int + 1, scale_int)\n",
    "                f_minus  = fake_float_truncate(x, e_bits_int, m_bits_int - 1, scale_int)\n",
    "                f_minus2 = fake_float_truncate(x, e_bits_int, m_bits_int - 2, scale_int)\n",
    "            \n",
    "                der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_m_bits = grad_output * der * m_bits\n",
    "       \n",
    "        # 4) Gradient wrt m_bits: approximate with central difference\n",
    "        grad_scale_bits = None\n",
    "        if scale_param.requires_grad:\n",
    "            \n",
    "            f_plus2  = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int + 2)\n",
    "            f_plus   = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int + 1)\n",
    "            f_minus  = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int - 1)\n",
    "            f_minus2 = fake_float_truncate(x, e_bits_int, m_bits_int, scale_int - 2)\n",
    "            \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0 \n",
    "            grad_scale_bits = grad_output * der\n",
    "             \n",
    "        return grad_x, grad_e_bits, grad_m_bits, grad_scale_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_bits  3  m_bits  15  scale  -1\n",
      "in:  tensor([-4.7316])  out:  tensor([-4.7316])\n",
      "e_bits  3  m_bits  16  scale  2\n",
      "in:  tensor([33.1811])  out:  tensor([33.1807])\n",
      "e_bits  5  m_bits  14  scale  1\n",
      "in:  tensor([-16.9213])  out:  tensor([-16.9209])\n",
      "e_bits  1  m_bits  4  scale  0\n",
      "in:  tensor([3.9190])  out:  tensor([3.8750])\n",
      "e_bits  3  m_bits  21  scale  -2\n",
      "in:  tensor([30.8143])  out:  tensor([7.7036])\n",
      "e_bits  3  m_bits  26  scale  -1\n",
      "in:  tensor([-16.8371])  out:  tensor([-8.4186])\n",
      "e_bits  5  m_bits  21  scale  -2\n",
      "in:  tensor([-48.7621])  out:  tensor([-48.7621])\n",
      "e_bits  1  m_bits  4  scale  1\n",
      "in:  tensor([24.2095])  out:  tensor([6.])\n",
      "e_bits  4  m_bits  10  scale  -1\n",
      "in:  tensor([-45.5206])  out:  tensor([-45.5000])\n",
      "e_bits  3  m_bits  2  scale  -2\n",
      "in:  tensor([41.1008])  out:  tensor([5.])\n",
      "e_bits  4  m_bits  29  scale  -1\n",
      "in:  tensor([-33.8543])  out:  tensor([-33.8543])\n",
      "e_bits  4  m_bits  2  scale  -1\n",
      "in:  tensor([-29.3971])  out:  tensor([-28.])\n",
      "e_bits  1  m_bits  22  scale  1\n",
      "in:  tensor([-29.3126])  out:  tensor([-7.3282])\n",
      "e_bits  10  m_bits  24  scale  0\n",
      "in:  tensor([12.6154])  out:  tensor([12.6154])\n",
      "e_bits  2  m_bits  22  scale  -1\n",
      "in:  tensor([33.6445])  out:  tensor([2.1028])\n",
      "e_bits  7  m_bits  0  scale  -1\n",
      "in:  tensor([14.0220])  out:  tensor([8.])\n",
      "e_bits  9  m_bits  25  scale  2\n",
      "in:  tensor([-0.7799])  out:  tensor([-0.7799])\n",
      "e_bits  2  m_bits  7  scale  2\n",
      "in:  tensor([-46.3708])  out:  tensor([-23.1250])\n",
      "e_bits  9  m_bits  20  scale  -1\n",
      "in:  tensor([-0.7125])  out:  tensor([-0.7125])\n",
      "e_bits  7  m_bits  14  scale  0\n",
      "in:  tensor([-18.6028])  out:  tensor([-18.6025])\n",
      "e_bits  3  m_bits  2  scale  0\n",
      "in:  tensor([20.9179])  out:  tensor([20.])\n",
      "e_bits  1  m_bits  10  scale  -1\n",
      "in:  tensor([0.8994])  out:  tensor([0.8994])\n",
      "e_bits  3  m_bits  2  scale  0\n",
      "in:  tensor([-26.7295])  out:  tensor([-24.])\n",
      "e_bits  10  m_bits  26  scale  -1\n",
      "in:  tensor([35.7176])  out:  tensor([35.7176])\n",
      "e_bits  7  m_bits  6  scale  2\n",
      "in:  tensor([-31.1525])  out:  tensor([-31.])\n",
      "e_bits  8  m_bits  21  scale  0\n",
      "in:  tensor([27.9455])  out:  tensor([27.9455])\n",
      "e_bits  0  m_bits  5  scale  2\n",
      "in:  tensor([39.9481])  out:  tensor([4.8750])\n",
      "e_bits  5  m_bits  3  scale  -1\n",
      "in:  tensor([-14.2519])  out:  tensor([-14.])\n",
      "e_bits  5  m_bits  4  scale  1\n",
      "in:  tensor([-8.2914])  out:  tensor([-8.])\n",
      "e_bits  0  m_bits  29  scale  2\n",
      "in:  tensor([-29.9667])  out:  tensor([-7.4917])\n",
      "e_bits  2  m_bits  7  scale  2\n",
      "in:  tensor([35.1172])  out:  tensor([17.5000])\n",
      "e_bits  2  m_bits  21  scale  -2\n",
      "in:  tensor([-34.3419])  out:  tensor([-1.0732])\n",
      "e_bits  8  m_bits  10  scale  1\n",
      "in:  tensor([7.3243])  out:  tensor([7.3242])\n",
      "e_bits  4  m_bits  19  scale  1\n",
      "in:  tensor([-40.8426])  out:  tensor([-40.8425])\n",
      "e_bits  2  m_bits  9  scale  -1\n",
      "in:  tensor([-33.9901])  out:  tensor([-2.1211])\n",
      "e_bits  9  m_bits  22  scale  -1\n",
      "in:  tensor([-11.1648])  out:  tensor([-11.1648])\n",
      "e_bits  6  m_bits  20  scale  -2\n",
      "in:  tensor([-42.2398])  out:  tensor([-42.2397])\n",
      "e_bits  8  m_bits  12  scale  0\n",
      "in:  tensor([-6.9768])  out:  tensor([-6.9766])\n",
      "e_bits  5  m_bits  25  scale  -2\n",
      "in:  tensor([-31.6827])  out:  tensor([-31.6827])\n",
      "e_bits  4  m_bits  8  scale  1\n",
      "in:  tensor([-28.0198])  out:  tensor([-28.])\n",
      "e_bits  2  m_bits  21  scale  -2\n",
      "in:  tensor([45.2850])  out:  tensor([1.4152])\n",
      "e_bits  8  m_bits  1  scale  -1\n",
      "in:  tensor([43.8932])  out:  tensor([32.])\n",
      "e_bits  1  m_bits  10  scale  0\n",
      "in:  tensor([-40.7150])  out:  tensor([-2.5430])\n",
      "e_bits  6  m_bits  19  scale  2\n",
      "in:  tensor([30.3664])  out:  tensor([30.3664])\n",
      "e_bits  8  m_bits  22  scale  0\n",
      "in:  tensor([41.3559])  out:  tensor([41.3559])\n",
      "e_bits  1  m_bits  13  scale  -2\n",
      "in:  tensor([19.7594])  out:  tensor([0.6174])\n",
      "e_bits  9  m_bits  20  scale  0\n",
      "in:  tensor([-42.2952])  out:  tensor([-42.2951])\n",
      "e_bits  1  m_bits  21  scale  0\n",
      "in:  tensor([15.9458])  out:  tensor([3.9865])\n",
      "e_bits  2  m_bits  7  scale  2\n",
      "in:  tensor([-47.9856])  out:  tensor([-23.8750])\n",
      "e_bits  1  m_bits  7  scale  2\n",
      "in:  tensor([42.2432])  out:  tensor([10.5000])\n",
      "e_bits  9  m_bits  12  scale  -1\n",
      "in:  tensor([-8.4565])  out:  tensor([-8.4551])\n",
      "e_bits  3  m_bits  9  scale  1\n",
      "in:  tensor([-21.9634])  out:  tensor([-21.9375])\n",
      "e_bits  1  m_bits  11  scale  2\n",
      "in:  tensor([34.5150])  out:  tensor([8.6250])\n",
      "e_bits  4  m_bits  17  scale  -1\n",
      "in:  tensor([26.9888])  out:  tensor([26.9888])\n",
      "e_bits  8  m_bits  12  scale  -2\n",
      "in:  tensor([21.2256])  out:  tensor([21.2227])\n",
      "e_bits  2  m_bits  23  scale  1\n",
      "in:  tensor([-4.2193])  out:  tensor([-4.2193])\n",
      "e_bits  2  m_bits  30  scale  2\n",
      "in:  tensor([-11.1855])  out:  tensor([-11.1855])\n",
      "e_bits  7  m_bits  22  scale  -2\n",
      "in:  tensor([12.5030])  out:  tensor([12.5030])\n",
      "e_bits  6  m_bits  28  scale  0\n",
      "in:  tensor([-15.2926])  out:  tensor([-15.2926])\n",
      "e_bits  5  m_bits  30  scale  -1\n",
      "in:  tensor([-10.1849])  out:  tensor([-10.1849])\n",
      "e_bits  1  m_bits  22  scale  0\n",
      "in:  tensor([20.5360])  out:  tensor([2.5670])\n",
      "e_bits  6  m_bits  5  scale  2\n",
      "in:  tensor([-40.2785])  out:  tensor([-40.])\n",
      "e_bits  6  m_bits  1  scale  0\n",
      "in:  tensor([19.1021])  out:  tensor([16.])\n",
      "e_bits  9  m_bits  25  scale  1\n",
      "in:  tensor([30.5977])  out:  tensor([30.5977])\n",
      "e_bits  9  m_bits  20  scale  -2\n",
      "in:  tensor([19.7446])  out:  tensor([19.7446])\n",
      "e_bits  0  m_bits  27  scale  1\n",
      "in:  tensor([41.9468])  out:  tensor([2.6217])\n",
      "e_bits  9  m_bits  3  scale  -2\n",
      "in:  tensor([37.3769])  out:  tensor([36.])\n",
      "e_bits  0  m_bits  3  scale  0\n",
      "in:  tensor([21.3838])  out:  tensor([1.2500])\n",
      "e_bits  8  m_bits  20  scale  0\n",
      "in:  tensor([-21.3796])  out:  tensor([-21.3796])\n",
      "e_bits  3  m_bits  15  scale  1\n",
      "in:  tensor([-0.1356])  out:  tensor([-0.1356])\n",
      "e_bits  6  m_bits  1  scale  1\n",
      "in:  tensor([16.1433])  out:  tensor([16.])\n",
      "e_bits  9  m_bits  27  scale  2\n",
      "in:  tensor([-40.3982])  out:  tensor([-40.3982])\n",
      "e_bits  8  m_bits  19  scale  -1\n",
      "in:  tensor([36.3437])  out:  tensor([36.3437])\n",
      "e_bits  0  m_bits  14  scale  -2\n",
      "in:  tensor([-29.9033])  out:  tensor([-0.4672])\n",
      "e_bits  4  m_bits  6  scale  1\n",
      "in:  tensor([34.9987])  out:  tensor([34.5000])\n",
      "e_bits  6  m_bits  8  scale  -2\n",
      "in:  tensor([35.6285])  out:  tensor([35.6250])\n",
      "e_bits  3  m_bits  1  scale  2\n",
      "in:  tensor([18.8686])  out:  tensor([16.])\n",
      "e_bits  3  m_bits  11  scale  1\n",
      "in:  tensor([22.1791])  out:  tensor([22.1719])\n",
      "e_bits  9  m_bits  20  scale  0\n",
      "in:  tensor([19.5499])  out:  tensor([19.5499])\n",
      "e_bits  2  m_bits  29  scale  0\n",
      "in:  tensor([-7.9124])  out:  tensor([-7.9124])\n",
      "e_bits  6  m_bits  29  scale  0\n",
      "in:  tensor([-38.1418])  out:  tensor([-38.1418])\n",
      "e_bits  5  m_bits  5  scale  -2\n",
      "in:  tensor([-1.0474])  out:  tensor([-1.0312])\n",
      "e_bits  3  m_bits  6  scale  0\n",
      "in:  tensor([-48.9786])  out:  tensor([-24.2500])\n",
      "e_bits  2  m_bits  6  scale  1\n",
      "in:  tensor([-36.5022])  out:  tensor([-9.1250])\n",
      "e_bits  2  m_bits  16  scale  -2\n",
      "in:  tensor([-38.6441])  out:  tensor([-1.2076])\n",
      "e_bits  7  m_bits  22  scale  0\n",
      "in:  tensor([-39.5240])  out:  tensor([-39.5240])\n",
      "e_bits  8  m_bits  19  scale  1\n",
      "in:  tensor([-39.9616])  out:  tensor([-39.9616])\n",
      "e_bits  8  m_bits  18  scale  2\n",
      "in:  tensor([37.2347])  out:  tensor([37.2346])\n",
      "e_bits  9  m_bits  4  scale  -2\n",
      "in:  tensor([-6.5954])  out:  tensor([-6.5000])\n",
      "e_bits  3  m_bits  18  scale  -2\n",
      "in:  tensor([0.8856])  out:  tensor([0.8856])\n",
      "e_bits  6  m_bits  8  scale  -1\n",
      "in:  tensor([-6.9811])  out:  tensor([-6.9688])\n",
      "e_bits  6  m_bits  3  scale  1\n",
      "in:  tensor([-24.7567])  out:  tensor([-24.])\n",
      "e_bits  8  m_bits  12  scale  -1\n",
      "in:  tensor([-37.0516])  out:  tensor([-37.0469])\n",
      "e_bits  2  m_bits  6  scale  1\n",
      "in:  tensor([42.5880])  out:  tensor([10.6250])\n",
      "e_bits  1  m_bits  16  scale  0\n",
      "in:  tensor([-26.5091])  out:  tensor([-3.3136])\n",
      "e_bits  3  m_bits  4  scale  0\n",
      "in:  tensor([-45.5234])  out:  tensor([-22.])\n",
      "e_bits  4  m_bits  15  scale  2\n",
      "in:  tensor([10.7445])  out:  tensor([10.7444])\n",
      "e_bits  7  m_bits  21  scale  -2\n",
      "in:  tensor([45.5853])  out:  tensor([45.5853])\n",
      "e_bits  4  m_bits  12  scale  2\n",
      "in:  tensor([-31.1416])  out:  tensor([-31.1406])\n",
      "e_bits  7  m_bits  15  scale  1\n",
      "in:  tensor([-10.0447])  out:  tensor([-10.0444])\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    in_test = (torch.rand(1) - 0.5)*100.0\n",
    "    e_bits = int(torch.round(torch.rand(1)*10).item())\n",
    "    m_bits = int(torch.round(torch.rand(1)*30).item())\n",
    "    scale = int(torch.round((torch.rand(1) - 0.5)*5.0).item())\n",
    "    out_test = fake_float_truncate(in_test, e_bits, m_bits, scale)\n",
    "    print(\"e_bits \", e_bits, \" m_bits \", m_bits, \" scale \", scale)\n",
    "    print(\"in: \", in_test, \" out: \", out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_fixed_truncate2(x: torch.Tensor, bits_int: int, scale_int: int, zero_point_int: int) -> torch.Tensor:\n",
    "    \n",
    "    qmin = 0\n",
    "    qmax = 2**bits_int - 1\n",
    "    \n",
    "    #from float to fixed point, and quantize accordingly\n",
    "    q_x = torch.clamp(torch.round(x * 2**(scale_int + bits_int//2) + 2**(bits_int-1) + zero_point_int), qmin, qmax)\n",
    "\n",
    "    # from quantized fixed point to float\n",
    "    fq_x = (q_x - 2**(bits_int-1) - zero_point_int) / 2**(scale_int + bits_int//2)\n",
    "        \n",
    "    return fq_x\n",
    "\n",
    "def fake_fixed_truncate(x: torch.Tensor, bits_int: int, scale_int: int, zero_point_int: int) -> torch.Tensor:\n",
    "    \n",
    "    qmin = 0\n",
    "    qmax = 2**bits_int - 1\n",
    "    \n",
    "    mantissa = x * 2**(scale_int + bits_int//2) + zero_point_int + 2**(bits_int-1)\n",
    "    \n",
    "    #from float to fixed point, and quantize accordingly\n",
    "    q_x = torch.clamp(torch.round(mantissa), qmin, qmax)\n",
    "\n",
    "    # from quantized fixed point to float\n",
    "    fq_x = (q_x - 2**(bits_int-1) - zero_point_int) / 2**(scale_int + bits_int//2)\n",
    "        \n",
    "    return fq_x\n",
    "\n",
    "class FakeFixedFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd for 'fake-float' exponent+mantissa truncation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, bits_param, scale_param, zero_point_param):\n",
    "        \n",
    "        # save for backward\n",
    "        ctx.save_for_backward(x, bits_param, scale_param, zero_point_param)\n",
    "        \n",
    "        # Round e_bits, m_bits to nearest integer for the forward pass\n",
    "        bits_int = int(torch.round(param_to_bit(bits_param)).item())\n",
    "        scale_int = int(torch.round(scale_param).item())\n",
    "        zero_point_int = int(torch.round(zero_point_param).item())\n",
    "\n",
    "        out = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int)\n",
    "        \n",
    "        #print(\"input\")\n",
    "        #print(x)\n",
    "        #print(\"output\")\n",
    "        #print(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, bits_param, scale_param, zero_point_param = ctx.saved_tensors\n",
    "        \n",
    "        bits = param_to_bit(bits_param)\n",
    "        scale = scale_param\n",
    "        zero_point = zero_point_param\n",
    "                \n",
    "        bits_int = int(torch.round(bits).item())\n",
    "        scale_int = int(torch.round(scale).item())\n",
    "        zero_point_int = int(torch.round(zero_point).item())\n",
    "\n",
    "        #print(\"shape x: \", x.shape)\n",
    "        #print(\"shape grad_output: \", grad_output.shape)\n",
    "\n",
    "        # 1) Gradient wrt x: straight-through\n",
    "        grad_x = grad_output\n",
    "        \n",
    "        # 1) Gradient wrt x: approximate with central difference\n",
    "        \"\"\"\n",
    "        grad_x = None\n",
    "        if True:\n",
    "            delta = 0.01            \n",
    "\n",
    "            f_plus2  = fake_float_truncate(x + 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_plus   = fake_float_truncate(x + 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus  = fake_float_truncate(x - 1.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "            f_minus2 = fake_float_truncate(x - 2.0*delta, e_bits_int, m_bits_int, s_int)\n",
    "        \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "            grad_x = grad_output * der\n",
    "        \"\"\"\n",
    "                \n",
    "        # 2) Gradient wrt bits: approximate with central difference\n",
    "        grad_bits = None\n",
    "        if bits_param.requires_grad:\n",
    "            if(bits_int < 2):\n",
    "                f_plus   = fake_fixed_truncate(x, bits_int + 1, scale_int, zero_point_int)\n",
    "                f_minus  = fake_fixed_truncate(x, bits_int    , scale_int, zero_point_int)\n",
    "                der = (f_plus - f_minus)\n",
    "            else:\n",
    "                f_plus2  = fake_fixed_truncate(x, bits_int + 2, scale_int, zero_point_int)\n",
    "                f_plus   = fake_fixed_truncate(x, bits_int + 1, scale_int, zero_point_int)\n",
    "                f_minus  = fake_fixed_truncate(x, bits_int - 1, scale_int, zero_point_int)\n",
    "                f_minus2 = fake_fixed_truncate(x, bits_int - 2, scale_int, zero_point_int)\n",
    "            \n",
    "                der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_bits = grad_output * der * bits\n",
    "        \n",
    "        # 3) Gradient wrt scale: approximate with central difference\n",
    "        grad_scale_bits = None\n",
    "        if scale_param.requires_grad:\n",
    "            \n",
    "            f_plus2  = fake_fixed_truncate(x, bits_int, scale_int + 2, zero_point_int)\n",
    "            f_plus   = fake_fixed_truncate(x, bits_int, scale_int + 1, zero_point_int)\n",
    "            f_minus  = fake_fixed_truncate(x, bits_int, scale_int - 1, zero_point_int)\n",
    "            f_minus2 = fake_fixed_truncate(x, bits_int, scale_int - 2, zero_point_int)\n",
    "        \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0\n",
    "            \n",
    "            grad_scale_bits = grad_output * der\n",
    "       \n",
    "        # 4) Gradient wrt m_bits: approximate with central difference\n",
    "        grad_zero_point_bits = None\n",
    "        if zero_point_param.requires_grad:\n",
    "            \n",
    "            f_plus2  = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int + 2)\n",
    "            f_plus   = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int + 1)\n",
    "            f_minus  = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int - 1)\n",
    "            f_minus2 = fake_fixed_truncate(x, bits_int, scale_int, zero_point_int - 2)\n",
    "            \n",
    "            der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / 12.0 \n",
    "            grad_zero_point_bits = grad_output * der\n",
    "             \n",
    "        return grad_x, grad_bits, grad_scale_bits, grad_zero_point_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bits  25  scale  -1  zero_point  0\n",
      "in:  tensor([20.7144])  out  tensor([20.7148])\n",
      "bits  6  scale  2  zero_point  0\n",
      "in:  tensor([-39.1586])  out  tensor([-1.])\n",
      "bits  21  scale  -2  zero_point  0\n",
      "in:  tensor([-1.3127])  out  tensor([-1.3125])\n",
      "bits  27  scale  0  zero_point  0\n",
      "in:  tensor([49.2922])  out  tensor([49.2920])\n",
      "bits  9  scale  2  zero_point  0\n",
      "in:  tensor([24.3562])  out  tensor([3.9844])\n",
      "bits  21  scale  2  zero_point  0\n",
      "in:  tensor([13.9939])  out  tensor([13.9939])\n",
      "bits  3  scale  0  zero_point  0\n",
      "in:  tensor([-40.7704])  out  tensor([-2.])\n",
      "bits  18  scale  1  zero_point  0\n",
      "in:  tensor([-21.5928])  out  tensor([-21.5928])\n",
      "bits  14  scale  2  zero_point  0\n",
      "in:  tensor([-39.3895])  out  tensor([-16.])\n",
      "bits  8  scale  -2  zero_point  0\n",
      "in:  tensor([-18.4102])  out  tensor([-18.5000])\n",
      "bits  26  scale  2  zero_point  0\n",
      "in:  tensor([-15.7469])  out  tensor([-15.7469])\n",
      "bits  18  scale  2  zero_point  0\n",
      "in:  tensor([-30.5858])  out  tensor([-30.5859])\n",
      "bits  12  scale  -1  zero_point  0\n",
      "in:  tensor([41.1332])  out  tensor([41.1250])\n",
      "bits  20  scale  2  zero_point  0\n",
      "in:  tensor([-0.6442])  out  tensor([-0.6440])\n",
      "bits  18  scale  -2  zero_point  0\n",
      "in:  tensor([-25.3189])  out  tensor([-25.3203])\n",
      "bits  4  scale  -1  zero_point  0\n",
      "in:  tensor([-34.5366])  out  tensor([-4.])\n",
      "bits  20  scale  2  zero_point  0\n",
      "in:  tensor([-18.6867])  out  tensor([-18.6868])\n",
      "bits  22  scale  2  zero_point  0\n",
      "in:  tensor([-41.2732])  out  tensor([-41.2732])\n",
      "bits  28  scale  -2  zero_point  0\n",
      "in:  tensor([-44.0468])  out  tensor([-44.0469])\n",
      "bits  9  scale  -1  zero_point  0\n",
      "in:  tensor([38.5125])  out  tensor([31.8750])\n",
      "bits  17  scale  -2  zero_point  0\n",
      "in:  tensor([22.5919])  out  tensor([22.5938])\n",
      "bits  32  scale  -1  zero_point  0\n",
      "in:  tensor([22.3238])  out  tensor([22.3203])\n",
      "bits  7  scale  2  zero_point  0\n",
      "in:  tensor([16.2316])  out  tensor([1.9688])\n",
      "bits  30  scale  2  zero_point  0\n",
      "in:  tensor([16.6813])  out  tensor([16.6812])\n",
      "bits  28  scale  -2  zero_point  0\n",
      "in:  tensor([-16.8271])  out  tensor([-16.8262])\n",
      "bits  7  scale  0  zero_point  0\n",
      "in:  tensor([14.1792])  out  tensor([7.8750])\n",
      "bits  8  scale  -2  zero_point  0\n",
      "in:  tensor([12.4835])  out  tensor([12.5000])\n",
      "bits  2  scale  1  zero_point  0\n",
      "in:  tensor([18.1347])  out  tensor([0.2500])\n",
      "bits  29  scale  -2  zero_point  0\n",
      "in:  tensor([18.4464])  out  tensor([18.4453])\n",
      "bits  3  scale  -1  zero_point  0\n",
      "in:  tensor([-16.2497])  out  tensor([-4.])\n",
      "bits  28  scale  -1  zero_point  0\n",
      "in:  tensor([26.9988])  out  tensor([26.9980])\n",
      "bits  16  scale  2  zero_point  0\n",
      "in:  tensor([-29.4354])  out  tensor([-29.4355])\n",
      "bits  20  scale  0  zero_point  0\n",
      "in:  tensor([17.6339])  out  tensor([17.6338])\n",
      "bits  31  scale  0  zero_point  0\n",
      "in:  tensor([-22.2341])  out  tensor([-22.2344])\n",
      "bits  30  scale  -2  zero_point  0\n",
      "in:  tensor([-25.1810])  out  tensor([-25.1797])\n",
      "bits  5  scale  1  zero_point  0\n",
      "in:  tensor([-37.6648])  out  tensor([-2.])\n",
      "bits  13  scale  -1  zero_point  0\n",
      "in:  tensor([-18.4802])  out  tensor([-18.4688])\n",
      "bits  8  scale  1  zero_point  0\n",
      "in:  tensor([22.9247])  out  tensor([3.9688])\n",
      "bits  31  scale  2  zero_point  0\n",
      "in:  tensor([26.1609])  out  tensor([26.1611])\n",
      "bits  22  scale  -2  zero_point  0\n",
      "in:  tensor([49.6746])  out  tensor([49.6758])\n",
      "bits  25  scale  0  zero_point  0\n",
      "in:  tensor([42.5835])  out  tensor([42.5835])\n",
      "bits  29  scale  -1  zero_point  0\n",
      "in:  tensor([-2.5450])  out  tensor([-2.5449])\n",
      "bits  12  scale  -2  zero_point  0\n",
      "in:  tensor([18.8086])  out  tensor([18.8125])\n",
      "bits  11  scale  1  zero_point  0\n",
      "in:  tensor([-10.4997])  out  tensor([-10.5000])\n",
      "bits  0  scale  0  zero_point  0\n",
      "in:  tensor([-40.8249])  out  tensor([-0.5000])\n",
      "bits  17  scale  2  zero_point  0\n",
      "in:  tensor([0.5288])  out  tensor([0.5283])\n",
      "bits  23  scale  0  zero_point  0\n",
      "in:  tensor([22.9693])  out  tensor([22.9692])\n",
      "bits  1  scale  2  zero_point  0\n",
      "in:  tensor([-18.6410])  out  tensor([-0.2500])\n",
      "bits  15  scale  -1  zero_point  0\n",
      "in:  tensor([-44.9375])  out  tensor([-44.9375])\n",
      "bits  27  scale  -1  zero_point  0\n",
      "in:  tensor([-4.1291])  out  tensor([-4.1289])\n",
      "bits  17  scale  0  zero_point  0\n",
      "in:  tensor([9.5914])  out  tensor([9.5898])\n",
      "bits  8  scale  2  zero_point  0\n",
      "in:  tensor([16.9246])  out  tensor([1.9844])\n",
      "bits  8  scale  0  zero_point  0\n",
      "in:  tensor([18.3862])  out  tensor([7.9375])\n",
      "bits  25  scale  1  zero_point  0\n",
      "in:  tensor([37.7854])  out  tensor([37.7854])\n",
      "bits  20  scale  1  zero_point  0\n",
      "in:  tensor([-40.1924])  out  tensor([-40.1924])\n",
      "bits  4  scale  0  zero_point  0\n",
      "in:  tensor([36.9607])  out  tensor([1.7500])\n",
      "bits  31  scale  -1  zero_point  0\n",
      "in:  tensor([-11.6549])  out  tensor([-11.6562])\n",
      "bits  16  scale  -1  zero_point  0\n",
      "in:  tensor([43.1338])  out  tensor([43.1328])\n",
      "bits  18  scale  -1  zero_point  0\n",
      "in:  tensor([28.8486])  out  tensor([28.8477])\n",
      "bits  3  scale  1  zero_point  0\n",
      "in:  tensor([11.8242])  out  tensor([0.7500])\n",
      "bits  2  scale  2  zero_point  0\n",
      "in:  tensor([-41.0990])  out  tensor([-0.2500])\n",
      "bits  9  scale  1  zero_point  0\n",
      "in:  tensor([10.4728])  out  tensor([7.9688])\n",
      "bits  28  scale  0  zero_point  0\n",
      "in:  tensor([-28.5828])  out  tensor([-28.5830])\n",
      "bits  24  scale  2  zero_point  0\n",
      "in:  tensor([-16.1541])  out  tensor([-16.1541])\n",
      "bits  14  scale  2  zero_point  0\n",
      "in:  tensor([-22.8603])  out  tensor([-16.])\n",
      "bits  23  scale  -2  zero_point  0\n",
      "in:  tensor([-49.2477])  out  tensor([-49.2480])\n",
      "bits  23  scale  -1  zero_point  0\n",
      "in:  tensor([-18.5207])  out  tensor([-18.5205])\n",
      "bits  13  scale  -2  zero_point  0\n",
      "in:  tensor([-29.6378])  out  tensor([-29.6250])\n",
      "bits  20  scale  -1  zero_point  0\n",
      "in:  tensor([-12.4080])  out  tensor([-12.4082])\n",
      "bits  22  scale  1  zero_point  0\n",
      "in:  tensor([30.7883])  out  tensor([30.7883])\n",
      "bits  16  scale  0  zero_point  0\n",
      "in:  tensor([21.3253])  out  tensor([21.3242])\n",
      "bits  6  scale  -2  zero_point  0\n",
      "in:  tensor([-43.5430])  out  tensor([-16.])\n",
      "bits  6  scale  0  zero_point  0\n",
      "in:  tensor([-4.8220])  out  tensor([-4.])\n",
      "bits  8  scale  0  zero_point  0\n",
      "in:  tensor([-43.8758])  out  tensor([-8.])\n",
      "bits  6  scale  1  zero_point  0\n",
      "in:  tensor([12.3160])  out  tensor([1.9375])\n",
      "bits  29  scale  1  zero_point  0\n",
      "in:  tensor([1.9190])  out  tensor([1.9189])\n",
      "bits  24  scale  -2  zero_point  0\n",
      "in:  tensor([-17.8676])  out  tensor([-17.8672])\n",
      "bits  16  scale  -1  zero_point  0\n",
      "in:  tensor([45.2726])  out  tensor([45.2734])\n",
      "bits  9  scale  -1  zero_point  0\n",
      "in:  tensor([-46.0187])  out  tensor([-32.])\n",
      "bits  12  scale  0  zero_point  0\n",
      "in:  tensor([-3.0869])  out  tensor([-3.0938])\n",
      "bits  7  scale  -2  zero_point  0\n",
      "in:  tensor([20.7323])  out  tensor([20.5000])\n",
      "bits  23  scale  0  zero_point  0\n",
      "in:  tensor([-41.5356])  out  tensor([-41.5356])\n",
      "bits  4  scale  0  zero_point  0\n",
      "in:  tensor([-34.1858])  out  tensor([-2.])\n",
      "bits  7  scale  2  zero_point  0\n",
      "in:  tensor([-16.8935])  out  tensor([-2.])\n",
      "bits  20  scale  -1  zero_point  0\n",
      "in:  tensor([0.3639])  out  tensor([0.3633])\n",
      "bits  11  scale  2  zero_point  0\n",
      "in:  tensor([-5.8168])  out  tensor([-5.8203])\n",
      "bits  0  scale  -2  zero_point  0\n",
      "in:  tensor([3.8969])  out  tensor([-2.])\n",
      "bits  11  scale  -1  zero_point  0\n",
      "in:  tensor([11.0859])  out  tensor([11.0625])\n",
      "bits  29  scale  -2  zero_point  0\n",
      "in:  tensor([44.4674])  out  tensor([44.4688])\n",
      "bits  15  scale  -2  zero_point  0\n",
      "in:  tensor([-33.9152])  out  tensor([-33.9062])\n",
      "bits  0  scale  -2  zero_point  0\n",
      "in:  tensor([47.9431])  out  tensor([-2.])\n",
      "bits  19  scale  2  zero_point  0\n",
      "in:  tensor([17.1932])  out  tensor([17.1934])\n",
      "bits  24  scale  1  zero_point  0\n",
      "in:  tensor([-2.7262])  out  tensor([-2.7261])\n",
      "bits  13  scale  -1  zero_point  0\n",
      "in:  tensor([47.1250])  out  tensor([47.1250])\n",
      "bits  5  scale  -2  zero_point  0\n",
      "in:  tensor([16.8991])  out  tensor([15.])\n",
      "bits  29  scale  -1  zero_point  0\n",
      "in:  tensor([-15.8210])  out  tensor([-15.8203])\n",
      "bits  22  scale  1  zero_point  0\n",
      "in:  tensor([4.7485])  out  tensor([4.7485])\n",
      "bits  29  scale  2  zero_point  0\n",
      "in:  tensor([39.9525])  out  tensor([39.9526])\n",
      "bits  27  scale  1  zero_point  0\n",
      "in:  tensor([-40.4445])  out  tensor([-40.4446])\n",
      "bits  29  scale  0  zero_point  0\n",
      "in:  tensor([-3.9666])  out  tensor([-3.9668])\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    bits = int(torch.round(torch.rand(1)*32).item())\n",
    "    scale = int(torch.round((torch.rand(1) - 0.5)*5.0).item())\n",
    "    zero_point = int(torch.round((torch.rand(1) - 0.5)*0.0).item())\n",
    "    in_test = (torch.rand(1)-0.5)*100.0\n",
    "    out_test = fake_fixed_truncate(in_test, bits, scale, zero_point)\n",
    "    print(\"bits \", bits, \" scale \", scale, \" zero_point \", zero_point)\n",
    "    print(\"in: \", in_test, \" out \", out_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### differentiable Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoundSTE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass: use the usual rounding\n",
    "        return torch.round(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass: pass the gradient unchanged (STE)\n",
    "        return grad_output\n",
    "    \n",
    "class RoundFDE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass: use the usual rounding\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.round(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass: pass the gradient unchanged (STE)\n",
    "        (input, ) = ctx.saved_tensors\n",
    "        delta = 1.0\n",
    "        f_plus2  = torch.round(input + 2*delta)\n",
    "        f_plus   = torch.round(input + 1*delta)\n",
    "        f_minus  = torch.round(input - 1*delta)\n",
    "        f_minus2 = torch.round(input - 2*delta)\n",
    "        # der = (f_plus - f_minus)/2.0\n",
    "        der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "        \n",
    "        return der * grad_output\n",
    "\n",
    "class RoundSIG(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd function that does a hard round in forward,\n",
    "    but uses a sigmoid-based approximation for the backward pass.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, alpha=10.0):\n",
    "        \"\"\"\n",
    "        Forward pass: returns torch.round(input).\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.alpha = alpha\n",
    "        return torch.round(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Backward pass: approximate the gradient of round(x)\n",
    "        with the derivative of a sigmoid centered at the fractional midpoint (0.5).\n",
    "        \"\"\"\n",
    "        (input,) = ctx.saved_tensors\n",
    "        alpha = ctx.alpha\n",
    "\n",
    "        # Fractional part\n",
    "        frac = input - torch.floor(input)\n",
    "\n",
    "        # Sigmoid of (fractional_part - 0.5), scaled by alpha\n",
    "        s = torch.sigmoid(alpha * (frac - 0.5))\n",
    "\n",
    "        # Derivative of sigmoid = alpha * s * (1 - s)\n",
    "        grad_input = alpha * s * (1 - s) * grad_output\n",
    "        return grad_input, None  # alpha is not a tensor that requires grad\n",
    "    \n",
    "def diff_round(x):\n",
    "    return RoundSTE.apply(x)\n",
    "    #return RoundFDE.apply(x)\n",
    "    #return RoundSIG.apply(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloorSTE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass uses standard floor\n",
    "        return torch.floor(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Straight-through pass: just return the gradient as-is\n",
    "        return grad_output\n",
    "\n",
    "class FloorFDE(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Forward pass: use the usual rounding\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.floor(input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass: pass the gradient unchanged (STE)\n",
    "        (input, ) = ctx.saved_tensors\n",
    "        delta = 1.0\n",
    "        f_plus2  = torch.floor(input + 2*delta)\n",
    "        f_plus   = torch.floor(input + 1*delta)\n",
    "        f_minus  = torch.floor(input - 1*delta)\n",
    "        f_minus2 = torch.floor(input - 2*delta)\n",
    "        # der = (f_plus - f_minus)/2.0\n",
    "        der = (-f_plus2 + 8*f_plus - 8*f_minus + f_minus2) / (12.0 * delta)\n",
    "        \n",
    "        return der * grad_output\n",
    "\n",
    "def diff_floor(input):\n",
    "    return FloorSTE.apply(input)\n",
    "    #return FloorFDE.apply(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxObserver(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We store running min/max\n",
    "        self.register_buffer(\"min_val\", torch.tensor(float(\"inf\")))\n",
    "        self.register_buffer(\"max_val\", torch.tensor(float(\"-inf\")))\n",
    "        # You could also store averaging stats, etc.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Update running min/max\n",
    "        self.min_val = torch.min(self.min_val, x.detach().min())\n",
    "        self.max_val = torch.max(self.max_val, x.detach().max())\n",
    "        return x  # Just pass through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed point quanizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPointFakeQuantize(nn.Module):\n",
    "    def __init__(self, observer, bits=32, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.observer = observer\n",
    "        self.bits = nn.Parameter(torch.tensor(float(bits)), requires_grad=requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        b_int = torch.clamp(diff_round(self.bits), 1, 32)\n",
    "        \n",
    "        # 1) Get min/max from observer\n",
    "        min_val = self.observer.min_val\n",
    "        max_val = self.observer.max_val\n",
    "\n",
    "        # If they're not valid, skip\n",
    "        #if min_val >= max_val:\n",
    "        #    return x\n",
    "\n",
    "        # 2) Compute scale and zero_point\n",
    "        # For an unsigned 4-bit range, we can hold values 0..15\n",
    "        # qmin, qmax = 0, (1 << b_int) - 1  # e.g. 0..15\n",
    "        qmin, qmax = torch.tensor(float(0)), 2**b_int - 1  # e.g. 0..15\n",
    "        \n",
    "        qmin = qmin.to(x.device)\n",
    "        #qmax = qmax.to(x.device)\n",
    "        max_val = max_val.to(x.device)\n",
    "        min_val = min_val.to(x.device)\n",
    "\n",
    "        # Typical formula for scale/zero-point:\n",
    "        scale = (max_val - min_val) / float(qmax - qmin)\n",
    "        zero_point = qmin - diff_round(min_val / scale)\n",
    "\n",
    "        # 3) Quantize (in floating point)\n",
    "        # clamp to range of [qmin, qmax]\n",
    "        q_x = torch.clamp(diff_round(x / scale + zero_point), qmin, qmax)\n",
    "\n",
    "        # 4) Dequantize back to float\n",
    "        fq_x = (q_x - zero_point) * scale\n",
    "        return fq_x\n",
    "\n",
    "    def getBits(self):\n",
    "        return [self.bits]\n",
    "\n",
    "    def printParams(self):\n",
    "        print(\"bits: \", self.bits.detach().item())\n",
    "        \n",
    "class FixedPointFakeQuantize2(nn.Module):\n",
    "    def __init__(self, bits=32, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.bits = nn.Parameter(torch.tensor(float(bits)), requires_grad=requires_grad)\n",
    "        self.scale = nn.Parameter(torch.tensor(float(bits//2)), requires_grad=requires_grad)\n",
    "        self.zero_point = nn.Parameter(torch.tensor(float(2**(bits//2-1)-1)), requires_grad=requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        bits_int = torch.clamp(diff_round(self.bits), 1, 32)\n",
    "        scale_int = diff_round(self.scale)\n",
    "        zero_point_int = diff_round(self.zero_point)\n",
    "        \n",
    "        qmin = torch.tensor(float(0)).to(x.device)\n",
    "        qmax = 2**bits_int - 1  # e.g. 0..15\n",
    "        \n",
    "        #from float to fixed point, and quantize accordingly\n",
    "        q_x = torch.clamp(diff_round(x * 2**scale_int + zero_point_int), qmin, qmax)\n",
    "\n",
    "        # from quantized fixed point to float\n",
    "        fq_x = (q_x - zero_point_int) / 2**scale_int\n",
    "        \n",
    "        return fq_x\n",
    "\n",
    "    def getBits(self):\n",
    "        return [self.bits]\n",
    "\n",
    "    def printParams(self):\n",
    "        print(\"bits: \", self.bits.detach().item())\n",
    "        print(\"scale: \", self.scale.detach().item())\n",
    "        print(\"zero point: \", self.zero_point.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point quantizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FloatingPointFakeQuantize(nn.Module):\n",
    "    def __init__(self, m_bits=23, e_bits=8, requires_grad=False):\n",
    "        super().__init__()\n",
    "        self.e_bits = nn.Parameter(torch.tensor(float(e_bits)), requires_grad=requires_grad)\n",
    "        self.m_bits = nn.Parameter(torch.tensor(float(m_bits)), requires_grad=requires_grad)\n",
    "        self.scale = nn.Parameter(torch.tensor(float(0)), requires_grad=requires_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e_bits_int = torch.clamp(diff_round(self.e_bits), 0, 32)\n",
    "        m_bits_int = torch.clamp(diff_round(self.m_bits), 1, 32)\n",
    "        scale_int = diff_round(self.scale)\n",
    "        \n",
    "        sign = x.sign()\n",
    "        abs_x = x.abs().clamp(min=1e-45)\n",
    "\n",
    "        #recover the floatint point representation\n",
    "        #exponent \\in {-2**7,..,2**7-1}\n",
    "        #mantissa \\in {1.0,...,2.0}\n",
    "\n",
    "        exponent = diff_floor(torch.log2(abs_x)).clamp(min=1e-45)\n",
    "        mantissa = abs_x / (2**exponent)\n",
    "    \n",
    "        # truncate exponent\n",
    "        # lets parameterize the exponent as a constant value + a variable value\n",
    "        # the constant part is 2**7-1 in standar floating point, but we will learn it\n",
    "        # the variable part \\in {0,..,2**8-1}\n",
    "        # lets say exponent = v_exponent - 2**(bits-1)-1 + c_exponent\n",
    "        # so v_exponent = exponent + 2**(bits-1)-1 - c_exponent\n",
    "        c_exponent = scale_int\n",
    "        v_exponent = exponent + (2**(e_bits_int-1)-1) - c_exponent\n",
    "        \n",
    "        # the valriable part is clamped to the alloted bits\n",
    "        q_min = torch.tensor(float(0)).to(x.device)\n",
    "        q_max = 2**e_bits_int-1\n",
    "        q_exponent = torch.clamp(v_exponent, q_min, q_max) - (2**(e_bits_int-1)-1) + c_exponent\n",
    "    \n",
    "        # truncate mantissa\n",
    "        # this just removes the less significant bits\n",
    "        m_scale = 2.0 ** m_bits_int\n",
    "        q_mantissa = diff_floor(mantissa * m_scale) / m_scale\n",
    "    \n",
    "        # from quantized floatint point to float\n",
    "        fq_x = sign * (2**q_exponent) * q_mantissa\n",
    "        return fq_x\n",
    "\n",
    "    def getBits(self):\n",
    "        return [self.e_bits, self.m_bits]\n",
    "\n",
    "    def printParams(self):\n",
    "        print(\"e_bits: \", self.e_bits.detach().item())\n",
    "        print(\"m_bits: \", self.m_bits.detach().item())\n",
    "        print(\"scale: \", self.scale.detach().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Float32 example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCIFAR10Model(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_size[0], 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * input_size[1]//8 * input_size[2]//8, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantWrapper(nn.Module):\n",
    "    def __init__(self, module, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.observer = MinMaxObserver()\n",
    "        self.fake_quant_input = FixedPointFakeQuantize(self.observer, requires_grad=optimizeQuant)\n",
    "        self.fake_quant_weight = FixedPointFakeQuantize(self.observer, requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_input = FixedPointFakeQuantize2(requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_weight = FixedPointFakeQuantize2(requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_input = FloatingPointFakeQuantize(requires_grad=optimizeQuant)\n",
    "        #self.fake_quant_weight = FloatingPointFakeQuantize(requires_grad=optimizeQuant)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.observer(x)\n",
    "        x = self.fake_quant_input(x)\n",
    "        w = self.fake_quant_weight(self.module.weight)\n",
    "        b = self.module.bias\n",
    "        if isinstance(self.module, nn.Conv2d):\n",
    "            return F.conv2d(x, w, b, stride=self.module.stride, padding=self.module.padding, dilation=self.module.dilation, groups=self.module.groups)\n",
    "        elif isinstance(self.module, nn.Linear):\n",
    "            return F.linear(x, w, b)\n",
    "        else:\n",
    "            return self.module(x)\n",
    "        \n",
    "    def getBits(self):\n",
    "        return self.fake_quant_input.getBits() + self.fake_quant_weight.getBits()\n",
    "        #return self.fake_quant_weight.getBits()\n",
    "    \n",
    "    def printQuantParams(self):\n",
    "        print(\"input quant params: \")\n",
    "        self.fake_quant_input.printParams()\n",
    "        print(\"weight quant params: \")\n",
    "        self.fake_quant_weight.printParams()\n",
    "\n",
    "class QuantWrapperFloatingPoint(nn.Module):\n",
    "    def __init__(self, module, e_bits=5, m_bits=10, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "        #self.input_e_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(e_bits))), requires_grad=optimizeQuant)\n",
    "        #self.input_m_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(m_bits))), requires_grad=optimizeQuant)\n",
    "        #self.input_scale = nn.Parameter(torch.tensor(0.0), requires_grad=optimizeQuant)\n",
    "        \n",
    "        self.weight_e_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(e_bits))), requires_grad=optimizeQuant)\n",
    "        self.weight_m_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(m_bits))), requires_grad=optimizeQuant)\n",
    "        self.weight_scale = nn.Parameter(torch.tensor(0.0), requires_grad=optimizeQuant)\n",
    "        \n",
    "        self.bias_e_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(e_bits))), requires_grad=False)\n",
    "        self.bias_m_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(m_bits))), requires_grad=False)\n",
    "        self.bias_scale = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        \n",
    "        self.output_e_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(e_bits))), requires_grad=optimizeQuant)\n",
    "        self.output_m_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(m_bits))), requires_grad=optimizeQuant)\n",
    "        self.output_scale = nn.Parameter(torch.tensor(0.0), requires_grad=optimizeQuant)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = FakeFloatFunction.apply(x,   self.input_e_bits_param, self.input_m_bits_param, self.input_scale)\n",
    "        \n",
    "        if hasattr(self.module, 'weight') and self.module.weight != None:\n",
    "            w = FakeFloatFunction.apply(self.module.weight, self.weight_e_bits_param, self.weight_m_bits_param, self.weight_scale)\n",
    "        else:\n",
    "            w = None\n",
    "        \n",
    "        if hasattr(self.module, 'bias') and self.module.bias != None:\n",
    "            b = FakeFloatFunction.apply(self.module.bias, self.bias_e_bits_param, self.bias_m_bits_param, self.bias_scale)\n",
    "        else:\n",
    "            b = None\n",
    "        \n",
    "        if isinstance(self.module, nn.Conv2d):\n",
    "            out = F.conv2d(x, w, b, stride=self.module.stride, padding=self.module.padding, dilation=self.module.dilation, groups=self.module.groups)\n",
    "        elif isinstance(self.module, nn.Linear):\n",
    "            out = F.linear(x, w, b)\n",
    "        else:\n",
    "            out = self.module(x)\n",
    "        \n",
    "        out = FakeFloatFunction.apply(out, self.output_e_bits_param, self.output_m_bits_param, self.output_scale)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def getBits(self):\n",
    "        #return [param_to_bit(self.input_e_bits_param) + param_to_bit(self.input_m_bits_param) + 1, param_to_bit(self.weight_e_bits_param) + param_to_bit(self.weight_m_bits_param) + 1]\n",
    "        #return [param_to_bit(self.weight_e_bits_param) + param_to_bit(self.weight_m_bits_param) + 1, param_to_bit(self.bias_e_bits_param) + param_to_bit(self.bias_m_bits_param) + 1, param_to_bit(self.output_e_bits_param) + param_to_bit(self.output_m_bits_param) + 1]\n",
    "        return [param_to_bit(self.weight_e_bits_param) + param_to_bit(self.weight_m_bits_param) + 1, param_to_bit(self.output_e_bits_param) + param_to_bit(self.output_m_bits_param) + 1]\n",
    "\n",
    "    def printQuantParams(self):\n",
    "        #print(\"input quant params: \")\n",
    "        #print(\"e bits: \", param_to_bit(self.input_e_bits_param).detach().item(), \" m bits \", param_to_bit(self.input_m_bits_param).detach().item(), \" scale \", self.input_scale.detach().item())\n",
    "        print(\"weight quant params: \")\n",
    "        print(\"e bits \", param_to_bit(self.weight_e_bits_param).detach().item(), \" m bits \", param_to_bit(self.weight_m_bits_param).detach().item(), \" scale \", self.weight_scale.detach().item())\n",
    "        print(\"bias quant params: \")\n",
    "        print(\"e bits \", param_to_bit(self.bias_e_bits_param).detach().item(), \" m bits \", param_to_bit(self.bias_m_bits_param).detach().item(), \" scale \", self.bias_scale.detach().item())\n",
    "        print(\"output quant params: \")\n",
    "        print(\"e bits: \", param_to_bit(self.output_e_bits_param).detach().item(), \" m bits \", param_to_bit(self.output_m_bits_param).detach().item(), \" scale \", self.output_scale.detach().item())\n",
    "        \n",
    "class QuantWrapperFixedPoint(nn.Module):\n",
    "    def __init__(self, module, bits=32, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "\n",
    "        #self.input_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(bits))), requires_grad=optimizeQuant)\n",
    "        #self.input_scale = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        #self.input_zero_point = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        \n",
    "        self.output_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(bits))), requires_grad=optimizeQuant)\n",
    "        self.output_scale = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        self.output_zero_point = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        \n",
    "        self.weight_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(bits))), requires_grad=optimizeQuant)\n",
    "        self.weight_scale = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        self.weight_zero_point = nn.Parameter(torch.tensor(float(0)), requires_grad=optimizeQuant)\n",
    "        \n",
    "        self.bias_bits_param = nn.Parameter(bit_to_param(torch.tensor(float(bits))), requires_grad=False)\n",
    "        self.bias_scale = nn.Parameter(torch.tensor(float(0)), requires_grad=False)\n",
    "        self.bias_zero_point = nn.Parameter(torch.tensor(float(0)), requires_grad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = FakeFixedFunction.apply(x, self.input_bits_param, self.input_scale, self.input_zero_point)\n",
    "        \n",
    "        if hasattr(self.module, 'weight') and self.module.weight != None:\n",
    "            w = FakeFixedFunction.apply(self.module.weight, self.weight_bits_param, self.weight_scale, self.weight_zero_point)\n",
    "        else:\n",
    "            w = None\n",
    "\n",
    "        if hasattr(self.module, 'bias') and self.module.bias != None:\n",
    "            b = FakeFixedFunction.apply(self.module.bias, self.bias_bits_param, self.bias_scale, self.bias_zero_point)\n",
    "        else:\n",
    "            b = None\n",
    "        \n",
    "        if isinstance(self.module, nn.Conv2d):\n",
    "            out = F.conv2d(x, w, b, stride=self.module.stride, padding=self.module.padding, dilation=self.module.dilation, groups=self.module.groups)\n",
    "        elif isinstance(self.module, nn.Linear):\n",
    "            out = F.linear(x, w, b)\n",
    "        else:\n",
    "            out = self.module(x)\n",
    "        \n",
    "        out = FakeFixedFunction.apply(out, self.output_bits_param, self.output_scale, self.output_zero_point)    \n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def getBits(self):\n",
    "        #return [param_to_bit(self.input_bits_param), param_to_bit(self.weight_bits_param)]\n",
    "        #return [param_to_bit(self.weight_bits_param), param_to_bit(self.bias_bits_param), param_to_bit(self.output_bits_param)]\n",
    "        return [param_to_bit(self.weight_bits_param), param_to_bit(self.output_bits_param)]\n",
    "\n",
    "    def printQuantParams(self):\n",
    "        #print(\"input quant params: \")\n",
    "        #print(\"bits: \", param_to_bit(self.input_bits_param).detach().item(), \" scale \", self.input_scale.detach().item(), \" zero point \", self.input_zero_point.detach().item())\n",
    "        print(\"weight quant params: \")\n",
    "        print(\"bits: \", param_to_bit(self.weight_bits_param).detach().item(), \" scale \", self.weight_scale.detach().item(), \" zero point \", self.weight_zero_point.detach().item())\n",
    "        print(\"bias quant params: \")\n",
    "        print(\"bits: \", param_to_bit(self.bias_bits_param).detach().item(), \" scale \", self.bias_scale.detach().item(), \" zero point \", self.bias_zero_point.detach().item())\n",
    "        print(\"output quant params: \")\n",
    "        print(\"bits: \", param_to_bit(self.output_bits_param).detach().item(), \" scale \", self.output_scale.detach().item(), \" zero point \", self.output_zero_point.detach().item())\n",
    "        \n",
    "class QuantSimpleCIFAR10Model(nn.Module):\n",
    "    def __init__(self, QuantClass, num_classes=10, optimizeQuant=False):\n",
    "        super().__init__()\n",
    "        self.input = QuantClass(nn.Identity(), optimizeQuant=optimizeQuant)\n",
    "        self.conv1 = QuantClass(nn.Conv2d(input_size[0], 64, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = QuantClass(nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = QuantClass(nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = QuantClass(nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv5 = QuantClass(nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.conv6 = QuantClass(nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False), optimizeQuant=optimizeQuant)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.fc7 = QuantClass(nn.Linear(256 * input_size[1]//4 * input_size[2]//4, 512), optimizeQuant=optimizeQuant)\n",
    "        self.bn7 = nn.BatchNorm1d(512)\n",
    "        self.fc8 = QuantClass(nn.Linear(512, 512), optimizeQuant=optimizeQuant)\n",
    "        self.bn8 = nn.BatchNorm1d(512)\n",
    "        self.fc9 = QuantClass(nn.Linear(512, num_classes), optimizeQuant=optimizeQuant)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n",
    "        x = self.input(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc8(x)\n",
    "        x = self.bn8(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x)\n",
    "        x = self.fc9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class squared_hinge_loss(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, predictions, targets):\n",
    "        ctx.save_for_backward(predictions, targets)\n",
    "        output = 1. - predictions.mul(targets)\n",
    "        output[output.le(0.)] = 0.\n",
    "        loss = torch.mean(output.mul(output))\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        predictions, targets = ctx.saved_tensors\n",
    "        output = 1. - predictions.mul(targets)\n",
    "        output[output.le(0.)] = 0.\n",
    "        grad_output.resize_as_(predictions).copy_(targets).mul_(-2.).mul_(output)\n",
    "        grad_output.mul_(output.ne(0).float())\n",
    "        grad_output.div_(predictions.numel())\n",
    "        return grad_output, None\n",
    "\n",
    "\n",
    "class SqrHingeLoss(nn.Module):\n",
    "    # Squared Hinge Loss\n",
    "    def __init__(self):\n",
    "        super(SqrHingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return squared_hinge_loss.apply(input, target)\n",
    "    \n",
    "def label_smoothing_loss(pred, target, smoothing=0.1):\n",
    "    confidence = 1.0 - smoothing\n",
    "    log_probs = F.log_softmax(pred, dim=-1)\n",
    "    nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "    nll_loss = nll_loss.squeeze(1)\n",
    "    smooth_loss = -log_probs.mean(dim=-1)\n",
    "    loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitwidth_squared(model):\n",
    "    s = 0.0\n",
    "    c = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            for bit in module.getBits():\n",
    "                s += bit ** 2\n",
    "                c += 1\n",
    "    if c == 0:\n",
    "        return 0\n",
    "    return s/c\n",
    "\n",
    "def bitwidth_sum(model):\n",
    "    s = 0.0\n",
    "    c = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            for bit in module.getBits():\n",
    "                s += bit\n",
    "                c += 1\n",
    "    if c==0:\n",
    "        return 0\n",
    "    return s/c\n",
    "\n",
    "def bitwidth_round_sum(model):\n",
    "    s = 0.0\n",
    "    c = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            for bit in module.getBits():\n",
    "                s += torch.round(bit)\n",
    "                c += 1\n",
    "    if c==0:\n",
    "        return 0\n",
    "    return s/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printBitWidths(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, QuantWrapperFixedPoint) or isinstance(module, QuantWrapperFloatingPoint):\n",
    "            print(\"module: \", name)\n",
    "            module.printQuantParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, bit_width_criterion, scheduler=None, lambda_bw=1e-1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        if isinstance(criterion, SqrHingeLoss):\n",
    "            target = target.unsqueeze(1)\n",
    "            target_onehot = torch.Tensor(target.size(0), len(classes)).to(device, non_blocking=True)\n",
    "            target_onehot.fill_(-1)\n",
    "            target_onehot.scatter_(1, target, 1)\n",
    "            target = target.squeeze()\n",
    "            target = target_onehot\n",
    "                    \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_ce = criterion(output, target)\n",
    "        penalty_bw = bit_width_criterion(model) \n",
    "        loss = loss_ce + lambda_bw*penalty_bw\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        #if batch_idx % 200 == 0:\n",
    "        #    print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \"\n",
    "        #          f\"({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Train set: Average loss: {train_loss:.4f}\")\n",
    "\n",
    "def test(model, device, test_loader, criterion, bit_width_criterion, lambda_bw=1e-1):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    penalty_bw = bit_width_criterion(model) \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            if isinstance(criterion, SqrHingeLoss):\n",
    "                target = target.unsqueeze(1)\n",
    "                target_onehot = torch.Tensor(target.size(0), len(classes)).to(device, non_blocking=True)\n",
    "                target_onehot.fill_(-1)\n",
    "                target_onehot.scatter_(1, target, 1)\n",
    "                target = target.squeeze()\n",
    "                target = target_onehot\n",
    "\n",
    "            loss_ce = criterion(output, target)\n",
    "            loss = loss_ce + lambda_bw*penalty_bw\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    print(f\"Test set: Average loss: {test_loss:.4f}, Accuracy: {accuracy} ({100.0*accuracy:.2f}%) bit penalty {penalty_bw}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using divice  cuda\n",
      "Train set: Average loss: 3.6074\n",
      "Test set: Average loss: 3.3868, Accuracy: 0.3332 (33.32%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 3.1374\n",
      "Test set: Average loss: 3.0448, Accuracy: 0.4726 (47.26%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.8900\n",
      "Test set: Average loss: 2.9664, Accuracy: 0.5218 (52.18%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.6767\n",
      "Test set: Average loss: 2.9203, Accuracy: 0.5499 (54.99%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.5236\n",
      "Test set: Average loss: 2.7250, Accuracy: 0.6201 (62.01%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.4275\n",
      "Test set: Average loss: 2.5026, Accuracy: 0.6798 (67.98%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.3332\n",
      "Test set: Average loss: 2.4521, Accuracy: 0.7071 (70.71%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.2585\n",
      "Test set: Average loss: 2.4083, Accuracy: 0.7221 (72.21%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.1758\n",
      "Test set: Average loss: 2.2975, Accuracy: 0.7597 (75.97%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.1205\n",
      "Test set: Average loss: 2.2349, Accuracy: 0.7903 (79.03%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.0821\n",
      "Test set: Average loss: 2.3972, Accuracy: 0.734 (73.40%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.0372\n",
      "Test set: Average loss: 2.1043, Accuracy: 0.8313 (83.13%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 2.0033\n",
      "Test set: Average loss: 2.1339, Accuracy: 0.8187 (81.87%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 1.9763\n",
      "Test set: Average loss: 2.0929, Accuracy: 0.8326 (83.26%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 1.9445\n",
      "Test set: Average loss: 2.1469, Accuracy: 0.8236 (82.36%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 1.9203\n",
      "Test set: Average loss: 2.0875, Accuracy: 0.8424 (84.24%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "Train set: Average loss: 1.8987\n",
      "Test set: Average loss: 2.1042, Accuracy: 0.8384 (83.84%) bit penalty 16.0\n",
      "module:  input\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv1\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv2\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv3\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv4\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv5\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  conv6\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc7\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc8\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n",
      "module:  fc9\n",
      "weight quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "bias quant params: \n",
      "e bits  5.000000476837158  m bits  10.0  scale  0.0\n",
      "output quant params: \n",
      "e bits:  5.000000476837158  m bits  10.0  scale  0.0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"using divice \", device)\n",
    "\n",
    "QuantClass = QuantWrapperFloatingPoint\n",
    "#QuantClass = QuantWrapperFixedPoint\n",
    "\n",
    "base_model_path = f\"train_weights_and_quant_{QuantClass.__name__}_{dataset}_base_model.pth\"\n",
    "best_accuracy_model_path = f\"train_weights_and_quant_{QuantClass.__name__}_{dataset}_best_accuracy_model.pth\"\n",
    "less_bits_model_path = f\"train_weights_and_quant_{QuantClass.__name__}_{dataset}_less_bits_model.pth\"\n",
    "\n",
    "load_model_path = None\n",
    "if(os.path.isfile(best_accuracy_model_path)):\n",
    "    load_model_path = best_accuracy_model_path\n",
    "elif(os.path.isfile(base_model_path)):\n",
    "    load_model_path = base_model_path   \n",
    "else:\n",
    "    best_accuracy_model_path = base_model_path\n",
    "    less_bits_model_path = base_model_path\n",
    "\n",
    "if(load_model_path):\n",
    "    # Create model\n",
    "    # model = SimpleQuantizedMLP(e_bits=4.0, m_bits=4.0, num_classes=len(classes)).to(device)\n",
    "    model = QuantSimpleCIFAR10Model(QuantClass, num_classes=len(classes), optimizeQuant=True).to(device)\n",
    "    #model = SimpleCIFAR10Model(num_classes=len(classes)).to(device)\n",
    "    model.load_state_dict(torch.load(load_model_path, weights_only=True))\n",
    "else:\n",
    "    model = QuantSimpleCIFAR10Model(QuantClass, num_classes=len(classes), optimizeQuant=False).to(device)\n",
    "\n",
    "#criterion = SqrHingeLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = label_smoothing_loss\n",
    "\n",
    "bit_width_criterion = bitwidth_sum\n",
    "\n",
    "# Create optimizer (SGD or Adam)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)  # Adjusted Cosine Annealing with warm-up strategy\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_penalty_bw = 100000.0\n",
    "# Train for some epochs\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, criterion, bit_width_criterion, epoch)\n",
    "    if scheduler != None:\n",
    "        scheduler.step()\n",
    "    accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "    penalty_bw = bitwidth_sum(model)\n",
    "    if(accuracy > best_accuracy):\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), best_accuracy_model_path)\n",
    "    if(penalty_bw < best_penalty_bw):\n",
    "        best_penalty_bw = penalty_bw\n",
    "        torch.save(model.state_dict(), less_bits_model_path)\n",
    "    printBitWidths(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(base_model_path, weights_only=True))\n",
    "base_accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "base_penalty_bw = bitwidth_round_sum(model).detach().item()\n",
    "model.load_state_dict(torch.load(best_accuracy_model_path, weights_only=True))\n",
    "best_accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "best_accuracy_penalty_bw = bitwidth_round_sum(model).detach().item()\n",
    "model.load_state_dict(torch.load(less_bits_model_path, weights_only=True))\n",
    "lest_bits_accuracy = test(model, device, test_loader, criterion, bit_width_criterion)\n",
    "less_bits_penalty_bw = bitwidth_round_sum(model).detach().item()\n",
    "print(\"base model accuracy: \", base_accuracy, \" penalty bw \", base_penalty_bw)\n",
    "print(\"best accuracy model accuracy: \", best_accuracy, \" penalty bw \", best_accuracy_penalty_bw)\n",
    "print(\"less bits model accuracy: \", lest_bits_accuracy, \" penalty bw \", less_bits_penalty_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_bits_model_path = f\"train_weights_and_quant_{QuantClass.__name__}_{dataset}_best_accuracy_model.pth\"\n",
    "pickle_path = f\"train_weights_and_quant_{QuantClass.__name__}_{dataset}.pkl\"\n",
    "state_dict = torch.load(best_accuracy_model_path, weights_only=True)\n",
    "state_dict_numpy = {}\n",
    "\n",
    "for key in state_dict:\n",
    "    #print(f\"{key}: {type(state_dict[key])}\")\n",
    "    state_dict_numpy[key] = state_dict[key].cpu().detach().numpy().tolist()\n",
    "    #print(key)\n",
    "    #print(state_dict_numpy[key])\n",
    "\n",
    "with open(\"mnist_cnn.pkl\", \"wb\") as f:\n",
    "    pickle.dump(state_dict_numpy, f)\n",
    "\n",
    "printBitWidths(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
