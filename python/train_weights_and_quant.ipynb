{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 1) MNIST Dataset & Dataloaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset,  batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_float_truncate(x: torch.Tensor, e_bits: int, m_bits: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Approximate 'float' with e_bits exponent bits and m_bits mantissa bits.\n",
    "    Simplified approach: unbiased exponent in integer range + truncated mantissa.\n",
    "    \"\"\"\n",
    "    eps = 1e-45\n",
    "    abs_x = x.abs().clamp(min=eps)\n",
    "    sign = x.sign()\n",
    "    \n",
    "    # exponent\n",
    "    e = torch.floor(torch.log2(abs_x))\n",
    "    min_e = -(2**(e_bits)) + 1\n",
    "    max_e =  (2**(e_bits)) - 1\n",
    "    e_clamped = torch.clamp(e, min_e, max_e)\n",
    "    \n",
    "    # fraction in [1,2) if x >= eps\n",
    "    frac = abs_x / (2.0 ** e_clamped)\n",
    "    \n",
    "    # truncate mantissa\n",
    "    scale = 2.0 ** m_bits\n",
    "    frac_trunc = torch.floor(frac * scale) / scale\n",
    "    \n",
    "    return sign * (2.0 ** e_clamped) * frac_trunc\n",
    "\n",
    "\n",
    "class FakeFloatFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd for 'fake-float' exponent+mantissa truncation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, e_bits, m_bits):\n",
    "        # save for backward\n",
    "        ctx.save_for_backward(x, e_bits, m_bits)\n",
    "        \n",
    "        # Round e_bits, m_bits to nearest integer for the forward pass\n",
    "        e_bits_int = int(torch.round(e_bits).clamp(min=0.0).item())\n",
    "        m_bits_int = int(torch.round(m_bits).clamp(min=1.0).item())\n",
    "        \n",
    "        out = fake_float_truncate(x, e_bits_int, m_bits_int)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, e_bits, m_bits = ctx.saved_tensors\n",
    "        \n",
    "        # 1) Gradient wrt x: straight-through\n",
    "        grad_x = grad_output.clone()\n",
    "        \n",
    "        e_bits_int = int(torch.round(e_bits).clamp(min=0).item())\n",
    "        m_bits_int = int(torch.round(m_bits).clamp(min=1).item())\n",
    "        \n",
    "        # 2) Gradient wrt e_bits: approximate with central difference\n",
    "        grad_e_bits = None\n",
    "        if e_bits.requires_grad:\n",
    "            delta = 1\n",
    "            e_plus2_int  = int(torch.round(e_bits + 2*delta).clamp(min=0).item())\n",
    "            e_plus_int   = int(torch.round(e_bits + delta).clamp(min=0).item())\n",
    "            e_minus_int  = int(torch.round(e_bits - delta).clamp(min=0).item())\n",
    "            e_minus2_int = int(torch.round(e_bits - 2*delta).clamp(min=0).item())\n",
    "            \n",
    "            f_plus2  = fake_float_truncate(x, e_plus2_int,  m_bits_int)\n",
    "            f_plus   = fake_float_truncate(x, e_plus_int,   m_bits_int)\n",
    "            f_minus  = fake_float_truncate(x, e_minus_int,  m_bits_int)\n",
    "            f_minus2 = fake_float_truncate(x, e_minus2_int, m_bits_int)\n",
    "            \n",
    "            #diff_e = (f_plus - f_minus) * grad_output\n",
    "            #grad_e_bits = diff_e.sum() / (2.0 * delta)\n",
    "            \n",
    "            diff_e = -f_plus2 + 8*f_plus - 8*f_minus + f_minus2\n",
    "            grad_e_bits = diff_e.sum() / (12.0 * delta)\n",
    "        \n",
    "        # 3) Gradient wrt m_bits: approximate with central difference\n",
    "        grad_m_bits = None\n",
    "        if m_bits.requires_grad:\n",
    "            delta = 1.0\n",
    "            m_plus2_int  = int(torch.round(m_bits + 2*delta).clamp(min=1).item())\n",
    "            m_plus_int   = int(torch.round(m_bits + delta).clamp(min=1).item())\n",
    "            m_minus_int  = int(torch.round(m_bits - delta).clamp(min=1).item())\n",
    "            m_minus2_int = int(torch.round(m_bits - 2*delta).clamp(min=1).item())\n",
    "            \n",
    "            f_plus2  = fake_float_truncate(x, e_bits_int, m_plus2_int)\n",
    "            f_plus   = fake_float_truncate(x, e_bits_int, m_plus_int)\n",
    "            f_minus  = fake_float_truncate(x, e_bits_int, m_minus_int)\n",
    "            f_minus2 = fake_float_truncate(x, e_bits_int, m_minus2_int)\n",
    "            \n",
    "            #diff_e = (f_plus - f_minus) * grad_output\n",
    "            #grad_e_bits = diff_e.sum() / (2.0 * delta)\n",
    "            \n",
    "            diff_e = -f_plus2 + 8*f_plus - 8*f_minus + f_minus2\n",
    "            grad_m_bits = diff_e.sum() / (12.0 * delta)\n",
    "        \n",
    "        return grad_x, grad_e_bits, grad_m_bits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleQuantizedMLP(nn.Module):\n",
    "    def __init__(self, e_bits=4.0, m_bits=4.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "        # Now we make them trainable:\n",
    "        self.e_bits = nn.Parameter(torch.tensor(e_bits))\n",
    "        self.m_bits = nn.Parameter(torch.tensor(m_bits))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        w1 = FakeFloatFunction.apply(self.fc1.weight, self.e_bits, self.m_bits)\n",
    "        b1 = FakeFloatFunction.apply(self.fc1.bias,   self.e_bits, self.m_bits)\n",
    "        x  = F.relu(F.linear(x, w1, b1))\n",
    "\n",
    "        w2 = FakeFloatFunction.apply(self.fc2.weight, self.e_bits, self.m_bits)\n",
    "        b2 = FakeFloatFunction.apply(self.fc2.bias,   self.e_bits, self.m_bits)\n",
    "        x  = F.linear(x, w2, b2)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SimpleQuantizedCNN(nn.Module):\n",
    "    def __init__(self, e_bits=4.0, m_bits=4.0):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,  out_channels=16, kernel_size=3, padding=1)        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(32 * 28 * 28, 10)\n",
    "\n",
    "        self.input_e_bits = nn.Parameter(torch.tensor(e_bits), requires_grad=True)\n",
    "        self.input_m_bits = nn.Parameter(torch.tensor(m_bits), requires_grad=True)\n",
    "\n",
    "        self.output_e_bits = nn.Parameter(torch.tensor(e_bits), requires_grad=True)\n",
    "        self.output_m_bits = nn.Parameter(torch.tensor(m_bits), requires_grad=True)\n",
    "        \n",
    "        self.w_e_bits = nn.ParameterList([\n",
    "            nn.Parameter(torch.tensor(e_bits), requires_grad=True),  # layer 0\n",
    "            nn.Parameter(torch.tensor(e_bits), requires_grad=True),  # layer 1\n",
    "            nn.Parameter(torch.tensor(e_bits), requires_grad=True),\n",
    "        ])\n",
    "        \n",
    "        self.w_m_bits = nn.ParameterList([\n",
    "            nn.Parameter(torch.tensor(m_bits), requires_grad=True),  # layer 0\n",
    "            nn.Parameter(torch.tensor(m_bits), requires_grad=True),  # layer 1\n",
    "            nn.Parameter(torch.tensor(m_bits), requires_grad=True),\n",
    "        ])\n",
    "          \n",
    "        self.b_e_bits = nn.ParameterList([\n",
    "            nn.Parameter(torch.tensor(e_bits), requires_grad=True),  # layer 0\n",
    "            nn.Parameter(torch.tensor(e_bits), requires_grad=True),  # layer 1\n",
    "            nn.Parameter(torch.tensor(e_bits), requires_grad=True),\n",
    "        ])\n",
    "        \n",
    "        self.b_m_bits = nn.ParameterList([\n",
    "            nn.Parameter(torch.tensor(m_bits), requires_grad=True),  # layer 0\n",
    "            nn.Parameter(torch.tensor(m_bits), requires_grad=True),  # layer 1\n",
    "            nn.Parameter(torch.tensor(m_bits), requires_grad=True),\n",
    "        ])\n",
    "              \n",
    "    def forward(self, x):\n",
    "        x = FakeFloatFunction.apply(x, self.input_e_bits, self.input_m_bits)\n",
    "        \n",
    "        w1 = FakeFloatFunction.apply(self.conv1.weight, self.w_e_bits[0], self.w_m_bits[0])\n",
    "        b1 = FakeFloatFunction.apply(self.conv1.bias,   self.b_e_bits[0], self.b_m_bits[0]) if self.conv1.bias is not None else None\n",
    "        x  = F.relu(F.conv2d(x, w1, b1, stride=1, padding=1))\n",
    "\n",
    "        w2 = FakeFloatFunction.apply(self.conv2.weight, self.w_e_bits[1], self.w_m_bits[1])\n",
    "        b2 = FakeFloatFunction.apply(self.conv2.bias,   self.b_e_bits[1], self.b_m_bits[1]) if self.conv2.bias is not None else None\n",
    "        x  = F.relu(F.conv2d(x, w2, b2, stride=1, padding=1))\n",
    "\n",
    "        x  = x.view(x.size(0), -1)\n",
    "        \n",
    "        w_fc = FakeFloatFunction.apply(self.fc.weight, self.w_e_bits[2], self.w_m_bits[2])\n",
    "        b_fc = FakeFloatFunction.apply(self.fc.bias,   self.b_e_bits[2], self.b_m_bits[2])\n",
    "        x  = F.linear(x, w_fc, b_fc)\n",
    "\n",
    "        x = FakeFloatFunction.apply(x, self.output_e_bits, self.output_m_bits)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def printBitWidths(self):\n",
    "        print(f\"Input e_bits \", self.input_e_bits.item(), \" m_bits \", self.input_m_bits.item())\n",
    "        print(f\"Output e_bits \", self.output_e_bits.item(), \" m_bits \", self.output_m_bits.item())\n",
    "        for i, (eb, mb) in enumerate(zip(self.w_e_bits, self.w_m_bits)):\n",
    "            print(f\"Layer {i} weight e_bits (float) = {eb.item()},  m_bits (float) = {mb.item()}\")\n",
    "        for i, (eb, mb) in enumerate(zip(self.b_e_bits, self.b_m_bits)):\n",
    "            print(f\"Layer {i} bias e_bits (float) = {eb.item()},  m_bits (float) = {mb.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitwidth_penalty(model, lambda_bw=1e-3):\n",
    "    \"\"\"\n",
    "    Computes a penalty term for the bitwidth parameters in 'model'.\n",
    "    'lambda_bw' is the weight/scale for this regularization.\n",
    "    \"\"\"\n",
    "    penalty = 0.0\n",
    "    \n",
    "    penalty += 4.0*model.input_e_bits*model.input_e_bits + model.input_m_bits*model.input_m_bits\n",
    "    penalty += 4.0*model.output_e_bits*model.output_e_bits + model.output_m_bits*model.output_m_bits\n",
    "    \n",
    "    # If the model has multiple layers with e_bits and m_bits in a ParameterList:\n",
    "    for eb, mb in zip(model.w_e_bits, model.w_m_bits):\n",
    "        # Option A: Penalize the raw float value (the \"continuous\" version)\n",
    "        penalty += 4.0*eb*eb + mb*mb\n",
    "        \n",
    "        # Option B (alternative): Penalize the rounded integer version\n",
    "        # penalty += torch.round(eb) + torch.round(mb)\n",
    "    \n",
    "    for eb, mb in zip(model.b_e_bits, model.b_m_bits):\n",
    "        penalty += 4.0*eb*eb + mb*mb\n",
    "            \n",
    "    return lambda_bw * penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, lambda_bw=1e-3):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_ce = F.cross_entropy(output, target)\n",
    "        penalty_bw = bitwidth_penalty(model, lambda_bw) \n",
    "        loss = loss_ce + penalty_bw\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \"\n",
    "                  f\"({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}\"\n",
    "          f\" ({accuracy:.2f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 8.961054\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 5.999619\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 5.203220\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 4.479943\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 3.995752\n",
      "\n",
      "Test set: Average loss: 0.0680, Accuracy: 9788/10000 (97.88%)\n",
      "\n",
      "Input e_bits  3.7857253551483154  m_bits  19.797115325927734\n",
      "Output e_bits  3.783262014389038  m_bits  19.923742294311523\n",
      "Layer 0 weight e_bits (float) = 3.78328800201416,  m_bits (float) = 19.92359161376953\n",
      "Layer 1 weight e_bits (float) = 3.7832722663879395,  m_bits (float) = 19.923786163330078\n",
      "Layer 2 weight e_bits (float) = 3.782982587814331,  m_bits (float) = 19.923580169677734\n",
      "Layer 0 bias e_bits (float) = 3.783287763595581,  m_bits (float) = 19.9235897064209\n",
      "Layer 1 bias e_bits (float) = 3.783287525177002,  m_bits (float) = 19.923603057861328\n",
      "Layer 2 bias e_bits (float) = 3.783287763595581,  m_bits (float) = 19.92359733581543\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 3.643143\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 3.261575\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.983214\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.693584\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.627723\n",
      "\n",
      "Test set: Average loss: 0.0466, Accuracy: 9853/10000 (98.53%)\n",
      "\n",
      "Input e_bits  2.4999098777770996  m_bits  17.499897003173828\n",
      "Output e_bits  1.7866649627685547  m_bits  16.518877029418945\n",
      "Layer 0 weight e_bits (float) = 1.7762789726257324,  m_bits (float) = 16.509624481201172\n",
      "Layer 1 weight e_bits (float) = 1.7884879112243652,  m_bits (float) = 16.516141891479492\n",
      "Layer 2 weight e_bits (float) = 1.9568943977355957,  m_bits (float) = 16.5758113861084\n",
      "Layer 0 bias e_bits (float) = 1.7759450674057007,  m_bits (float) = 16.50956916809082\n",
      "Layer 1 bias e_bits (float) = 1.776350975036621,  m_bits (float) = 16.509851455688477\n",
      "Layer 2 bias e_bits (float) = 1.776092767715454,  m_bits (float) = 16.50969123840332\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.339271\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.178759\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.062692\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.900680\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.783298\n",
      "\n",
      "Test set: Average loss: 0.0444, Accuracy: 9864/10000 (98.64%)\n",
      "\n",
      "Input e_bits  2.500605821609497  m_bits  17.499719619750977\n",
      "Output e_bits  0.7521922588348389  m_bits  13.803191184997559\n",
      "Layer 0 weight e_bits (float) = 0.8373854160308838,  m_bits (float) = 13.682734489440918\n",
      "Layer 1 weight e_bits (float) = 1.1488665342330933,  m_bits (float) = 13.928500175476074\n",
      "Layer 2 weight e_bits (float) = 2.4300358295440674,  m_bits (float) = 14.356941223144531\n",
      "Layer 0 bias e_bits (float) = 0.8299344182014465,  m_bits (float) = 13.677651405334473\n",
      "Layer 1 bias e_bits (float) = 0.8412641882896423,  m_bits (float) = 13.686620712280273\n",
      "Layer 2 bias e_bits (float) = 0.8349438309669495,  m_bits (float) = 13.681645393371582\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.757174\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.621007\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.550267\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.471833\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.436041\n",
      "\n",
      "Test set: Average loss: 0.0555, Accuracy: 9837/10000 (98.37%)\n",
      "\n",
      "Input e_bits  2.5003061294555664  m_bits  17.499746322631836\n",
      "Output e_bits  0.15563815832138062  m_bits  11.752137184143066\n",
      "Layer 0 weight e_bits (float) = 0.40365636348724365,  m_bits (float) = 11.354379653930664\n",
      "Layer 1 weight e_bits (float) = 1.5224663019180298,  m_bits (float) = 12.34865665435791\n",
      "Layer 2 weight e_bits (float) = 2.62656569480896,  m_bits (float) = 12.257060050964355\n",
      "Layer 0 bias e_bits (float) = 0.3733854293823242,  m_bits (float) = 11.30424690246582\n",
      "Layer 1 bias e_bits (float) = 0.42747730016708374,  m_bits (float) = 11.38586139678955\n",
      "Layer 2 bias e_bits (float) = 0.3976694941520691,  m_bits (float) = 11.346540451049805\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.354471\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.271205\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.237687\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.185556\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.168110\n",
      "\n",
      "Test set: Average loss: 0.0421, Accuracy: 9870/10000 (98.70%)\n",
      "\n",
      "Input e_bits  2.4997730255126953  m_bits  17.499759674072266\n",
      "Output e_bits  -0.24735064804553986  m_bits  10.493688583374023\n",
      "Layer 0 weight e_bits (float) = 0.23001718521118164,  m_bits (float) = 9.53607177734375\n",
      "Layer 1 weight e_bits (float) = 2.367969274520874,  m_bits (float) = 11.057662010192871\n",
      "Layer 2 weight e_bits (float) = 3.5017905235290527,  m_bits (float) = 10.31244945526123\n",
      "Layer 0 bias e_bits (float) = 0.12117442488670349,  m_bits (float) = 9.192717552185059\n",
      "Layer 1 bias e_bits (float) = 0.28092849254608154,  m_bits (float) = 9.695679664611816\n",
      "Layer 2 bias e_bits (float) = 0.1992093026638031,  m_bits (float) = 9.435531616210938\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.104588\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.094017\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.050254\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.013923\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.989629\n",
      "\n",
      "Test set: Average loss: 0.0517, Accuracy: 9852/10000 (98.52%)\n",
      "\n",
      "Input e_bits  2.499019145965576  m_bits  17.499866485595703\n",
      "Output e_bits  -0.5000420808792114  m_bits  10.242464065551758\n",
      "Layer 0 weight e_bits (float) = 0.24760811030864716,  m_bits (float) = 8.30179214477539\n",
      "Layer 1 weight e_bits (float) = 2.500026226043701,  m_bits (float) = 10.373191833496094\n",
      "Layer 2 weight e_bits (float) = 3.5005414485931396,  m_bits (float) = 8.802542686462402\n",
      "Layer 0 bias e_bits (float) = -0.12746693193912506,  m_bits (float) = 6.944036960601807\n",
      "Layer 1 bias e_bits (float) = 0.31980791687965393,  m_bits (float) = 8.760418891906738\n",
      "Layer 2 bias e_bits (float) = 0.1255340874195099,  m_bits (float) = 8.04894733428955\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.956595\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.955573\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.915154\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.891130\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.860399\n",
      "\n",
      "Test set: Average loss: 0.0527, Accuracy: 9852/10000 (98.52%)\n",
      "\n",
      "Input e_bits  2.4991447925567627  m_bits  17.498933792114258\n",
      "Output e_bits  -0.49967917799949646  m_bits  10.01502513885498\n",
      "Layer 0 weight e_bits (float) = 0.29201459884643555,  m_bits (float) = 7.542243003845215\n",
      "Layer 1 weight e_bits (float) = 2.5008466243743896,  m_bits (float) = 10.139830589294434\n",
      "Layer 2 weight e_bits (float) = 3.51293683052063,  m_bits (float) = 7.6971964836120605\n",
      "Layer 0 bias e_bits (float) = -0.5008471608161926,  m_bits (float) = 0.4975017309188843\n",
      "Layer 1 bias e_bits (float) = 0.5082710385322571,  m_bits (float) = 8.43107795715332\n",
      "Layer 2 bias e_bits (float) = 0.17945992946624756,  m_bits (float) = 6.946695804595947\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.849723\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.832479\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.830051\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.822664\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.820339\n",
      "\n",
      "Test set: Average loss: 0.0519, Accuracy: 9857/10000 (98.57%)\n",
      "\n",
      "Input e_bits  2.500189781188965  m_bits  17.499753952026367\n",
      "Output e_bits  -0.5003736615180969  m_bits  9.795424461364746\n",
      "Layer 0 weight e_bits (float) = 0.23611341416835785,  m_bits (float) = 6.784553050994873\n",
      "Layer 1 weight e_bits (float) = 2.499957799911499,  m_bits (float) = 10.030824661254883\n",
      "Layer 2 weight e_bits (float) = 3.5250117778778076,  m_bits (float) = 7.262707710266113\n",
      "Layer 0 bias e_bits (float) = -0.5028790831565857,  m_bits (float) = 0.4938392639160156\n",
      "Layer 1 bias e_bits (float) = 1.0416944026947021,  m_bits (float) = 7.633176803588867\n",
      "Layer 2 bias e_bits (float) = 0.3129003942012787,  m_bits (float) = 6.4998674392700195\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.814744\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.803513\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.808210\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     test(model, device, test_loader)\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m.\u001b[39mprintBitWidths()\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, lambda_bw)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, device, train_loader, optimizer, epoch, lambda_bw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m):\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/datasets/mnist.py:143\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    139\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:3090\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3088\u001b[0m shape \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3089\u001b[0m ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[0;32m-> 3090\u001b[0m strides \u001b[38;5;241m=\u001b[39m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3092\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Create model\n",
    "# model = SimpleQuantizedMLP(e_bits=4.0, m_bits=4.0).to(device)\n",
    "model = SimpleQuantizedCNN(e_bits=8.0, m_bits=24.0).to(device)\n",
    "\n",
    "# Create optimizer (SGD or Adam)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# or: optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train for some epochs\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    model.printBitWidths()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
