{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay, allocate, PL\n",
    "import struct\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pickle\n",
    "from array import array\n",
    "from os.path  import join\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PL.reset()\n",
    "overlay = Overlay('cnn_fpga.bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP blocks : ['dot_0', 'conv2D_3x3_0', 'ReLU_0', 'MaxPooling2D_0', 'axi_dma_in1', 'axi_dma_in2', 'axi_dma_conv2d', 'axi_dma_relu', 'axi_dma_maxpool2d', 'processing_system7_0']\n"
     ]
    }
   ],
   "source": [
    "print('IP blocks :', list(overlay.ip_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = './data/mnist/'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "        \n",
    "#\n",
    "# Show some random training and test images \n",
    "#\n",
    "#images_2_show = []\n",
    "#titles_2_show = []\n",
    "#for i in range(0, 10):\n",
    "#    r = random.randint(1, 60000)\n",
    "#    images_2_show.append(x_train[r])\n",
    "#    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "#for i in range(0, 5):\n",
    "#    r = random.randint(1, 10000)\n",
    "#    images_2_show.append(x_test[r])        \n",
    "#    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "#show_images(images_2_show, titles_2_show)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "x = np.array(x_test[0])\n",
    "y = y_test[0]\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    c = x.max()\n",
    "    logsumexp = np.log(np.exp(x - c).sum())\n",
    "    return x - c - logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x00\\x00 A\\x00\\x000A\\x00\\x00@A\\x00\\x00PA\\x00\\x00`A\\x00\\x00pA\\x00\\x00\\x80A\\x00\\x00\\x88A\\x00\\x00\\x90A'\n",
      "[10. 11. 12. 13. 14. 15. 16. 17. 18.]\n"
     ]
    }
   ],
   "source": [
    "def float_to_hex(f):\n",
    "    return struct.unpack('I', struct.pack('f', f))[0]\n",
    "\n",
    "def hex_to_float(f):\n",
    "    return struct.unpack('f', struct.pack('I', f))[0]\n",
    "\n",
    "def numpy_to_hex(f):\n",
    "    #assert f.shape\n",
    "    format_string = f'{f.shape[0]}f'\n",
    "    packed_data = struct.pack(format_string, *f)\n",
    "    return packed_data\n",
    "\n",
    "def hex_to_numpy(f, length):\n",
    "    format_string = f'{length}f'\n",
    "    unpacked_data = struct.unpack(format_string, f)\n",
    "    return np.array(unpacked_data)\n",
    "\n",
    "data_in = np.array([10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0], dtype=np.float32)\n",
    "data_hex = numpy_to_hex(data_in)\n",
    "print(data_hex)\n",
    "data_out = hex_to_numpy(data_hex, 9)\n",
    "print(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n",
      "conv1.weight: <class 'list'>\n",
      "conv1.bias: <class 'list'>\n",
      "conv2.weight: <class 'list'>\n",
      "conv2.bias: <class 'list'>\n",
      "fc1.weight: <class 'list'>\n",
      "fc1.bias: <class 'list'>\n",
      "fc2.weight: <class 'list'>\n",
      "fc2.bias: <class 'list'>\n",
      "32\n",
      "1\n",
      "[[0.1870943158864975, -0.23402291536331177, -0.2610444724559784], [0.14852683246135712, -0.34062135219573975, 0.17761141061782837], [-0.07393540441989899, 0.22221820056438446, 0.11669355630874634]]\n",
      "[[ 0.18709432 -0.23402292 -0.26104447]\n",
      " [ 0.14852683 -0.34062135  0.17761141]\n",
      " [-0.0739354   0.2222182   0.11669356]]\n",
      "128\n",
      "12544\n",
      "0.0047676535323262215\n",
      "0.0047676535323262215\n"
     ]
    }
   ],
   "source": [
    "# Load the .pt file\n",
    "#with open(\"mnist_cnn.pt\", \"rb\") as f:\n",
    "#    data = pickle.load(f)\n",
    "\n",
    "#load the pre-processed pickle\n",
    "with open(\"mnist_cnn.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# Print the loaded data structure\n",
    "print(type(data))\n",
    "print(data.keys())\n",
    "\n",
    "if isinstance(data, dict):\n",
    "    for key in data:\n",
    "        print(f\"{key}: {type(data[key])}\")\n",
    "\n",
    "# Example: Convert a specific weight tensor to a NumPy array\n",
    "weight_key = \"conv1.weight\"  # Replace with the key you want to inspect\n",
    "\n",
    "weight_tensor = data[weight_key]\n",
    "print(len(weight_tensor))\n",
    "print(len(weight_tensor[0]))\n",
    "print(weight_tensor[0][0])\n",
    "# Convert to a NumPy array\n",
    "weight_array = np.array(weight_tensor[0][0])\n",
    "print(weight_array)\n",
    "\n",
    "# Example: Convert a specific weight tensor to a NumPy array\n",
    "weight_key = \"fc1.weight\"  # Replace with the key you want to inspect\n",
    "\n",
    "weight_tensor = data[weight_key]\n",
    "print(len(weight_tensor))\n",
    "print(len(weight_tensor[0]))\n",
    "print(weight_tensor[0][0])\n",
    "# Convert to a NumPy array\n",
    "weight_array = np.array(weight_tensor[0][0])\n",
    "print(weight_array)\n",
    "    \n",
    "#if hasattr(data[weight_key], 'numpy'):\n",
    "#    weight_array = data[weight_key].numpy()  # Convert directly to NumPy array\n",
    "#else:\n",
    "#    print(\"The data format isn't directly convertible. Raw data might need more processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __init__(self, overlay):\n",
    "        self.overlay = overlay\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.output_buffer = None\n",
    "        self.layer_ip = None\n",
    "        self.ip_dict = None\n",
    "        self.dma_send = None\n",
    "        self.dma_recv = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        start_time = time.time()\n",
    "        output = self.forward(x)\n",
    "        proc_time = time.time() - start_time\n",
    "        print(type(self).__name__, \" proc time: \", proc_time)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "    \n",
    "    #def get_register_offset(self, ip, parameter):\n",
    "    #    #print(self.overlay.ip_dict[ip]['registers'])\n",
    "    #    return self.overlay.ip_dict[ip]['registers'][parameter]['address_offset']\n",
    "        \n",
    "    def read_param_float(self, param):\n",
    "        address = self.ip_dict['registers'][param]['address_offset']\n",
    "        data = self.layer_ip.read(address)\n",
    "        return hex_to_float(data)\n",
    "        \n",
    "    def read_param_hex(self, param):\n",
    "        address = self.ip_dict['registers'][param]['address_offset']\n",
    "        data = self.layer_ip.read(address)\n",
    "        return data\n",
    "\n",
    "    def write_param_float(self, param, value):\n",
    "        address = self.ip_dict['registers'][param]['address_offset']\n",
    "        self.layer_ip.write(address, float_to_hex(value))\n",
    "    \n",
    "    def write_param_hex(self, param, value):\n",
    "        address = self.ip_dict['registers'][param]['address_offset']\n",
    "        self.layer_ip.write(address, value)\n",
    "    \n",
    "    def write_param_numpy(self, param, values):\n",
    "        #address = self.ip_dict['registers'][param]['address_offset']\n",
    "        #self.layer_ip.write(address, numpy_to_hex(values))\n",
    "        \n",
    "        val = values.reshape(-1)\n",
    "        address = self.ip_dict['registers'][param]['address_offset']\n",
    "        for i in range(val.size):\n",
    "            #print(\"writting: \", val[i], \" to: \", address+4*i)\n",
    "            self.layer_ip.write(address+4*i, float_to_hex(val[i]))\n",
    "        \n",
    "    def read_param_numpy(self, param, length=1):\n",
    "        address = self.ip_dict['registers'][param]['address_offset']\n",
    "        data = []\n",
    "        for i in range(length):\n",
    "            data_ = self.layer_ip.read(offset=address + 4*i)\n",
    "            data.append(hex_to_float(data_))\n",
    "        #return hex_to_numpy(data)\n",
    "        #return hex_to_float(data)\n",
    "        return np.array(data, dtype=np.float32)\n",
    "        \n",
    "    def process_ip(self, in_buffer, out_buffer):\n",
    "        self.layer_ip.write(0x0, 0x01)\n",
    "        self.dma_send.transfer(in_buffer)\n",
    "        self.dma_recv.transfer(out_buffer)\n",
    "        #print(type(self).__name__, \" sending\")\n",
    "        self.dma_send.wait()\n",
    "        #print(type(self).__name__, \" recieving\")\n",
    "        self.dma_recv.wait()\n",
    "    \n",
    "    \n",
    "class Linear_(Module):\n",
    "    def __init__(self, overlay, in_size, out_size):\n",
    "        Module.__init__(self, overlay)\n",
    "        \n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.output_buffer = []\n",
    "        self.output_buffer.append(allocate(shape=(out_size,), dtype=np.float32))\n",
    "    \n",
    "        self.layer_ip = overlay.Linear_0\n",
    "        self.ip_dict = overlay.ip_dict['Linear_0']\n",
    "\n",
    "        self.dma_send = overlay.axi_dma_linear.sendchannel\n",
    "        self.dma_recv = overlay.axi_dma_linear.recvchannel\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        assert len(x) == 1 and x[0].shape[0] == self.in_size\n",
    "        \n",
    "        #print(\"weights: \", self.weights[0])\n",
    "        #print(\"bias: \", self.bias[0])\n",
    "                \n",
    "        self.write_param_numpy('Memory_weights', self.weights.reshape(-1))\n",
    "        self.write_param_numpy('Memory_bias', self.bias.reshape(-1))   \n",
    "        self.write_param_hex('in_size', self.in_size)\n",
    "        self.write_param_hex('out_size', self.out_size)\n",
    "        \n",
    "        self.process_ip(x[0], self.output_buffer[0])\n",
    "                            \n",
    "        return self.output_buffer\n",
    "   \n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, overlay, in_size, out_size):\n",
    "        Module.__init__(self, overlay)\n",
    "        \n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.output_buffer = allocate(shape=(out_size,), dtype=np.float32)\n",
    "        self.aux_weight_buffer = allocate(shape=(in_size, ), dtype=np.float32)\n",
    "\n",
    "        self.layer_ip = overlay.dot_0\n",
    "        self.ip_dict = overlay.ip_dict['dot_0']\n",
    "\n",
    "        self.dma_send_1 = overlay.axi_dma_in1.sendchannel\n",
    "        self.dma_send_2 = overlay.axi_dma_in2.sendchannel\n",
    "    \n",
    "    def setWeightsAndBias(self, weights, bias):\n",
    "        assert len(weights.shape) == 2\n",
    "        assert weights.shape[0] == self.out_size\n",
    "        assert weights.shape[1] == self.in_size\n",
    "        \n",
    "        assert len(bias.shape) == 1\n",
    "        assert bias.shape[0] == self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def process_ip(self, in_buffer1, in_buffer2):\n",
    "        self.layer_ip.write(0x0, 0x01)\n",
    "        self.dma_send_1.transfer(in_buffer1)\n",
    "        self.dma_send_2.transfer(in_buffer2)\n",
    "        #print(type(self).__name__, \" sending\")\n",
    "        self.dma_send_1.wait()\n",
    "        self.dma_send_2.wait()\n",
    "        #print(type(self).__name__, \" recieving\")\n",
    "        #self.dma_recv.wait()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        assert len(x.shape) == 1\n",
    "        assert x.shape[0] == self.in_size\n",
    "        \n",
    "        self.write_param_hex('in_size', self.in_size)\n",
    "                \n",
    "        for i in range(self.out_size):         \n",
    "            #print(\"weights: \", self.weights[i, :])\n",
    "            #print(\"bias: \", self.bias[i])\n",
    "\n",
    "            self.aux_weight_buffer[:] = self.weights[i, :]\n",
    "            self.process_ip(x, self.aux_weight_buffer)\n",
    "\n",
    "            self.output_buffer[i] = self.read_param_float(\"result\") + self.bias[i]\n",
    "                    \n",
    "        return self.output_buffer\n",
    "        \n",
    "\n",
    "class Conv2d(Module):\n",
    "    def __init__(self, overlay, in_height, in_width, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        Module.__init__(self, overlay)\n",
    "        \n",
    "        assert kernel_size == 3\n",
    "        assert stride == 1\n",
    "        \n",
    "        self.layer_ip = overlay.conv2D_3x3_0\n",
    "        self.ip_dict = overlay.ip_dict['conv2D_3x3_0']\n",
    "        self.dma_send = self.overlay.axi_dma_conv2d.sendchannel\n",
    "        self.dma_recv = self.overlay.axi_dma_conv2d.recvchannel\n",
    "        \n",
    "        self.in_width = in_width\n",
    "        self.in_height = in_height\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.out_width = in_width\n",
    "        self.out_height = in_height\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.output_buffer = allocate(shape=(self.out_channels, self.out_height, self.out_width), dtype=np.float32)\n",
    "        self.aux_in_buffer = allocate(shape=(self.in_height, self.in_width), dtype=np.float32)\n",
    "        self.aux_out_buffer = allocate(shape=(self.out_height, self.out_width), dtype=np.float32)\n",
    "\n",
    "    def setWeightsAndBias(self, weights, bias):\n",
    "        assert len(weights.shape) == 4\n",
    "        assert weights.shape[0] == self.out_channels\n",
    "        assert weights.shape[1] == self.in_channels\n",
    "        assert weights.shape[2] == 3\n",
    "        assert weights.shape[3] == 3\n",
    "        \n",
    "        assert len(bias.shape) == 1\n",
    "        assert bias.shape[0] == self.out_channels\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        assert len(x.shape) == 3 \n",
    "        assert x.shape[0] == self.in_channels\n",
    "        assert x.shape[1] == self.in_height\n",
    "        assert x.shape[2] == self.in_width\n",
    "        \n",
    "        self.write_param_hex('in_width', self.in_width)\n",
    "        self.write_param_hex('in_height', self.in_height)\n",
    "        \n",
    "        for out_channel in range(self.out_channels):      \n",
    "            for in_channel in range(self.in_channels):   \n",
    "                 \n",
    "                #print(\"weights: \", self.weights[out_channel, in_channel, :, :])\n",
    "                #print(\"bias: \", self.bias[out_channel])\n",
    "                self.write_param_numpy('Memory_weights', self.weights[out_channel, in_channel, :, :])  \n",
    "                #self.write_param_float('bias', self.bias[out_channel])   \n",
    "                #print(self.read_param_numpy('Memory_weights', 9))\n",
    "                self.aux_in_buffer[:] = x[in_channel, :, :]\n",
    "                self.process_ip(self.aux_in_buffer, self.aux_out_buffer)\n",
    "                \n",
    "                if in_channel == 0:\n",
    "                    self.output_buffer[out_channel, :, :] = self.aux_out_buffer[:];\n",
    "                else:\n",
    "                    self.output_buffer[out_channel, :, :] += self.aux_out_buffer[:]\n",
    "            \n",
    "            self.output_buffer[out_channel, :, :] += self.bias[out_channel]\n",
    "            \n",
    "        return self.output_buffer        \n",
    "\n",
    "\n",
    "class ReLU(Module):\n",
    "    def __init__(self, overlay, data_size):\n",
    "        Module.__init__(self, overlay)\n",
    "    \n",
    "        #fpga specific\n",
    "        self.layer_ip = overlay.ReLU_0\n",
    "        self.ip_dict = overlay.ip_dict['ReLU_0']\n",
    "        self.dma_send = overlay.axi_dma_relu.sendchannel\n",
    "        self.dma_recv = overlay.axi_dma_relu.recvchannel\n",
    "        \n",
    "        self.data_size = data_size\n",
    "        self.output_buffer = allocate(shape=(self.data_size,), dtype=np.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        assert x.size == self.data_size \n",
    "        \n",
    "        self.write_param_hex('data_size', self.data_size)\n",
    "\n",
    "        self.process_ip(x.reshape(-1), self.output_buffer)\n",
    "        self.output_buffer = self.output_buffer.reshape(x.shape)\n",
    "            \n",
    "        return self.output_buffer\n",
    "\n",
    "\n",
    "class MaxPooling2D(Module):\n",
    "    def __init__(self, overlay, in_height, in_width, in_channels):\n",
    "        Module.__init__(self, overlay)\n",
    "    \n",
    "        self.layer_ip = overlay.MaxPooling2D_0\n",
    "        self.ip_dict = overlay.ip_dict['MaxPooling2D_0']\n",
    "        self.dma_send = overlay.axi_dma_maxpool2d.sendchannel\n",
    "        self.dma_recv = overlay.axi_dma_maxpool2d.recvchannel\n",
    "        \n",
    "        self.in_height = in_height\n",
    "        self.in_width = in_width\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.out_height = int(in_height/2)\n",
    "        self.out_width = int(in_width/2)\n",
    "        self.out_channels = in_channels\n",
    "                \n",
    "        self.output_buffer = allocate(shape=(self.out_channels, self.out_height, self.out_width), dtype=np.float32)\n",
    "        \n",
    "        self.aux_in_buffer = allocate(shape=(self.in_height, self.in_width), dtype=np.float32)\n",
    "        self.aux_out_buffer = allocate(shape=(self.out_height, self.out_width), dtype=np.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        assert len(x.shape) == 3\n",
    "        assert x.shape[0] == self.in_channels\n",
    "        assert x.shape[1] == self.in_height\n",
    "        assert x.shape[2] == self.in_width\n",
    "        \n",
    "        self.write_param_hex('in_width', self.in_width)\n",
    "        self.write_param_hex('in_height', self.in_height)\n",
    "\n",
    "        for channel in range(self.in_channels):\n",
    "            self.aux_in_buffer[:, :] = x[channel, :, :]\n",
    "            self.process_ip(self.aux_in_buffer, self.aux_out_buffer)\n",
    "            self.output_buffer[channel, :, :] = self.aux_out_buffer[:, :]\n",
    "        \n",
    "        return self.output_buffer\n",
    "\n",
    "    \n",
    "class Net(Module):\n",
    "    def __init__(self, overlay):\n",
    "        #super(Net, self).__init__()\n",
    "        Module.__init__(self, overlay)\n",
    "        self.conv1 = Conv2d(overlay, 28, 28, 1, 32, 3, 1)\n",
    "        self.relu1 = ReLU(overlay, 28*28*32)\n",
    "        self.conv2 = Conv2d(overlay, 28, 28, 32, 64, 3, 1)\n",
    "        self.relu2 = ReLU(overlay, 28*28*64)\n",
    "        self.max_pool2d = MaxPooling2D(overlay, 28, 28, 64)\n",
    "                \n",
    "        #self.dropout1 = Dropout(0.25)\n",
    "        #self.dropout2 = Dropout(0.5)\n",
    "        self.fc1 = Linear(overlay, 14*14*64, 128)\n",
    "        self.relu3 = ReLU(overlay, 128)\n",
    "        self.fc2 = Linear(overlay, 128, 10)\n",
    "            \n",
    "    def load_state_dict(self, pickle_file):\n",
    "        #load the pre-processed pickle\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "    \n",
    "        conv1_weight = np.array(data[\"conv1.weight\"], dtype=np.float32)\n",
    "        conv1_bias = np.array(data[\"conv1.bias\"], dtype=np.float32)\n",
    "        \n",
    "        self.conv1.setWeightsAndBias(conv1_weight, conv1_bias)\n",
    "        \n",
    "        conv2_weight = np.array(data[\"conv2.weight\"], dtype=np.float32)\n",
    "        conv2_bias = np.array(data[\"conv2.bias\"], dtype=np.float32)\n",
    "        \n",
    "        self.conv2.setWeightsAndBias(conv2_weight, conv2_bias)\n",
    "          \n",
    "        fc1_weight = np.array(data[\"fc1.weight\"], dtype=np.float32)\n",
    "        fc1_bias = np.array(data[\"fc1.bias\"], dtype=np.float32)\n",
    "        \n",
    "        #print(\"weight shape: \", fc1_weight.shape)\n",
    "        #print(\"bias shape: \", fc1_bias.shape)\n",
    "        self.fc1.setWeightsAndBias(fc1_weight, fc1_bias)\n",
    "        \n",
    "        fc2_weight = np.array(data[\"fc2.weight\"], dtype=np.float32)\n",
    "        fc2_bias = np.array(data[\"fc2.bias\"], dtype=np.float32)\n",
    "        \n",
    "        self.fc2.setWeightsAndBias(fc2_weight, fc2_bias)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        #x = self.dropout1(x)\n",
    "        #x = torch.flatten(x, 1)\n",
    "        x = x.reshape(-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        #x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = log_softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d  proc time:  0.3169379234313965\n",
      "ReLU  proc time:  0.012430191040039062\n",
      "Conv2d  proc time:  18.511022090911865\n",
      "ReLU  proc time:  0.0018851757049560547\n",
      "MaxPooling2D  proc time:  0.7681906223297119\n",
      "Linear  proc time:  0.20090055465698242\n",
      "ReLU  proc time:  0.0012941360473632812\n",
      "Linear  proc time:  0.01960611343383789\n",
      "Net  proc time:  19.861352920532227\n",
      "gt:  7  pred:  7\n",
      "Conv2d  proc time:  0.30504608154296875\n",
      "ReLU  proc time:  0.0029973983764648438\n",
      "Conv2d  proc time:  18.506895542144775\n",
      "ReLU  proc time:  0.003134012222290039\n",
      "MaxPooling2D  proc time:  0.755915641784668\n",
      "Linear  proc time:  0.18788433074951172\n",
      "ReLU  proc time:  0.0013043880462646484\n",
      "Linear  proc time:  0.012329578399658203\n",
      "Net  proc time:  19.782593965530396\n",
      "gt:  2  pred:  8\n",
      "Conv2d  proc time:  0.29515624046325684\n",
      "ReLU  proc time:  0.0029141902923583984\n",
      "Conv2d  proc time:  18.49225401878357\n",
      "ReLU  proc time:  0.0032477378845214844\n",
      "MaxPooling2D  proc time:  0.7577667236328125\n",
      "Linear  proc time:  0.17825102806091309\n",
      "ReLU  proc time:  0.0012607574462890625\n",
      "Linear  proc time:  0.01156926155090332\n",
      "Net  proc time:  19.746314764022827\n",
      "gt:  1  pred:  5\n",
      "Conv2d  proc time:  0.2957923412322998\n",
      "ReLU  proc time:  0.002826213836669922\n",
      "Conv2d  proc time:  18.307880640029907\n",
      "ReLU  proc time:  0.0030798912048339844\n",
      "MaxPooling2D  proc time:  0.7521469593048096\n",
      "Linear  proc time:  0.17803692817687988\n",
      "ReLU  proc time:  0.0012369155883789062\n",
      "Linear  proc time:  0.011724233627319336\n",
      "Net  proc time:  19.55662727355957\n",
      "gt:  0  pred:  7\n",
      "Conv2d  proc time:  0.2994697093963623\n",
      "ReLU  proc time:  0.0028116703033447266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function PynqBuffer.__del__ at 0xadb03460>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/share/pynq-venv/lib/python3.10/site-packages/pynq/buffer.py\", line 62, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d  proc time:  18.502026557922363\n",
      "ReLU  proc time:  0.0031392574310302734\n",
      "MaxPooling2D  proc time:  0.75667405128479\n",
      "Linear  proc time:  0.17919182777404785\n",
      "ReLU  proc time:  0.0013470649719238281\n",
      "Linear  proc time:  0.01203298568725586\n",
      "Net  proc time:  19.760658502578735\n",
      "gt:  4  pred:  4\n",
      "Conv2d  proc time:  0.29756641387939453\n",
      "ReLU  proc time:  0.0015110969543457031\n"
     ]
    }
   ],
   "source": [
    "model = Net(overlay)\n",
    "model.load_state_dict(\"mnist_cnn.pkl\")\n",
    "\n",
    "input_buffer = allocate(shape=(1,28,28), dtype=np.float32)\n",
    "\n",
    "for i in range(10):\n",
    "    input_buffer[:] = np.array(x_test[i]).reshape((1, 28, 28))\n",
    "    output = model(input_buffer)\n",
    "    prediction = np.argmax(output)\n",
    "    print(\"gt: \", y_test[i], \" pred: \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "#imgplot = plt.imshow(image)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
